{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765f9435",
   "metadata": {},
   "source": [
    "![Cancer](https://media2.giphy.com/media/sCqnpiUFN228E/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978f40a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110d1d",
   "metadata": {},
   "source": [
    "Among the most important areas in the world is human health. Exploring the methods for preventing and detecting health problems has sparked a lot of interest. Cancer is the most common illness that has a significant impact on human health. A malignant tumor is a cancerous tumor that develops as a result of the disease. Colon cancer, together with breast cancer and lung cancer, is the third most deadly disease in the United States, killing 49,190 people in 2016 [1]. This is a cancer that begins in the large intestine colon, which is the last component of the digestive system.\n",
    "\n",
    "The machine learning technique should be used in this assignment to aid in the detection of malignant cells and the differentiation of cell types in colon cancer. Deep learning algorithms such as AlexNet, Resnet50, and VGG19 will all be developed and evaluated in this notebook, with XGBoost being the sole non-deep learning option to tackle the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb03b9",
   "metadata": {},
   "source": [
    "# Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f538a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): failed\n",
      "\n",
      "NotWritableError: The current user does not have write permissions to a required path.\n",
      "  path: /Users/s3777214/opt/anaconda3/pkgs/cache/b89cf7bf.json\n",
      "  uid: 15973971\n",
      "  gid: 721532113\n",
      "\n",
      "If you feel that permissions on this path are set incorrectly, you can manually\n",
      "change them by executing\n",
      "\n",
      "  $ sudo chown 15973971:721532113 /Users/s3777214/opt/anaconda3/pkgs/cache/b89cf7bf.json\n",
      "\n",
      "In general, it's not advisable to use 'sudo conda'.\n",
      "\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge keras-preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d2892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pydot in /Users/s3823236/.local/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from pydot) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bbfaecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in /Users/s3823236/.local/lib/python3.9/site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from opencv-python) (1.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecc69724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /Users/s3823236/.local/lib/python3.9/site-packages (5.7.0)\n",
      "Requirement already satisfied: six in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from plotly) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "235d33aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /Users/s3823236/.local/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (1.46.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast>=0.2.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/s3823236/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/s3823236/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/s3823236/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/s3823236/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4c7fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.0-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.20.3)\n",
      "Requirement already satisfied: scipy in /Users/s3777214/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f49e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3043d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47cc8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "df_label_extra = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "632656e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>cellTypeName</th>\n",
       "      <th>cellType</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22405</td>\n",
       "      <td>1</td>\n",
       "      <td>22405.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22406</td>\n",
       "      <td>1</td>\n",
       "      <td>22406.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22407</td>\n",
       "      <td>1</td>\n",
       "      <td>22407.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22408</td>\n",
       "      <td>1</td>\n",
       "      <td>22408.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22409</td>\n",
       "      <td>1</td>\n",
       "      <td>22409.png</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>1625</td>\n",
       "      <td>60</td>\n",
       "      <td>1625.png</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>1626</td>\n",
       "      <td>60</td>\n",
       "      <td>1626.png</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>1627</td>\n",
       "      <td>60</td>\n",
       "      <td>1627.png</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>1628</td>\n",
       "      <td>60</td>\n",
       "      <td>1628.png</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>1629</td>\n",
       "      <td>60</td>\n",
       "      <td>1629.png</td>\n",
       "      <td>epithelial</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9896 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
       "0          22405          1  22405.png   fibroblast         0            0\n",
       "1          22406          1  22406.png   fibroblast         0            0\n",
       "2          22407          1  22407.png   fibroblast         0            0\n",
       "3          22408          1  22408.png   fibroblast         0            0\n",
       "4          22409          1  22409.png   fibroblast         0            0\n",
       "...          ...        ...        ...          ...       ...          ...\n",
       "9891        1625         60   1625.png   epithelial         2            1\n",
       "9892        1626         60   1626.png   epithelial         2            1\n",
       "9893        1627         60   1627.png   epithelial         2            1\n",
       "9894        1628         60   1628.png   epithelial         2            1\n",
       "9895        1629         60   1629.png   epithelial         2            1\n",
       "\n",
       "[9896 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc3d0e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InstanceID</th>\n",
       "      <th>patientID</th>\n",
       "      <th>ImageName</th>\n",
       "      <th>isCancerous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12681</td>\n",
       "      <td>61</td>\n",
       "      <td>12681.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12682</td>\n",
       "      <td>61</td>\n",
       "      <td>12682.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12683</td>\n",
       "      <td>61</td>\n",
       "      <td>12683.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12684</td>\n",
       "      <td>61</td>\n",
       "      <td>12684.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12685</td>\n",
       "      <td>61</td>\n",
       "      <td>12685.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10379</th>\n",
       "      <td>20028</td>\n",
       "      <td>99</td>\n",
       "      <td>20028.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>20029</td>\n",
       "      <td>99</td>\n",
       "      <td>20029.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>20030</td>\n",
       "      <td>99</td>\n",
       "      <td>20030.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>20031</td>\n",
       "      <td>99</td>\n",
       "      <td>20031.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>20032</td>\n",
       "      <td>99</td>\n",
       "      <td>20032.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10384 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       InstanceID  patientID  ImageName  isCancerous\n",
       "0           12681         61  12681.png            0\n",
       "1           12682         61  12682.png            0\n",
       "2           12683         61  12683.png            0\n",
       "3           12684         61  12684.png            0\n",
       "4           12685         61  12685.png            0\n",
       "...           ...        ...        ...          ...\n",
       "10379       20028         99  20028.png            0\n",
       "10380       20029         99  20029.png            0\n",
       "10381       20030         99  20030.png            0\n",
       "10382       20031         99  20031.png            0\n",
       "10383       20032         99  20032.png            0\n",
       "\n",
       "[10384 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = df_label.groupby('patientID').any()\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=cancer_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 50])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b314f",
   "metadata": {},
   "source": [
    "51 out of total of 77 persons who have cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px \n",
    "\n",
    "pie=px.pie(data_frame=df_label,\n",
    "           names='cellTypeName',\n",
    "           color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "           width=550,\n",
    "           height=550)\n",
    "pie.update_layout(title_text='Distribution of cell types', title_x=0.5)\n",
    "pie.update_traces(textinfo='value+label+percent')\n",
    "pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82977e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (10 , 5))\n",
    "cell_types_graph = sns.countplot(ax=ax1,x='isCancerous', hue='cellTypeName', data=df_label, palette='tab10')\n",
    "cell_types_graph.set_title(\"Cell types of positive vs negative patients\", fontsize=20)\n",
    "cell_types_graph.set_xticklabels(cell_types_graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 5000])\n",
    "for p in cell_types_graph.patches:\n",
    "    if p.get_height() > 0:\n",
    "        height = p.get_height()  \n",
    "        cell_types_graph.text(p.get_x()+p.get_width()/2., height + 100, int(height), ha=\"center\")\n",
    "    else:\n",
    "        cell_types_graph.text(p.get_x()+p.get_width()/2, 100, '0', ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41865a",
   "metadata": {},
   "source": [
    "From the graph, we can conclude the epithelial is cancerous cell type as all the patients who have cancer all possess epithelia cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c70346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=df_label, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 6000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06185e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=df_label_extra, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 8000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (7 , 5))\n",
    "graph = sns.countplot(ax=ax1,x='cellTypeName', data=df_label, palette='tab10')\n",
    "graph.set_title(\"Cell types number\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 5000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 100, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e17ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "CELL_TYPE_SAMPLE_SIZE = 5\n",
    "\n",
    "for cell_type_name in df_label['cellTypeName'].unique():\n",
    "    df_sample = df_label[df_label['cellTypeName'] == cell_type_name].sample(CELL_TYPE_SAMPLE_SIZE)\n",
    "    plt.figure(figsize=(CELL_TYPE_SAMPLE_SIZE ** 2, CELL_TYPE_SAMPLE_SIZE))\n",
    "    for image_index, image_name in enumerate(df_sample['ImageName']):\n",
    "        plt.subplot(1, CELL_TYPE_SAMPLE_SIZE + 1, image_index+1)\n",
    "        plt.grid(None)\n",
    "        img = image.load_img('./patch_images/' + image_name, target_size=(27, 27))\n",
    "        plt.imshow(img)\n",
    "        plt.title(cell_type_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f8ffd",
   "metadata": {},
   "source": [
    "## *Task1: Classify  images  according  to  whether  given  cell  image  represents  a cancerous cells or not (isCancerous)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58db1c",
   "metadata": {},
   "source": [
    "# Data Processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03798191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5817\n",
       "1    5817\n",
       "Name: isCancerous, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cancer_class_count = df_label.isCancerous.value_counts()\n",
    "amount_for_balance = abs(is_cancer_class_count[0] - is_cancer_class_count[1])\n",
    "df_random_cancer_from_extra = df_label_extra[df_label_extra['isCancerous'] == 1].sample(amount_for_balance)\n",
    "df_label = pd.concat([df_label, df_random_cancer_from_extra], ignore_index=True)\n",
    "df_label.isCancerous.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 6980, Val Data: 2327, Test Data: 2327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_label, test_size=0.2, random_state=9999)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918f0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_dataframe_iterator(dataframe, \n",
    "                            image_shape = (27, 27), \n",
    "                            batch_size = 64,\n",
    "                            x_col = \"ImageName\",\n",
    "                            y_col = \"cellTypeName\",\n",
    "                            classes = [\"fibroblast\", \"inflammatory\", \"epithelial\", \"others\"]):\n",
    "    dataframe[y_col] = dataframe[y_col].apply(str)\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        rotation_range = 20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ) \n",
    "    iterator = generator.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = \"./patch_images\", \n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        classes = classes, \n",
    "        class_mode = \"categorical\", \n",
    "        target_size = image_shape, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e646a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec3e3b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20280\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_list = os.listdir('./patch_images/')\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dea685c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18581.png\n",
      "15848.png\n",
      "4971.png\n"
     ]
    }
   ],
   "source": [
    "import hashlib, os\n",
    "duplicates = []\n",
    "hash_keys = dict()\n",
    "for index, filename in  enumerate(os.listdir('./patch_images/')):  #listdir('.') = current directory\n",
    "\n",
    "    if os.path.isfile('./patch_images/'+filename):\n",
    "        with open('./patch_images/'+filename, 'rb') as f:\n",
    "            filehash = hashlib.md5(f.read()).hexdigest()\n",
    "        if filehash not in hash_keys: \n",
    "            hash_keys[filehash] = index\n",
    "        else:\n",
    "            duplicates.append((index,hash_keys[filehash]))\n",
    "            print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d8d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from imageio import imread\n",
    "for file_indexes in duplicates[:30]:\n",
    "    try:\n",
    "    \n",
    "        plt.subplot(121),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[1]]))\n",
    "        plt.title(file_indexes[1]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        plt.subplot(122),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[0]]))\n",
    "        plt.title(str(file_indexes[0]) + ' duplicate'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    except OSError as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e190503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./patch_images/18581.png\n",
      "./patch_images/15848.png\n",
      "./patch_images/4971.png\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate\n",
    "for index in duplicates:\n",
    "#     os.remove('./patch_images/' + file_list[index[0]] )\n",
    "    print('./patch_images/' + file_list[index[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "437bb811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
      "0           22405          1  22405.png   fibroblast       0.0            0\n",
      "1           22406          1  22406.png   fibroblast       0.0            0\n",
      "2           22407          1  22407.png   fibroblast       0.0            0\n",
      "3           22408          1  22408.png   fibroblast       0.0            0\n",
      "4           22409          1  22409.png   fibroblast       0.0            0\n",
      "...           ...        ...        ...          ...       ...          ...\n",
      "11629        5857         85   5857.png          NaN       NaN            1\n",
      "11630       12996         67  12996.png          NaN       NaN            1\n",
      "11631       11523         65  11523.png          NaN       NaN            1\n",
      "11632        7557         88   7557.png          NaN       NaN            1\n",
      "11633       11543         65  11543.png          NaN       NaN            1\n",
      "\n",
      "[11634 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0939f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1215\n",
      "18512\n",
      "20259\n"
     ]
    }
   ],
   "source": [
    "for index in duplicates:\n",
    "    print(index[0])\n",
    "    df_label = df_label[df_label.ImageName  != file_list[index[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0983f0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
      "0           22405          1  22405.png   fibroblast       0.0            0\n",
      "1           22406          1  22406.png   fibroblast       0.0            0\n",
      "2           22407          1  22407.png   fibroblast       0.0            0\n",
      "3           22408          1  22408.png   fibroblast       0.0            0\n",
      "4           22409          1  22409.png   fibroblast       0.0            0\n",
      "...           ...        ...        ...          ...       ...          ...\n",
      "11629        5857         85   5857.png          NaN       NaN            1\n",
      "11630       12996         67  12996.png          NaN       NaN            1\n",
      "11631       11523         65  11523.png          NaN       NaN            1\n",
      "11632        7557         88   7557.png          NaN       NaN            1\n",
      "11633       11543         65  11543.png          NaN       NaN            1\n",
      "\n",
      "[11631 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0eafcf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5817\n",
       "0    5815\n",
       "Name: isCancerous, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cancer_class_count = df_label.isCancerous.value_counts()\n",
    "amount_for_balance = abs(is_cancer_class_count[0] - is_cancer_class_count[1])\n",
    "df_random_cancer_from_extra = df_label_extra[df_label_extra['isCancerous'] == 1].sample(amount_for_balance)\n",
    "df_label = pd.concat([df_label, df_random_cancer_from_extra], ignore_index=True)\n",
    "df_label.isCancerous.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63554cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data : 6978, Val Data: 2327, Test Data: 2327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_label, test_size=0.2, random_state=9999)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "345e7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_dataframe_iterator(dataframe, \n",
    "                            image_shape = (27, 27), \n",
    "                            batch_size = 64,\n",
    "                            x_col = \"ImageName\",\n",
    "                            y_col = \"cellTypeName\",\n",
    "                            classes = [\"fibroblast\", \"inflammatory\", \"epithelial\", \"others\"]):\n",
    "    dataframe[y_col] = dataframe[y_col].apply(str)\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        rotation_range = 20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ) \n",
    "    iterator = generator.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = \"./patch_images\", \n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        classes = classes, \n",
    "        class_mode = \"categorical\", \n",
    "        target_size = image_shape, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c77af1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6978 validated image filenames belonging to 2 classes.\n",
      "Found 2327 validated image filenames belonging to 2 classes.\n",
      "Found 2327 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_iterator = get_dataframe_iterator(train_df, y_col='isCancerous', classes=['0','1'])\n",
    "val_iterator = get_dataframe_iterator(val_df, y_col='isCancerous', classes=['0','1'])\n",
    "test_iterator = get_dataframe_iterator(test_df, y_col='isCancerous', classes=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5af9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Add\n",
    "from keras import regularizers\n",
    "from keras import Input\n",
    "from tensorflow.keras import initializers\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "from keras import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d655018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, iterator, val_iterator, \n",
    "              epochs = 100, \n",
    "              export_dir = './export',\n",
    "              name = 'default'):\n",
    "    es = EarlyStopping(monitor='val_accuracy', \n",
    "                       mode='max', \n",
    "                       verbose=1, \n",
    "                       patience=10, \n",
    "                       restore_best_weights=True)\n",
    "    mc = ModelCheckpoint('{}/model_{}.h5'.format(export_dir, name), \n",
    "                         monitor='val_accuracy', \n",
    "                         mode='max', \n",
    "                         save_best_only=True)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        iterator,\n",
    "        validation_data = val_iterator,\n",
    "        epochs = epochs,\n",
    "        verbose = 1,\n",
    "        callbacks=[mc,es]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079c57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe1edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11632, 27, 27)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "list_of_images = []\n",
    "\n",
    "for path in df_label['ImageName']:\n",
    "  image_path = os.path.join(\"./patch_images\", path)\n",
    "  image = cv2.imread(image_path , cv2.IMREAD_GRAYSCALE)\n",
    "  list_of_images.append(image)\n",
    "\n",
    "list_of_images = np.asarray(list_of_images)\n",
    "np.array(list_of_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfb8b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = np.reshape(list_of_images,  (-1 , 27 * 27))\n",
    "list_of_images = pd.DataFrame(list_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d4853ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (9305, 729)\n",
      "Train Y shape:  (9305,)\n",
      "Validate X shape:  (2327, 729)\n",
      "Validate Y shape:  (2327,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "train_x_cancer , validate_x_cancer, train_y_cancer , validate_y_cancer = train_test_split(list_of_images, df_label['isCancerous'], test_size=0.2 , random_state = 42, shuffle = True)\n",
    "\n",
    "print(\"Train X shape: \" , train_x_cancer.shape)\n",
    "print(\"Train Y shape: \" , train_y_cancer.shape)\n",
    "print(\"Validate X shape: \" , validate_x_cancer.shape)\n",
    "print(\"Validate Y shape: \" , validate_y_cancer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11f3cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8e72",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eae76c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.26%\n",
      "RMSE: 0.37\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Binary:logistic is used for logistic classfication problem which is our problem in this task\n",
    "xgbr = xgb.XGBRegressor(objective='binary:logistic')\n",
    "xgbr.fit(train_x_cancer, train_y_cancer)\n",
    "\n",
    "y_pred_validate = xgbr.predict(validate_x_cancer)\n",
    "prediction_validate = [round(value) for value in y_pred_validate]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(validate_y_cancer, prediction_validate)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "mse = mean_squared_error(validate_y_cancer, y_pred_validate)\n",
    "print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "# accuracy = accuracy_score(validate_y_cancer, ypred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f12a2738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validate report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1149\n",
      "           1       0.81      0.82      0.82      1178\n",
      "\n",
      "    accuracy                           0.81      2327\n",
      "   macro avg       0.81      0.81      0.81      2327\n",
      "weighted avg       0.81      0.81      0.81      2327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgbr.predict(train_x_cancer)\n",
    "prediction_train = [round(value) for value in y_pred_train]\n",
    "\n",
    "\n",
    "print(\"Validate report\")\n",
    "print(classification_report(validate_y_cancer, prediction_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e117bbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 1000}\n",
      "Lowest RMSE:  0.3638024251583933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "clf = GridSearchCV(estimator=xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "clf.fit(train_x_cancer, train_y_cancer)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3a2ff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1149\n",
      "           1       0.81      0.82      0.81      1178\n",
      "\n",
      "    accuracy                           0.81      2327\n",
      "   macro avg       0.81      0.81      0.81      2327\n",
      "weighted avg       0.81      0.81      0.81      2327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "xg_y_pred_validate = clf.predict(validate_x_cancer)\n",
    "xg_y_pred_train = clf.predict(train_x_cancer)\n",
    "xg_prediction_train = [round(value) for value in xg_y_pred_train]\n",
    "xg_prediction_validate = [round(value) for value in xg_y_pred_validate]\n",
    "\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer, xg_prediction_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3755536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "random_search = RandomizedSearchCV(estimator=xgbr,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         verbose=1)\n",
    "random_search.fit(train_x_cancer, train_y_cancer)\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Lowest RMSE: \", (-random_search.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5875b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce42bda2",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31edc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54611d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "!pip install keras_applications\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.util import tf_inspect\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(include_top=False, input_shape=(75, 75, 3), weights='imagenet')\n",
    "\n",
    "# Resize Input images to 75x75\n",
    "newInput = Input(batch_shape=(None, 27, 27, 3))\n",
    "resizedImg = Lambda(lambda image: tf.compat.v1.image.resize_images(image, (75, 75)))(newInput)\n",
    "newOutputs = model(resizedImg)\n",
    "model = Model(newInput, newOutputs)\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add Dense layer to classify on CIFAR10\n",
    "output = model.output\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dense(units=2, activation='softmax')(output)\n",
    "model_inceptionv3 = Model(model.input, output)\n",
    "\n",
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb83f109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0045 , amsgrad = True)\n",
    "model_inceptionv3.compile(optimizer=Adam(lr=1e-4),loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "history_inception_v3 = fit_model(model_inceptionv3, train_iterator, val_iterator, \n",
    "                                export_dir='.',\n",
    "                                name=\"Inception_Task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c1f2a",
   "metadata": {},
   "source": [
    "# GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
    "  # Input: \n",
    "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "\n",
    "  # 1st path:\n",
    "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "\n",
    "  # 2nd path\n",
    "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "  # 3rd path\n",
    "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "  # 4th path\n",
    "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
    "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
    "\n",
    "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "  return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogLeNet():\n",
    "  # input layer \n",
    "  input_layer = Input(shape = (27, 27, 3))\n",
    "\n",
    "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
    "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
    "\n",
    "  X = ZeroPadding2D(padding=(10, 10))(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 1)(X)\n",
    "\n",
    "  # convolutional layer: filters = 64, strides = 1\n",
    "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
    "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 1st Inception block\n",
    "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
    "\n",
    "  # 2nd Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 3rd Inception block\n",
    "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
    "\n",
    "  # Extra network 1:\n",
    "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
    "  X1 = Flatten()(X1)\n",
    "  X1 = Dense(1024, activation = 'relu')(X1)\n",
    "  X1 = Dropout(0.7)(X1)\n",
    "  X1 = Dense(2, activation = 'softmax')(X1) # <----- changed 1000 to 2\n",
    "\n",
    "  \n",
    "  # 4th Inception block\n",
    "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 5th Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 6th Inception block\n",
    "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # Extra network 2:\n",
    "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "  X2 = Flatten()(X2)\n",
    "  X2 = Dense(1024, activation = 'relu')(X2)\n",
    "  X2 = Dropout(0.7)(X2)\n",
    "  X2 = Dense(2, activation = 'softmax')(X2) # <----- changed 1000 to 2\n",
    "  \n",
    "  \n",
    "  # 7th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
    "                      f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # 8th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # 9th Inception block\n",
    "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # Global Average pooling layer \n",
    "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
    "\n",
    "  # Dropoutlayer \n",
    "  X = Dropout(0.4)(X)\n",
    "\n",
    "  # output layer \n",
    "  X = Dense(2, activation = 'softmax')(X) # <------ changed from 1000 to 2 \n",
    "  \n",
    "  # model\n",
    "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_googlenet_t1 = GoogLeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model_googlenet_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_googlenet_t1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00045, amsgrad = True)\n",
    "model_googlenet_t1.compile(optimizer=opt, loss='binary_crossentropy')\n",
    "\n",
    "history_googlenet_t1 = fit_model(model_googlenet_t1, train_iterator, val_iterator,\n",
    "                                export_dir='.',\n",
    "                                name=\"GoogLeNet_Task1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99379d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = model_googlenet_t1.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = [\n",
    "    evaluation_googlenet_t1[1], # dense_4_loss\n",
    "    evaluation_googlenet_t1[4], # dense_4_accuracy\n",
    "    evaluation_googlenet_t1[5], # dense_4_precision\n",
    "    evaluation_googlenet_t1[6], # dense_4_recall\n",
    "    evaluation_googlenet_t1[7]  # dense_4_f1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa198f7",
   "metadata": {},
   "source": [
    "## *Task2: Classify  images  according  to  cell-type,  such  as:  fibroblast,  inflammatory, epithelial or others* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee169c46",
   "metadata": {},
   "source": [
    "<a id =\"IV\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">Ⅰ. Cleaning dataset  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfb9f6",
   "metadata": {},
   "source": [
    "#### Before cleaning the data, let display the dataset to observe it in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d555f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbc66d",
   "metadata": {},
   "source": [
    "<a id =\"IV.A1\"></a>\n",
    "\n",
    "### *1. Check Data type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ee211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all info row by row\n",
    "df_label.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18d525",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "We need to check data type for overall understanding for our dataset and identifying which column we should keep or change data type for later encoding and better model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f5b0",
   "metadata": {},
   "source": [
    "<a id =\"IV.A2\"></a>\n",
    "\n",
    "### *2. Checking missing values*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535ad0a",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Missing value can lead to error for machine, thus, we need to check if there is any missing value and fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset has any missing value, \n",
    "df_label.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c605a",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the return value is false, we can conclude that the dataset has no missing values. However, we should double check for every columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f45c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total missing values for each columns \n",
    "df_label.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cf7a5",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "There is 100% no missing values in any columns in the dataset, thus, we dont not need to fill any missing values for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4d506",
   "metadata": {},
   "source": [
    "<a id =\"IV.A3\"></a>\n",
    "\n",
    "### *3. Check typography*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_name_values = df_label['cellTypeName'].nunique(dropna=False)\n",
    "print(celltype_name_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_label['cellTypeName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9b944",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Typo value can lead to time runing and storage problem for machine (fibroblast, fibreblast are 2 different values but have same meaning), thus, we check typo preventing same meaningful values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c8a06",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the cellTypeName column have 4 different values such as fibroblast, inflammatory, epithelial or others. => no typo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8813c8b",
   "metadata": {},
   "source": [
    "<a id =\"IV.A4\"></a>\n",
    "\n",
    "### *4. Convert string column to uppercase*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73572b",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since there are only 4 values fibroblast, inflammatory, epithelial in cellTypeName columns. Therefore, we do not need to convert to lowercase or uppercase for this dataset. However, in the larger dataset with multiple values, we should convert to all uppercase or lowercase to avoid duplication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb3f63",
   "metadata": {},
   "source": [
    "<a id =\"IV.A5\"></a>\n",
    "\n",
    "### 5. Eliminate extra white spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d910c3",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the Sepsis column have 4 different values such as fibroblast, inflammatory, epithelial or others => no extra white spaces    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c994bd3",
   "metadata": {},
   "source": [
    "<a id =\"IV.A6\"></a>\n",
    "\n",
    "### *6. Check duplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Datafrane -> no dupplication in the df_label dataframe\n",
    "duplicate_values = df_label[df_label.duplicated()]\n",
    "print(duplicate_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc5f7",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Duplicate data can lead to time runing and storage problem for machine, thus, we need to check if there is any duplicated data and drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88066fec",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "There is 100% no duplicated values in the dataset, thus, we dont not need to drop any rows for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d66ff",
   "metadata": {},
   "source": [
    "<a id =\"IV.A7a\"></a>\n",
    "\n",
    "### 7. Check impossible values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5655b",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Some time the dataset has some impossible values such as age is negative, thus, we need to check impossible value to find and drop or fix it to improve the accuracy of the machine learing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfdd5e",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "In this dataset, all of the data are reasonable => no impossible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a211bb",
   "metadata": {},
   "source": [
    "<a id =\"IV.B8\"></a>\n",
    "\n",
    "### 8. Check outlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7.5]\n",
    "# plot the boxplot to see the outlier of each numerical column\n",
    "sns.boxplot(data=df_label,orient=\"v\")\n",
    "plt.title(\"Bot-Plots Distribution\", y = 1,fontsize = 20, pad = 40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1cd74",
   "metadata": {},
   "source": [
    "### 🔬 Observation:\n",
    "According to the bot-plots, there are completely no outliner in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6697d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385a602",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "After finish cleaning the data, we should display the data to double check the data and figure out the count, mean, min , 25%, 50%, 75%, max to prepare for EDA step in later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9fb32",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">II. Exploratory Data Analysis (EDA)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf39ec",
   "metadata": {},
   "source": [
    "<a id =\"V.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.My hypothesises </h3>\n",
    "\n",
    "1. The value for each type in the cell type name will be different.\n",
    "\n",
    "2. The value of `others` class will be the least compare to other classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "ax = sns.countplot(y=\"cellTypeName\", data=df_label)\n",
    "ax.set_title(\"Bar chart to display the total number of each type in cell type name\", fontsize=15)\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f05837",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔬 Observation: \n",
    "In this plot, the vertical axis is cellTypeName and the horizontal axis is count (total values). In overall, the class epithelial has the most value (4079) whereas the other class have the least value (1386). In additional, the different between each class are large, thus, we should consider to solve this problem by using imbalance in the feature engineering step. \n",
    "\n",
    "After observation, we can conclude that our hypotheses are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a094c3",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">III. Feature Enginnering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1622526",
   "metadata": {},
   "source": [
    "<a id =\"VI.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Drop Unrealated columns to the target</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe28d3f",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since all columns in the dataset are neccessary => we do not need to drop any columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ad113",
   "metadata": {},
   "source": [
    "<a id =\"VI.2\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2.Class Imbalances</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_label['cellTypeName'].value_counts())\n",
    "print(df_label['cellTypeName'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dc023",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "The reason, we need to rebalance these classes value is the accuracy of the sepsis prediction might affected by the amount of values in one class. In other words , if one class has more values compare to the others , it is likely that we will receive the better prediction for this class instead of others, thus, the prediction for other clas might be worst. Thus,in this particular situation, since the difference between these classes are large, we can rebalance these classes using <strong>upsample method</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673ecbc",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the value for each cell type are extremely different from others (4079, 2543 , 1888 , 1386). Thus, we need to rebalance these classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampleData (minority_value):\n",
    "    return resample(minority_value,\n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=4079,    # to match majority class\n",
    "                                 random_state=123) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88507a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 2 classes depend all total values\n",
    "majority_value = df_label[df_label.cellTypeName==\"epithelial\"]\n",
    "minority_value = df_label[df_label.cellTypeName==\"inflammatory\"]\n",
    "minority_value2 = df_label[df_label.cellTypeName==\"fibroblast\"]\n",
    "minority_value3 = df_label[df_label.cellTypeName==\"others\"]\n",
    " \n",
    "# Balance majority value with upsampled minority value\n",
    "df_label_balanced = pd.concat([majority_value, resampleData(minority_value),\n",
    "                               resampleData(minority_value2),\n",
    "                               resampleData(minority_value3)])\n",
    " \n",
    "# Show new value in these classes\n",
    "df_label_balanced.cellTypeName.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4059c3a",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "After upsampling these classes, the value for all classes are the same, thus, we can move to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d2a69",
   "metadata": {},
   "source": [
    "<a id =\"VII\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">IV. Model Building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c999e89",
   "metadata": {},
   "source": [
    "<a id =\"VII.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Split dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d979574",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_bl, test_df_bl = train_test_split(np.array(df_label_balanced), test_size=0.2, random_state=42)\n",
    "train_df_bl, val_df_bl = train_test_split(np.array(train_df), test_size=0.2, random_state=42)\n",
    "print(train_df_bl.shape)`\n",
    "print(test_df_bl.shape)\n",
    "print(val_df_bl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ffd26",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "After spliting the data, we can start training the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41770af",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2. XG Boost</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a82977",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">3. Resnet</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cc294",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">4. GoogleNet</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758d7f0",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">5. Alex Net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5723cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
