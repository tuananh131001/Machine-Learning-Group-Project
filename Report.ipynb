{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765f9435",
   "metadata": {},
   "source": [
    "![Cancer](https://media2.giphy.com/media/sCqnpiUFN228E/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978f40a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110d1d",
   "metadata": {},
   "source": [
    "Among the most important areas in the world is human health. Exploring the methods for preventing and detecting health problems has sparked a lot of interest. Cancer is the most common illness that has a significant impact on human health. A malignant tumor is a cancerous tumor that develops as a result of the disease. Colon cancer, together with breast cancer and lung cancer, is the third most deadly disease in the United States, killing 49,190 people in 2016 [1]. This is a cancer that begins in the large intestine colon, which is the last component of the digestive system.\n",
    "\n",
    "The machine learning technique should be used in this assignment to aid in the detection of malignant cells and the differentiation of cell types in colon cancer. Deep learning algorithms such as AlexNet, Resnet50, and VGG19 will all be developed and evaluated in this notebook, with XGBoost being the sole non-deep learning option to tackle the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb03b9",
   "metadata": {},
   "source": [
    "# Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f49e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px \n",
    "from tensorflow.keras.preprocessing import image\n",
    "import hashlib, os\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from zipfile import ZipFile\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.util import tf_inspect\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Add\n",
    "from keras import regularizers\n",
    "from keras import Input\n",
    "from tensorflow.keras import initializers\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f219428d-4cba-403a-bc15-a2dda9bceeb9",
   "metadata": {},
   "source": [
    "# *Task1: Classify  images  according  to  whether  given  cell  image  represents  a cancerous cells or not (isCancerous)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3043d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "main_data_extra = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988081ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ZipFile(\"Image_classification_data.zip\").extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632656e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31f12a-6cc6-4485-8470-dc571aae82af",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">1. Data Preparation & Data exploration (EDA)</h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = main_data.groupby('patientID').any()\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=cancer_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 60])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b314f",
   "metadata": {},
   "source": [
    "51 out of total of 77 persons who have cancer, the rest 26 out of 77 is the number of people who don't have cancer cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pie=px.pie(data_frame=main_data,\n",
    "           names='cellTypeName',\n",
    "           color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "           width=550,\n",
    "           height=550)\n",
    "pie.update_layout(title_text='Distribution of cell types', title_x=0.5)\n",
    "pie.update_traces(textinfo='value+label+percent')\n",
    "pie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41865a",
   "metadata": {},
   "source": [
    "From the graph, we can conclude the epithelial is cancerous cell type as all the patients who have cancer all possess epithelia cell type. As the number of cells of the epithelial type have the biggest number in the record (41.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c70346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=main_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 6000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "c06185e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=main_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients extra df\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 8000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2c3ee1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz0AAAMwCAYAAAAK9g6rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACJp0lEQVR4nOzdf1zV9f3///uRA0cT+yaLE46cOWejQUnBVqyG1SbgD2ajXwrm+qnxLiszzIBBWKYWaTrF2tZcaXsnkYIyOq6y2Mp+0NnSnYbpSijF4aHUAOUAh/P9w4/nLaIJiB54ndv1cukir+d5HV7Px5POeZ37eT1fr5fJ4/F4BAAAAAAG1c/XHQAAAACA04nQAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0wtGuvvVb/+te/uvy8+vp6TZ069TT06NvNmTNHzz//vPfnn/3sZ5o4caImTpyocePGKScnR06n84z3CwBgTMuWLdMbb7whSVqyZImKi4u7/bu2bt2qnJwc7/LR++Brr71WiYmJmjhxon75y18qOTlZK1asUGtr6yn1H+gss687APRGBw4c6FZY6mm33nqr7rjjDkmSx+PRc889pzvvvFNr165VQECAj3sHAOjrPvjgA/3gBz+QJN1///2n9Lv+85//qLa29oSP5+fn6+KLL5YkHTx4UA899JDmz5+v3/zmN6e0XaAzCD3wCxdffLGmTZumd999V3v37tWdd96p1NRUOZ1OPfzww9q3b58kafTo0XrggQf0yCOPqKmpSRMnTtTatWu1bt06rVmzRi0tLTpw4IDuuusupaamau3atXr99dfVr18/VVdXq3///lq4cKFGjBghp9Op3Nxcff755+rXr58mTZqkqVOnqr6+XvPmzdP27dvV0tKiuLg4zZ49W2bzt78cTSaT7r77bq1bt07vvvuu4uPjz8TQAQD6iA8++ED5+fn67ne/q88//1z9+/fXggUL1K9fP82dO1eNjY1yOp2KiIjQM888o6KiIjkcDj355JMKCAjQm2++qZEjR+qOO+7QZ599pnnz5mn//v1yu9265ZZbdMMNN+iDDz7Q4sWLNXToUO3YsUOtra3Ky8vTd7/7XS1dulT19fV65JFHNH/+/G/t61lnnaWcnBz94he/0MyZMxUcHHyGRgn+iult8AvNzc0aPHiwXn75ZS1dulTz58+Xy+VSYWGhzj//fK1bt04vvfSSqqurVV9fr/nz56t///4qKSlRU1OTXnnlFf3ud79TcXGxFi9erKeeesr7uysqKvSb3/xGpaWlGjVqlH73u99JkvLy8nTBBRfIZrNpzZo1KiwsVHV1tZ544glFRkZq7dq1Ki4u1r59+7Ry5cpO1/LDH/5Q27dv7/ExAgD0fQ6HQ7fccos2bNiglJQUZWRkqLCwUNddd50KCwv117/+Vbt27dLbb7+ttLQ0RUVFafbs2RozZoz3d7S2tuq+++7TrFmztHbtWq1evVp//OMf9fHHH0s6PI3t9ttvV3FxsVJSUrR48WINGTJE9913n2JjY08aeI4ICwtTcHCwPv/889MxFEA7HOmB3/j5z38uSYqMjFRzc7MOHjyon/3sZ5o2bZr27Nmjn/70p5o1a5YGDRqkAwcOeJ83cOBAPfvssyovL1dVVZW2bdumgwcPeh+PjIxUWFiYJOlHP/qRXn/9dUnS5s2blZGRIUkaNGiQSktLJUlvv/22/vWvf6moqEiS1NTU1KU6TCaTBgwY0M1RAAAYWUREhGJjYyVJ119/vebOnavnn39eDodDv//971VVVaW9e/e2248dq6qqSl988YUyMzO9bU1NTfr3v/+tESNG6Lvf/a4uuugiSYf3e+vWret2f9mn4Uwh9MBvWCwWSYffYKXD58hccsklevPNN/Xee+/p/fff14033qjf//73Ouecc7zP++9//6ubb75ZN910k2JiYpSUlKS33nrL+3j//v29P5tMJnk8HkmS2Wz2bkuSvvzySw0ePFhtbW1asmSJRowYIUn65ptv2q33bTwejz755BNNmTKle4MAADC0453v+dBDD+mss87S2LFjdfXVV2vPnj3efdXxuN1uDRo0SCUlJd62uro6DRo0SB9//PEJ93tdtXv3bh08eFDf+973uvV8oCuY3ga/lp+fr4KCAv3iF79QVlaWfvCDH2jHjh0ym81yu93yeDxyOBwKCQnR//zP/+iqq67yBh632/2tvzsuLk6vvvqqpMNXg/v1r3+tqqoqXXXVVfrTn/4kj8ej5uZmpaena/Xq1Sftq9vt1vLlyzV48GD9+Mc/PvXiAQCGs23bNm3btk2StGbNGl166aXasmWL7rnnHo0bN06StGXLFu8+LCAgoMMV1IYPH+6d4i1Je/bs0YQJE+RwOL5128f7XSfyzTff6LHHHlNaWpr3S0ngdOJID/zar3/9a82ZM0cTJkxQUFCQfvjDH2r8+PEKCAjQJZdcovHjx2vlypU677zzlJSUJJPJpJ/85CcKCQlRdXX1t/7unJwcPfroo0pOTpbH49H06dMVFRWlrKwszZs3T8nJyWppadFPf/pT3Xnnncf9HX/605+0fv16mUwmud1uXXzxxd5zhgAAONa5556rZ555Rrt371ZISIiefPJJlZeX65577tFZZ52l4OBg/fjHP9YXX3wh6fClpBctWqSWlhbv7wgKClJBQYHmzZunP/zhD2ptbdX999+vmJgYffDBByfcdnR0tJYvX657771Xy5Yt6/D4Qw89pP79+ysgIEBut1sJCQm6++67e34QgOMwebp7TBIAAAC9xgcffKDHHnvMew4pgP/D9DYAAAAAhsaRHgAAAACG1qkjPQ0NDZowYYJ27dolSfrnP/+pm266SePHj9eDDz6o5uZmSVJlZaVSUlKUmJiorKws78lsNTU1SktLU1JSktLT09XY2HiaygEAAACA9k56pGfLli3Kzs7Wzp07ZbPZdM455ygpKUl/+MMfFBERoQcffFCxsbFKTU3VhAkT9Pjjjys6OlqZmZmKiopSamqqpk+frl/+8pcaP368li9froMHD3rvX3IybW1tamxsVGBgYKcv6wsA6Mjj8ailpUUDBw5Uv37Mbu4t2M8BwKk72T7upKEnKytLv/rVrzR79my9+OKL+uSTT7RhwwbvVTm+/vprud1uNTc369e//rXeeOMNSdJHH32kpUuX6vnnn9fll1+uDz/8UGazWXv27NGUKVP05ptvdqqA+vp67j4PAD3owgsv1KBBg3zdDfw/7OcAoOecaB930ktWz5s3r91ydXW1zjrrLM2cOVOff/65LrvsMs2ZM0f//ve/FRoa6l0vNDRUtbW12rdvn4KDg2U2m9u1d1ZgYGCn1wUAnBzvq73Lkb/HhRdeqKCgoE49x+FwKCoq6nR2q89ibE6MsTkxxubE+srYNDc3a/v27Sfcx3X5Pj1ut1vvvPOO1qxZo+9+97vKysrS7373O/30pz9td1je4/F479J77OH6rhy+P7JuVFRUt29eZbfbFRMT063nGhHj0RFj0hFj0lFfHxOXyyWHw8EUql7myN8jKCioS/s5buh4YozNiTE2J8bYnFhfGpsT7eO6PKn73HPP1ahRozR06FAFBARo7Nix2rp1q8LCwuR0Or3r1dXVyWq1KiQkRPX19d47/zqdTlmt1m6WAQAAAABd0+XQc9VVV+mTTz7Rnj17JElvvfWWIiMjFR4eLovFIrvdLkkqKSlRfHy8AgMDFRsbq7KyMklScXGx4uPje7AEAAAAADixLk9vGzJkiObOnau7775bLpdLF110kR5++GFJUn5+vrKzs9XQ0KDIyEhNnTpVkpSbm6s5c+ZoxYoVGjJkiBYtWtSzVQAAAADACXQ69GzatMn789VXX62rr766wzoREREqKirq0B4eHq5Vq1Z1r4cAAAAAcAq4UQMAAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADC0Ll+9DQAAo2loaNCkSZP07LPP6rPPPmt3ldHa2lqNGjVKzz33nJYtW6ZXX31VZ599tiTppptuUlpammpqapSRkaGvvvpKw4cPV35+vgYOHOircgAAxyD0AAD82pYtW5Sdna2qqipJ0ujRozV69GhJh2+oPXnyZD3yyCOSJIfDoUWLFunSSy9t9zvy8vKUmpqq8ePHa/ny5SooKFBGRsYZrQMAcGJMbwMA+LXCwkLl5ubKarV2eOzJJ5/UpEmTdMEFF0g6HHqee+45JScna+7cuXK5XGppaVFFRYUSExMlSSkpKbLZbGeyBADASXCkBwDg1+bNm3fc9qqqKn344YfexxsbG3XRRRcpIyNDw4YN05w5c1RQUKC0tDQFBwfLbD68Sw0NDVVtbW2X++FwOLq0vt1u7/I2/AVjc2KMzYkxNidmhLEh9AAAcBxr1qxRamqqgoKCJEkDBw7U73//e+/jt99+uzIzM5WamiqTydTuuccud0ZUVJQsFkun1rXb7YqJienyNvwBY3NijM2JMTYn1lfGxuVyfeuXR0xvQ49rbnH75bYBGMubb76pcePGeZdrampUVFTkXfZ4PDKbzQoJCVF9fb3c7sPvP06n87hT5YyI93sAfQVHetDjggIDlDyrxCfb3vD0RJ9sF4CxfP3112pqatLQoUO9bf3799dTTz2lyy+/XOeff75eeukljRkzRoGBgYqNjVVZWZmSk5NVXFys+Ph4H/b+zOH9HkBfwZEeAACOsWvXLoWFhbVrCwkJ0dy5c5Wenq6kpCR5PB7ddtttkqTc3FwVFhZq3Lhx+uijj/TAAw/4oNcAgBPhSA8AAJI2bdrk/fmSSy5RYWFhh3USExO9V2k7Wnh4uFatWnVa+wcA6D6O9AAAAAAwNEIPAAAAAEPzi9ATcVGkz7bt8tHVZbiqDQAAAHCYX5zTM/Cs/j69uowvts1VbQAAAIDD/OJIDwAAAAD/RegBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAB9zoluwh0TE+OzbQPovfzi5qQAAMBYggIDfHrjcQB9C0d6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoXUq9DQ0NGjChAnatWtXu/bVq1frlltu8S5XVlYqJSVFiYmJysrKUmtrqySppqZGaWlpSkpKUnp6uhobG3uwBAAA/Bf3jAGAkzvpfXq2bNmi7OxsVVVVtWv/z3/+o9/97ncaNmyYty0jI0OPP/64oqOjlZmZqcLCQqWmpiovL0+pqakaP368li9froKCAmVkZPR4MQAA+BvuVwMAJ3fSIz2FhYXKzc2V1Wr1tjU3NysnJ0f33Xeft2337t1qampSdHS0JCklJUU2m00tLS2qqKhQYmJiu3YAAAAAOBNOeqRn3rx5HdqefvppXX/99Tr//PO9bXv37lVoaKh3OTQ0VLW1tdq3b5+Cg4NlNpvbtXeVw+Ho8nOOiImJ6fZz+zK73d6tx06Vr8e7u7WdzjHpqxiTjhgTAAD6npOGnmO9++672rNnjx555BF98MEH3va2tjaZTCbvssfjkclk8v57tGOXOyMqKkoWi6XLz/NnJwofdrvd58HkdOpObUYfk+5gTDrq62PicrlO6QskAAD6qi6HntLSUu3YsUMTJ07UwYMHVVdXpwceeEAZGRlyOp3e9erq6mS1WhUSEqL6+nq53W4FBATI6XS2myoHAAAAAKdTl0PP/PnzvT9/8MEHWrZsmZ555hlJksVi8X4TWlJSovj4eAUGBio2NlZlZWVKTk5WcXGx4uPje6wAAAAAAPg2PXqfnvz8fM2fP19JSUk6ePCgpk6dKknKzc1VYWGhxo0bp48++kgPPPBAT24WAAAAAE6o00d6Nm3a1KHt8ssv1+WXX+5djoiIUFFRUYf1wsPDtWrVqm52EQAAAAC6r0eP9AAAAABAb0PoAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AgN9raGjQhAkTtGvXLknSI488ooSEBE2cOFETJ07U66+/LkmqrKxUSkqKEhMTlZWVpdbWVklSTU2N0tLSlJSUpPT0dDU2NvqsFgBAR4QeAIBf27JliyZPnqyqqipvm8Ph0OrVq1VSUqKSkhKNGTNGkpSRkaGcnBxt3LhRHo9HhYWFkqS8vDylpqbKZrMpKipKBQUFvigFAHAChB4AgF8rLCxUbm6urFarJOnQoUOqqalRZmamkpOTtXTpUrW1tWn37t1qampSdHS0JCklJUU2m00tLS2qqKhQYmJiu3YAQO9h9nUHAADwpXnz5rVbrqur0xVXXKHc3FwNGjRI06dPV1FRkUaOHKnQ0FDveqGhoaqtrdW+ffsUHBwss9ncrh0A0HsQegAAOMrQoUO1fPly7/Itt9yi4uJijRgxQiaTydvu8XhkMpm8/x7t2OXOcDgcXVrfbrdLkmJiYrq8LZy6I+Pf1/TVfp8JjM2JGWFsCD0AABzl008/VVVVlXe6msfjkdlsVlhYmJxOp3e9uro6Wa1WhYSEqL6+Xm63WwEBAXI6nd6pcl0RFRUli8XSqXXtdjthx8f64vjz/82JMTYn1lfGxuVyfeuXR5zTA+CUNLe4/XLbMC6Px6MnnnhCBw4cUEtLi9asWaMxY8YoPDxcFovF+41nSUmJ4uPjFRgYqNjYWJWVlUmSiouLFR8f78sSAADH4EgPgFMSFBig5FklPtn2hqcn+mS7MLaIiAhNmzZNkydPVmtrqxISEjRhwgRJUn5+vrKzs9XQ0KDIyEhNnTpVkpSbm6s5c+ZoxYoVGjJkiBYtWuTLEgAAxyD0AAAgadOmTd6f09LSlJaW1mGdiIgIFRUVdWgPDw/XqlWrTmv/AADdx/Q2AAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAMBJ+eqKmVypEz2BCxkAAADgpHx1tU6u1ImewJEeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AF6iC9PtOQkTwAAgBPjQgZAD/HVCZ4SJ3kCAAB8G470AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADC0ToWehoYGTZgwQbt27ZIkrVmzRhMmTFBycrIeeeQRNTc3S5IqKyuVkpKixMREZWVlqbW1VZJUU1OjtLQ0JSUlKT09XY2NjaepHAAAAABo76ShZ8uWLZo8ebKqqqokSTt37tTzzz+vl19+WevXr1dbW5v+/Oc/S5IyMjKUk5OjjRs3yuPxqLCwUJKUl5en1NRU2Ww2RUVFqaCg4PRVBAAAAABHOWnoKSwsVG5urqxWqyQpKChIubm5Cg4Olslk0oUXXqiamhrt3r1bTU1Nio6OliSlpKTIZrOppaVFFRUVSkxMbNcOAAAAAGfCSW9OOm/evHbL4eHhCg8PlyR9/fXXeumllzR//nzt3btXoaGh3vVCQ0NVW1urffv2KTg4WGazuV17Vzkcji4/54iYmJhuP7cvs9vt3XrsVPl6vLtb26mOSV+t+1R/pxHr7k3bAwAAp+6koedEamtrdeedd+r666/X5ZdfLrvdLpPJ5H3c4/HIZDJ5/z3ascudERUVJYvF0t3u+qUTfRi12+0+/6B6OnWnNiOMSU/3v6+MyZnsY18ZkxNxuVyn9AUSAAB9Vbeu3vbZZ59p0qRJ+tWvfqV77rlHkhQWFian0+ldp66uTlarVSEhIaqvr5fb7ZYkOZ1O71Q5AAAAADjduhx6GhoadMcdd+j+++/X7bff7m0PDw+XxWLxTv0oKSlRfHy8AgMDFRsbq7KyMklScXGx4uPje6j7AAAAAPDtuhx6ioqKVFdXp5UrV2rixImaOHGilixZIknKz8/X/PnzlZSUpIMHD2rq1KmSpNzcXBUWFmrcuHH66KOP9MADD/RoEQAAAABwIp0+p2fTpk2SpFtvvVW33nrrcdeJiIhQUVFRh/bw8HCtWrWqez0EAAAAgFPQrXN6AAAAAKCvIPQAAAAAMDRCDwAAAABDI/QAAAAAMDRCDwAAAHqt5hb3ad/GiW48fSa2jTOj01dvAwAAAM60oMAAJc8q8cm2Nzw90SfbRc/jSA8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAD8XkNDgyZMmKBdu3ZJktasWaMJEyYoOTlZjzzyiJqbmyVJy5Yt0zXXXKOJEydq4sSJeumllyRJNTU1SktLU1JSktLT09XY2OizWgAAHRF6AAB+bcuWLZo8ebKqqqokSTt37tTzzz+vl19+WevXr1dbW5v+/Oc/S5IcDocWLVqkkpISlZSUKC0tTZKUl5en1NRU2Ww2RUVFqaCgwFflAACOg9ADAPBrhYWFys3NldVqlSQFBQUpNzdXwcHBMplMuvDCC1VTUyPpcOh57rnnlJycrLlz58rlcqmlpUUVFRVKTEyUJKWkpMhms/msHgBAR2ZfdwCnR3OLW0GBAcd9LCYm5gz3BgB6r3nz5rVbDg8PV3h4uCTp66+/1ksvvaT58+ersbFRF110kTIyMjRs2DDNmTNHBQUFSktLU3BwsMzmw7vU0NBQ1dbWdrkfDoejS+vb7XZJvKf7ypHx72tOpd/++v9aX/1b9yQjjAGhx6CCAgOUPKvEJ9ve8PREn2wXAHpSbW2t7rzzTl1//fW6/PLLJUm///3vvY/ffvvtyszMVGpqqkwmU7vnHrvcGVFRUbJYLJ1a1263++0H0N7CV+P/bV9q4vTw99daX3m/cblc3/rlEaEHAIBjfPbZZ7rzzjt1yy236Pbbb5d0+GIFmzdv1g033CBJ8ng8MpvNCgkJUX19vdxutwICAuR0Or1T5YCexpeaQPdwTg8AAEdpaGjQHXfcofvvv98beCSpf//+euqpp/Tll1/K4/HopZde0pgxYxQYGKjY2FiVlZVJkoqLixUfH++r7gMAjoPQA6DPam5xn9HtHX14/0xvG2dOUVGR6urqtHLlSu+lqZcsWaKQkBDNnTtX6enpSkpKksfj0W233SZJys3NVWFhocaNG6ePPvpIDzzwgG+LAAC0w/Q2AH0W0zzQkzZt2iRJuvXWW3Xrrbced53ExETvVdqOFh4erlWrVp3O7gEATgFHegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYWqdCT0NDgyZMmKBdu3ZJkjZv3qzk5GQlJCRo8eLF3vUqKyuVkpKixMREZWVlqbW1VZJUU1OjtLQ0JSUlKT09XY2NjaehFAAAAADo6KShZ8uWLZo8ebKqqqokSU1NTcrMzFRBQYHKysrkcDhUXl4uScrIyFBOTo42btwoj8ejwsJCSVJeXp5SU1Nls9kUFRWlgoKC01cR/Fpzi7tbz4uJienhngAAAKC3MJ9shcLCQuXm5mr27NmSpK1bt2rYsGEaOnSoJCk5OVk2m00/+MEP1NTUpOjoaElSSkqKli5dqhtvvFEVFRVavny5t33KlCnKyMg4TSXBnwUFBih5VolPtr3h6Yk+2S4AAAC+3UlDz7x589ot7927V6Ghod5lq9Wq2traDu2hoaGqra3Vvn37FBwcLLPZ3K69qxwOR5efcwTf4sMf2O12n/xOf359nY4xBwAAPe+koedYbW1tMplM3mWPxyOTyXTC9iP/Hu3Y5c6IioqSxWLp8vMAf9HT4cNut/t1oOmMvjY+LpfrlL5AAgCgr+ry1dvCwsLkdDq9y06nU1artUN7XV2drFarQkJCVF9fL7fb3W59AAAAADgTuhx6Ro0apZ07d6q6ulput1ulpaWKj49XeHi4LBaLd7pHSUmJ4uPjFRgYqNjYWJWVlUmSiouLFR8f37NVAAAAAMAJdHl6m8Vi0YIFCzRjxgy5XC6NHj1aSUlJkqT8/HxlZ2eroaFBkZGRmjp1qiQpNzdXc+bM0YoVKzRkyBAtWrSoZ6sAAAAAgBPodOjZtGmT9+e4uDitX7++wzoREREqKirq0B4eHq5Vq1Z1s4sAAAAA0H1dnt4GAAAAAH0JoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAB+r6GhQRMmTNCuXbskSZs3b1ZycrISEhK0ePFi73qVlZVKSUlRYmKisrKy1NraKkmqqalRWlqakpKSlJ6ersbGRp/UAQA4PkIPAMCvbdmyRZMnT1ZVVZUkqampSZmZmSooKFBZWZkcDofKy8slSRkZGcrJydHGjRvl8XhUWFgoScrLy1NqaqpsNpuioqJUUFDgq3IAAMdB6AEA+LXCwkLl5ubKarVKkrZu3aphw4Zp6NChMpvNSk5Ols1m0+7du9XU1KTo6GhJUkpKimw2m1paWlRRUaHExMR27QCA3sPs6w4AAOBL8+bNa7e8d+9ehYaGepetVqtqa2s7tIeGhqq2tlb79u1TcHCwzGZzu/aucjgcXVrfbrdLkmJiYrq8LZy6I+N/pvH3PvN89bfuTYwwBoQeAACO0tbWJpPJ5F32eDwymUwnbD/y79GOXe6MqKgoWSyWTq1rt9v58OtjjL//8Pe/dV95v3G5XN/65RHT2wAAOEpYWJicTqd32el0ymq1dmivq6uT1WpVSEiI6uvr5Xa7260PAOg9CD0AABxl1KhR2rlzp6qrq+V2u1VaWqr4+HiFh4fLYrF4p3mUlJQoPj5egYGBio2NVVlZmSSpuLhY8fHxviwBAHAMprcBAHAUi8WiBQsWaMaMGXK5XBo9erSSkpIkSfn5+crOzlZDQ4MiIyM1depUSVJubq7mzJmjFStWaMiQIVq0aJEvSwAAHIPQAwCApE2bNnl/jouL0/r16zusExERoaKiog7t4eHhWrVq1WntHwCg+5jeBgAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI3QAwAAAMDQTin0lJSUaPz48Ro/frwWLlwoSdq8ebOSk5OVkJCgxYsXe9etrKxUSkqKEhMTlZWVpdbW1lPrOQAAAAB0QrdDz6FDhzRv3jytWrVKJSUl+uijj7Rp0yZlZmaqoKBAZWVlcjgcKi8vlyRlZGQoJydHGzdulMfjUWFhYY8VAQAAAAAn0u3Q43a71dbWpkOHDqm1tVWtra0KDg7WsGHDNHToUJnNZiUnJ8tms2n37t1qampSdHS0JCklJUU2m62nagAAAACAEzJ394nBwcG6//77NXbsWA0YMEA//vGPtXfvXoWGhnrXsVqtqq2t7dAeGhqq2traLm3P4XB0t6uKiYnp9nOBvsJut/vkd/rz6+t0jDkAAOh53Q4927Zt06uvvqq33npLgwYN0kMPPaSqqiqZTCbvOh6PRyaTSW1tbcdt74qoqChZLJbudhcwvJ4OH3a73a8DTWf0tfFxuVyn9AUSgMOaW9wKCgzwdTcAdEG3Q88777yjuLg4fec735F0eMra888/r4CA/3sTcDqdslqtCgsLk9Pp9LbX1dXJarWeQrcBHO107ID72gd6ADhTggIDlDyrxCfb3vD0RJ9sF+jruh16IiIi9NRTT+ngwYMaMGCANm3apFGjRmnDhg2qrq7W+eefr9LSUl1//fUKDw+XxWLxfnNcUlKi+Pj4nqwD8GvsgAEAAE6s26Hnqquu0r///W+lpKQoMDBQF198sWbMmKErr7xSM2bMkMvl0ujRo5WUlCRJys/PV3Z2thoaGhQZGampU6f2WBEAAAAAcCLdDj2SNG3aNE2bNq1dW1xcnNavX99h3YiICBUVFZ3K5gAAAACgy07p5qQAAAAA0NsRegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYmtnXHQAAoLd55ZVXtHr1au/yrl27NHHiRB06dEh2u10DBgyQJN17770aM2aMKisrlZWVpcbGRsXGxiovL09mM7tYoK9rbnErKDDA77ZtRLwjAwBwjBtvvFE33nijJGnHjh265557dO+99+rXv/61Vq9eLavV2m79jIwMPf7444qOjlZmZqYKCwuVmprqi64D6EFBgQFKnlXik21veHqiT7ZrVExvAwDgWzz66KOaOXOmBgwYoJqaGmVmZio5OVlLly5VW1ubdu/eraamJkVHR0uSUlJSZLPZfNtpAEA7HOkBAOAENm/erKamJo0dO1ZffvmlrrjiCuXm5mrQoEGaPn26ioqKNHLkSIWGhnqfExoaqtra2i5vy+FwdGl9u90uSYqJienytgD0DUde577WW/pxKgg9AACcwMsvv6zbbrtNkjR06FAtX77c+9gtt9yi4uJijRgxQiaTydvu8XjaLXdWVFSULBZLp9a12+2EHcAP9IbXeV95v3G5XN/65RHT2wAAOI7m5mZVVFTo2muvlSR9+umn2rhxo/dxj8cjs9mssLAwOZ1Ob3tdXV2Hc34AAL5F6AEA4Dg+/fRTXXDBBTrrrLMkHQ45TzzxhA4cOKCWlhatWbNGY8aMUXh4uCwWi3f6R0lJieLj433ZdQDAMZjeBgDAcXz55ZcKCwvzLkdERGjatGmaPHmyWltblZCQoAkTJkiS8vPzlZ2drYaGBkVGRmrq1Km+6jYA4DgIPQAAHMe4ceM0bty4dm1paWlKS0vrsG5ERISKiorOVNcAAF3E9DYAAAAAhkboAQAAAGBohB4AAAAAhnZKoWfTpk1KSUnR2LFj9fjjj0s6fCO35ORkJSQkaPHixd51KysrlZKSosTERGVlZam1tfXUeg4AAAAAndDt0PPll18qNzdXBQUFWr9+vf7973+rvLxcmZmZKigoUFlZmRwOh8rLyyVJGRkZysnJ0caNG+XxeFRYWNhjRQAAAADAiXQ79Lz++usaN26cwsLCFBgYqMWLF2vAgAEaNmyYhg4dKrPZrOTkZNlsNu3evVtNTU2Kjo6WJKWkpMhms/VUDQAAAABwQt2+ZHV1dbUCAwN19913a8+ePbr66qs1cuRIhYaGetexWq2qra3V3r1727WHhoaqtra2S9tzOBzd7apiYmK6/VwAOJEjN6MEAAC9W7dDj9vt1kcffaRVq1bprLPOUnp6uvr37y+TyeRdx+PxyGQyqa2t7bjtXREVFSWLxdLd7gJAj+trX6i4XK5T+gIJAIC+qtuh59xzz1VcXJxCQkIkSb/4xS9ks9kUEBDgXcfpdMpqtSosLExOp9PbXldXJ6vVegrdBgAAAIDO6fY5Pddcc43eeecdffPNN3K73fr73/+upKQk7dy5U9XV1XK73SotLVV8fLzCw8NlsVi8U0FKSkoUHx/fY0UAAAAAwIl0+0jPqFGjdOeddyo1NVUtLS268sorNXnyZH3/+9/XjBkz5HK5NHr0aCUlJUmS8vPzlZ2drYaGBkVGRmrq1Kk9VgQAnGnNLW4FBQacfEWDbBcAgL6s26FHkm644QbdcMMN7dri4uK0fv36DutGRESoqKjoVDYHAL1GUGCAkmeVnPHtbnh64hnfJgAAfd0p3ZwUAAAAAHo7Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAAPBqbnF7f46JifHZtnvSKd2nBwAAAICx+OpedNLpux8dR3oAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGJrZ1x0AAKA3uuWWW/T111/LbD68q5w7d64aGxs1f/58uVwujR07VjNnzpQkVVZWKisrS42NjYqNjVVeXp73eQAA3+MdGQCAY3g8HlVVVemtt97yhpempiYlJSVp1apVGjJkiKZPn67y8nKNHj1aGRkZevzxxxUdHa3MzEwVFhYqNTXVx1UAAI5gehsAAMf4/PPPJUm33367fvnLX2r16tXaunWrhg0bpqFDh8psNis5OVk2m027d+9WU1OToqOjJUkpKSmy2Ww+7D0A4Fgc6QEA4BjffPON4uLi9Jvf/EYtLS2aOnWq7rzzToWGhnrXsVqtqq2t1d69e9u1h4aGqra2tsvbdDgcXVrfbrdLkmJiYrq8LQB9w5HX+Znm6/eV01E3oQcAgGNceumluvTSS73LN9xwg5YuXdrug4DH45HJZFJbW5tMJlOH9q6KioqSxWLp1Lp2u93nH0oAnH7++jrvTt0ul+tbvzxiehsAAMf46KOP9N5773mXPR6PwsPD5XQ6vW1Op1NWq1VhYWHt2uvq6mS1Ws9ofwEA347QAwDAMerr6/Xkk0/K5XKpoaFB69at04MPPqidO3equrpabrdbpaWlio+PV3h4uCwWi3c6RklJieLj431cAQDgaExvAwDgGNdcc422bNmi6667Tm1tbUpNTdWll16qBQsWaMaMGXK5XBo9erSSkpIkSfn5+crOzlZDQ4MiIyM1depUH1cAADhaj4SehQsXat++fVqwYIE2b97MPQwAAH3eAw88oAceeKBdW1xcnNavX99h3YiICBUVFZ2hngEAuuqUp7e99957WrdunaTD9zDIzMxUQUGBysrK5HA4VF5eLknKyMhQTk6ONm7cKI/Ho8LCwlPdNAAAAACc1CmFnv3792vx4sW6++67JYl7GAAAAADodU5pfllOTo5mzpypPXv2SFKHexX05D0Munr/gqP56+X+ABiTr+7bAABAX9Xt0PPKK69oyJAhiouL09q1ayXphPcq6Il7GHTl/gUAYGTd/SLnZPcwAADAqLodesrKyuR0OjVx4kQdOHBABw8e1O7duxUQEOBdh3sYAAAAAPC1boeelStXen9eu3atPvzwQ+Xl5SkhIUHV1dU6//zzVVpaquuvv77dPQxiYmK4hwEAAACAM6ZHrxltsVi4hwEAAACAXqVHQk9KSopSUlIkcQ8DAAAAAL3LKd+nBwAAAAB6M0IPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAC9THOL29ddMBSzrzsAAAAAoL2gwAAlzyrxybY3PD3RJ9s9nTjSAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI3QAwAAAMDQCD0AAAAADI2bkwIAcBzLli3Ta6+9JkkaPXq0Zs+erUceeUR2u10DBgyQJN17770aM2aMKisrlZWVpcbGRsXGxiovL09mM7tYAOgteEcGAOAYmzdv1jvvvKN169bJZDLpzjvv1Ouvvy6Hw6HVq1fLarW2Wz8jI0OPP/64oqOjlZmZqcLCQqWmpvqo9wCAYzG9DQCAY4SGhmrOnDkKCgpSYGCgRowYoZqaGtXU1CgzM1PJyclaunSp2tratHv3bjU1NSk6OlqSlJKSIpvN5tsCAADtcKQHAIBjjBw50vtzVVWVXnvtNb300kv68MMPlZubq0GDBmn69OkqKirSyJEjFRoa6l0/NDRUtbW1Xd6mw+Ho0vp2u12SFBMT0+VtAUBvduT9rSedUug53nznzZs3a/78+XK5XBo7dqxmzpwpScx3BgD0OTt27ND06dM1e/Zsff/739fy5cu9j91yyy0qLi7WiBEjZDKZvO0ej6fdcmdFRUXJYrF0al273U7YAWBY3Xl/c7lc3/rlUbentx0937m4uFiffPKJSktLlZmZqYKCApWVlcnhcKi8vFzS4fnOOTk52rhxozwejwoLC7u7aQAATju73a5bb71Vs2bN0q9+9St9+umn2rhxo/dxj8cjs9mssLAwOZ1Ob3tdXV2Hc34AAL7V7dBzvPnOVVVVGjZsmIYOHSqz2azk5GTZbDbmOwMA+pQ9e/bonnvuUX5+vsaPHy/pcMh54okndODAAbW0tGjNmjUaM2aMwsPDZbFYvNMxSkpKFB8f78vuAwCO0e35Zceb7zxlypR285qtVqtqa2u1d+/eU57v3NW5zkdjCgAAIzkdc53R3vPPPy+Xy6UFCxZ42yZNmqRp06Zp8uTJam1tVUJCgiZMmCBJys/PV3Z2thoaGhQZGampU6f6qusAgOM45ZNqjp7vHBAQoKqqKu9jR+Y1t7W1nfJ8567MdQYAI+vuFzknm++M/5Odna3s7OzjPpaWltahLSIiQkVFRae7WwCAbjqlS1YfO9/52HnNTqdTVquV+c4AAAAAfKbboed4851HjRqlnTt3qrq6Wm63W6WlpYqPj2e+MwAAAACf6fb0thPNd16wYIFmzJghl8ul0aNHKykpSRLznQEAAAD4RrdDz7fNd16/fn2HNuY7AwAAAPCFUzqnBwAAAAB6O0IPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEM7o6Fnw4YNGjdunBISEvTSSy+dyU0DAHDasZ8DgN7JfKY2VFtbq8WLF2vt2rUKCgrSpEmTdPnll+sHP/jBmeoCAACnDfs5AOi9zljo2bx5s6644gqdc845kqTExETZbDbde++93/o8j8cjSWpubj6l7Z8zMOCUnt9dLpfLJ9v21XbZNttm26d/u9115H30yPsqetaZ3s8d/f+Cv70O2LZ/bdsfa/b3bXfHyfZxJs8Z2vs999xzOnjwoGbOnClJeuWVV7R161Y99thj3/q8+vp6bd++/Ux0EQD8woUXXqhBgwb5uhuGw34OAHzvRPu4M3akp62tTSaTybvs8XjaLZ/IwIEDdeGFFyowMLBT6wMAjs/j8ailpUUDBw70dVcMif0cAPjOyfZxZyz0hIWF6aOPPvIuO51OWa3Wkz6vX79+fCMJAD2kf//+vu6CYbGfAwDf+rZ93Bm7ettPf/pTvffee/r666916NAh/fWvf1V8fPyZ2jwAAKcV+zkA6L3O2JGe8847TzNnztTUqVPV0tKiG264QZdccsmZ2jwAAKcV+zkA6L3O2IUMAAAAAMAXzujNSQEAAADgTCP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AEA3cfFLoPc48nrkddkRY3NijM2JGW1sDBl6vvzyS1VWVqqlpUVut9vX3ekz2trafN2FXssoL/iewngc1tLS0m6ZccHpwn7t5A4ePChJMplMktinHY2xOTHG5sSMNjZn7OakZ8pf//pXLV68WGFhYQoJCVFkZKRuvPFGDRo0yNdd63UqKiq0fft2nXvuubrssssUGhqqtrY29etnyCzcZV988YXOOecctba2KiQkxO/HhvFor7y8XKtWrdL3v/99DR48WOnp6d4dA9CT2K+d3Ntvv63i4mKdc845ioyMVHx8vM477zy/f5+SGJtvw9icmBHHpm/2+gQOHjyo9evX6+mnn9bKlSv185//XDU1NXr22WfV0NDg6+71Kn//+9+Vm5urvXv36oMPPtCUKVO0c+dO9evXr88n+Z5QXl6uu+66S/n5+br11ltlt9v77Iu8JzAe7X3yySd68sknlZqaqrFjx2rdunXKycnxvnY44oOewn7t5LZv367c3FzdfPPNuvDCC1VdXa3HHntMNTU16tevn1+/HhmbE2NsTsyoY2OoTy0mk0lff/21ampqJElJSUm65ppr5HK5VFxczJSAo9jtdv3617/WzJkzlZOTo+TkZN14442qqqry6+Dj8XjkdDq1dOlSzZ07V3PnzlVaWppmzpyp8vJySX3/8G5XMB7H19bWpssuu0zXXnutLr30Uq1du1bbtm3To48+Kkkc8UGPYb92ci0tLbr66qsVFxen1NRU3XTTTRo+fLgWLlwop9Pp16/H1tZWXXnllYzNcbS0tGj06NGMzXEYdWwMFXoGDBigG264QX/729+0bds29evXT1dccYWioqJUUVHRYf69PwsKClJVVZV3+d5779Udd9yhe++9V3v37vXLb/E9Ho9MJpNCQkIUERGh7373u/J4PLr55ps1c+ZMZWVl6Z///Gef/pajKxiPEzvy+qmtrZUkBQcH649//KPee+89Pfvssz7uHYyE/dqJbdu2Te+9956+/vprvf3223rjjTckSd/73vd0/fXX67vf/a73yxl/e4/atm2bNm7cqPDwcNntdpWVlUlibKTDY/POO++osbFR77zzjl577TVJjI30f6+pAwcOaPPmzfrLX/4iyThjY7hPtldffbXOPvts/eUvf9G2bdsUEBCg6667TgcOHFB1dbWvu+dTO3fu1K5du3Tw4EHdcMMN2rBhg1avXi3p8P+86enpuvTSS7V161Yf99Q3jnx4MJlMampq0p///Gfvtxm/+tWv9D//8z/Ky8vT/v37++y3HF3BeLRXUVGhl156Sa+//rqGDRumK6+8UmlpaTp06JCkw8Fn7ty52r9/v287CsNhv9bRG2+8oYyMDL3wwgsqLy9XcnKyysrKvB/ILrjgAoWFhamyslKS/xx99Xg8am1t1SuvvKLf/va32rJlix566CFt2rRJb7/9tiT/HRtJ2rRpk2bNmqXly5dr165deuihh/TGG2/4/f830v+9plauXKkNGzbo0Ucf1VtvvWWosTHchQxCQkKUlpam1atX68UXX9RVV10lSfr666917rnn+rh3vvPGG29o+fLlCg8Pl8Vi0c9+9jO98MILuv/++yVJU6ZMkST169dPX331lS+76hN/+9vf9PLLL+vCCy/U9773PT3++OOaMGGCJOnhhx+WJKWmpupf//qXzGbDvWw6YDza+/vf/6758+drzJgx+vTTT7V06VK99NJLamho0C9/+UutXLlS559/vj7//HN98cUXam1t9YtxwZnBfq09p9OpF154Qc8884xGjBih5cuX629/+5vGjh2r4uJiNTY2aty4cRo0aJAOHDggl8uloKCgPvkhratMJpPMZrMiIiK0fft2bdq0SVarVT//+c9VUlKitrY2XXvttX45Ns3NzXrttdc0f/58XXLJJXI6nXI4HLrsssv06quvyuPx6Oqrr/bLsTl48KDWrl2rhQsX6kc/+pGmTZumyspKXXLJJYYaG0PulYcMGaI77rhD7777rkpKSnT22Wdr4cKF+s53vuPrrvlEQ0ODnn/+eeXk5GjkyJHatm2bFixYoGuuuUbPPPOMbr31VlVXVys4OFj//Oc/deutt/q6y2fU1q1b9dhjj2nWrFkKDAzU8uXLVVlZqQ0bNig5OVmSdN1116myslIOh0PNzc0+7vHpxXh0dOQcuJtvvlmStGTJEo0dO1Y2m01nn322srOz9Z3vfEc7d+7UggULCDzocezX/o/ZbFZLS4v3aPRNN92kf/zjH/rZz36mkJAQ5efn6+9//7s++OADPfvss7JYLD7u8Zk3ePBgBQcH6+KLL5bD4VBtba3q6uo0d+5c/eUvf9GWLVtUUFDgd2Pz5Zdf6sCBA2poaND999+vs88+WxaLRbW1tXr44Yd17bXXqqKiwu/G5si5gx9//LHOO+887dixQ2azWeecc45qamr00EMPKTExUR988EGfHhuTpy9OyuuC5uZmmUwmBQYG+rorPtPY2KgHH3xQc+fO1XnnnSdJ+vTTT5WTk6OpU6fq8ssv18aNG3Xw4EFde+21GjFihI97fGZ9/PHH2rhxo/cIRktLiyZMmKCrr75aM2fO1GOPPaaAgABVVVXpN7/5jUaOHOnjHp9ejEdHBQUFqq+v946JJC1btkybNm3SSy+9JKfTKZfLpeDgYA0ZMsSHPYU/8Pf9Wmtrq0pLS3XxxRdr+PDh2r59ux588EGtW7dOFotFdrtdAwcO1LnnnuuXR8Ikae/evXr55Zd13333KT8/X2vWrNHdd9+tO+64Q19++aUsFousVquvu3nGrV69Wnv27JHL5VJUVJSuu+46vf3223rzzTeVnJyssLAw9e/f3y/H5siMhgEDBuiaa67Rvffeq8rKSq1du1aXXnqpoqKi+vzYGO6cnmMFBQX57Y6hsbFRkjRw4EB9//vf10MPPaSmpiZJ0oUXXqgHHnhAb775pgYMGKC0tDTdddddfhd4pMNX4tq0aZP27t0rSQoMDNSGDRv0j3/8Q2VlZXr88cc1d+5cFRQU+MUHfMbjsJOdA3fvvfcqIiJC7733nr73ve9p5MiRBB6cEf68X5MOH+kZO3asLrjgAvXr109ut1smk0kWi0VFRUX63//9X4WHh/tt4JEOT1X/73//q9dee01/+9vfdN1112nLli167bXXNHTo0D79wfVU/PznP9f+/fv1ySefaPDgwZIOnzO3Z88eSYdP2PfXsfnZz36mwsJCRUZG6qKLLpIkXXTRRaqrq1NwcLAhxoY5GAZ15KZSZ599ti677DLddNNNCgwMVFZWlp544glZLBZFRkbqhRde0DfffKOBAwf6ustn1D//+U/t2LFDF1xwgS699FLdeOON+vWvf60XXnhBVqtVQUFBuu222/Sf//zHO2c1ODjYx70+fRiP9jp7DlxgYKCcTqcvuwr4paOn1/Tv31+XXHKJXn/9df35z3/WggUL/P7GrYMHD1ZbW5uWLl2qnJwcxcXFqbi4WJdddpmvu+ZTQ4YM0bRp0zRv3jxt2rRJkuRyuVRbW6uhQ4f6uHe+Fxwc7P0yLzg4WPX19aqurjbMF+KEHgP6z3/+o5ycHC1cuFA7d+7Uf/7zH73xxhuaNGmS3n//fd12222aP3++tmzZorq6Or87/6C8vFxPPPGE4uPjtXXrVi1fvlxZWVkymUyaOnWqXnjhBZ133nlyOp36z3/+o9bWVgUEBPS5E/Y6i/Foj3PggL4lICBA69at05YtW/Tb3/7WMB/QTkVAQIBuvfVW7d+/X1dccYUkacKECX63vz+eYcOGKTc3V6+99ppWrVqls88+W0899RRH6v+fn//85/rqq6+0YsUKBQUF6YknnlB4eLivu9UjDH9Oj785dOiQtm/frldffVVz586VJFVXV2vt2rWqqqrSQw89pMLCQu3evVv79+/X7NmzFRER4eNen1mLFy/Wj370IyUmJmr//v1au3atXn31VT3zzDP629/+5p2/+vHHH2vx4sWGnsIlSYsWLVJkZCTj8f9wDhzQtxw6dEiZmZm67777NHz4cF93p9c5cs81dHTkQjxBQUE+7knv4vF41NTUpLa2NkPNBCL0GMibb76pjz76SDfccIOmT5+uBx98UOPGjZN0+PyEwsJC/fCHP9R1112nlpYWeTwev3uhezwe5eXlyWw2Kzs7W9Lhc1heeOEFvfvuu1qxYoU+++wzmUwmBQcHG+bbjeNpbGzUwIED9eijj3qnPkqMhyQtXLhQDodDv//979W/f395PB69//77euWVV/TYY48ZaicAGEFzc7Pf7c8AdI3hL2TgL9566y0tW7ZMCQkJGjFihGbPnq23335b7733niRp+PDhCgsL08cffyzp8LkI/rSD2LVrl3bv3i2TyaT09HRt2bJFq1atknT4hM8JEyboO9/5jrZs2aKIiAj98Ic/NPQH/PLycr3wwguSpDvuuEMffvihXnrpJUn+OR5vv/22srKylJOTo+LiYt1000269NJLlZWVJZfLJZPJpMjISB08eFDffPONr7sL4Bj+tD8D0D2EHgPYtm2bnnjiCb344ovav3+/MjMz9dZbb6m5uVl/+MMfvHdhHjRokBoaGuRyueRPB/j++te/6oEHHlB2drby8vL09ttv6+GHH9a7777rDT6hoaHq16+fX9zd/K233lJ+fr6uvvpqSdLQoUP18MMPq7y83C/HY/v27crNzdXNN9+siIgI/ec//9HTTz+tn/zkJxoyZIhuu+02VVdX6+233/bLc+AAADAC9t4GEBwcrLa2Ni1btkzbt2/X/fffr3fffVc7duzQ/v37lZOTo8svv1z//Oc/+/RNpbqjvr5ef/rTn/TYY4/pvPPOk91u14YNG7Rr1y7deeedWrBggfeqZVu3blV6erqvu3xaVVZWauHChfrjH/+onTt36tFHH9XgwYP13e9+V9OmTdPChQv9ajykw/chuvrqqxUXF6e4uDjvOXCvvPKKHnroIZlMJi1ZskT79+/X448/rtDQUF93GQAAdBGhxwDOP/98LVy4UFlZWbrtttsUHR2tiy++WG+//bbKy8uVnp6u5uZmDRgwoM9fY72r3G632traFBISopCQEF155ZU6++yz9b//+7/68ssv9eyzz+qll15Sa2urnnnmGX3ve9/zdZdPqwMHDmjQoEF69913VVZWphtvvFHbt2/X5s2b1dLSomeffVarV6/2i/HYtm2b9u3bp9bWVr399tt644039Itf/ELDhg3Tddddp8LCQtntds2aNctvz4EDAMAouJCBQbS1tWnDhg0KDw9XbGyst33KlCl67LHH/O6KNv/+97917rnnymq1av78+aqrq9NvfvMbnXPOOWpoaFB5ebk++OAD7xXujO6TTz6R1WpVaGionn/+eS1ZskTLli1TfHy8Dh06pPfff19//etfNX/+fF939Yx44403tGTJEoWHh+v8889X//79VVNTo4kTJ2r06NGSpBdeeMF7NAwAAPRtnNNjEP369VNycrIuu+wyffDBB/rHP/6hN954Q998843+v//v//N1986YIxn+j3/8o+677z7V1dVpypQpGjx4sAoKCrR//34FBwfr8ssv1xdffKH//ve/Pu7x6XVkPFauXKkZM2boq6++0h133KH09HTvFcgGDBigqKgo/fe///WLG206nU698MILeuaZZ/Tss89q8ODBqqio0CWXXKLi4mKVlZVJ8t9z4AAAMCJCj4H069dPBw8e1CeffKInn3xSL7/8shYuXKiQkBBfd+2MOXIvgn79+unzzz/XI488oqCgIE2YMEFtbW3Kzc3VF198oYqKCjU1NRl+utKx4zFr1iw5nU6lp6crJiZG7777rurr67V161Y1NTX5xUn6ZrNZLS0tamlpkSTddNNNCg4O1s9+9jNdc801ys/P1yOPPKJly5Zp2rRpslgs3OMCAIA+jultBuR2u9XU1CSPx6Pg4GBfd8cnnnnmGf3yl7/UihUr9PXXX+uJJ56Qx+PRiy++qE8//VQej0cZGRm66KKLfN3VM+LIeDz33HPas2eP8vPzFRAQoBUrVugf//iHgoKClJub6xfj0draqtLSUl188cUaPny4tm/frgcffFDr1q2TxWKR3W7XwIEDde655+rcc8/1dXcBAEAPIPTAkHbs2KFhw4YpKChIs2bN0tdff62nnnpK5557rg4dOqR+/fr51VXsjh6PjIwM1dXV6cknn1RoaKj++9//auDAgRo0aJCvu3nGuFwumc1mBQQE6JNPPtHs2bP1l7/8RUVFRXr//feVm5vrV+MBAIDRMb0NhjRy5Ejv1LWnn35a5513nu644w599dVXGjBggF8FHqn9eDz11FOyWq2aNm2avvrqK4WFhfndB3yLxaKAgABJUv/+/XXJJZfo9ddf15///GdNmzbN78YDAACjI/TA0Nra2iRJCxYs0KhRo9TU1OTjHvnWkfFYuHChLr74Yr8fD0kKCAjQunXrtHjxYj311FO68MILfd0lAADQw5jeBsNra2tTv37k+yMYj/YOHTqkzMxM3XfffX53aXcAAPwFoQeA32tubjb8lfwAAPBnhB4AAAAAhsYcFwAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGiEHgAAAACGRugBAAAAYGhmX3cA6At++9vfat++fcrJydG1116rJUuWqKSkRBUVFZKkzz77TOHh4erfv78kac2aNd6fAQA4Vf/617/0+9//XkuXLj3hOrW1tVq8eLE++eQTmUwmWSwWTZ8+Xb/4xS/OYE+B3onQA3RTdna29+drr71W+fn5uvjii33YIwCAUV188cXfGni+/vprTZo0Sffff7/mz58vk8mkbdu26bbbbtOAAQN05ZVXnsHeAr0PoQd+q6ioSCtXrlS/fv00ePBgLVy4UJWVlVqxYoVaWlrUv39/Pfzww7r00ku79HsPHjyo0aNHq7CwUMOHD5ck3XrrrZoyZYreeOMNWSwWbdu2TV999ZWuvPJKZWdnKzAwUJ999pnmzZun/fv3y+1265ZbbtENN9xwOkoHAPQxH3zwgR577DE9+uijWrBggdra2iRJ06dPV2Jiov785z/rsssu03XXXed9TkREhJYuXaqzzz5b0uH93po1a9TS0qIDBw7orrvuUmpqqtauXavXX39d/fr1U3V1tfr376+FCxdqxIgRcjqdys3N1eeff65+/fpp0qRJmjp1qurr6zVv3jxt375dLS0tiouL0+zZs2U2mxUVFaWf//zn2rZtm/Lz8+VyufTkk0/q0KFDCgwM1AMPPKD4+HitXbtWGzdu1HPPPSdJ7ZY/+uij49YJdBehB37pyBvxunXrNGTIEP3pT3/SnDlz9PXXX+vFF1/U4MGDtWPHDt12223661//2qXffdZZZ+m6667TK6+8otmzZ+uLL75QVVWVrrnmGr3xxhvaunWrVq9ercDAQN1+++1as2aNJk2apPvuu09PPvmkIiMjVV9fr5tvvlk/+MEPFB0dfXoGAQDQ5/z2t7/VbbfdpvHjx2vbtm1as2aNEhMT5XA49LOf/azD+j/+8Y8lSY2NjXrllVf0u9/9ToMHD9bHH3+s2267TampqZKkiooKlZaWKiwsTI899ph+97vfaeHChcrLy9MFF1yggoIC1dfXa/LkyRo9erSeffZZRUZGasGCBXK73ZozZ45Wrlypu+66Sy0tLbrmmmu0ZMkS7du3T+PHj9eKFSs0atQo7dixQ1OmTFFRUVG36gS6i9ADv/Tee+/pqquu0pAhQyQdPhITGBiopUuX6tZbb/WuZzKZ9MUXX3T596empmrKlCmaOXOm1qxZoxtuuEEBAQGSpF/96lcaOHCgJGnixIl68803dcUVV+iLL75QZmam93c0NTXp3//+N6EHAOA1duxYzZ07V5s2bdJPf/pTPfjgg5IO7688Hs8Jnzdw4EA9++yzKi8vV1VVlbZt26aDBw96H4+MjFRYWJgk6Uc/+pFef/11SdLmzZuVkZEhSRo0aJBKS0slSW+//bb+9a9/ecNLU1NTu+3FxsZKkrZu3arvfe97GjVqlCRp5MiRuuyyy/Thhx/KZDJ1uU6guwg98EsBAQHt3mybmprU1tamuLg4PfPMM972PXv2yGq1et/8O2v48OH64Q9/qDfffFOlpaUqLCxst+0jPB6P+vXrJ7fbrUGDBqmkpMT7WF1dnQYNGtSN6gAARjVp0iRdc801evfdd/X3v/9dy5Ytk81mU3R0tD7++GNNmTKl3fovv/yyDh06pLFjx+rmm2/WTTfdpJiYGCUlJemtt97yrnf0xXeODlBms7nd/vLLL7/U4MGD1dbWpiVLlmjEiBGSpG+++abdemeddZYkye12dwg3Ho9Hra2tCgoKahfUWlpaTlqnxWLp9tjBv3HJavilyy+/XO+995727t0r6fBO4a233tK7776rzz77TJJUXl6uX/7ylx2+veqs1NRUPfnkk7rkkkt03nnnedtfe+01NTc3y+Vyad26dbrmmms0fPhw9e/f3xt69uzZowkTJsjhcJxipQAAI5k0aZIqKyuVkpKixx57TN98842cTqduvvlmffjhh1q/fr03SDgcDi1dulQXXnihHA6HQkJC9D//8z+66qqrvIHH7XZ/6/bi4uL06quvSpLq6+v161//WlVVVbrqqqv0pz/9SR6PR83NzUpPT9fq1as7PD86Olqff/65tm7dKknasWOHKioq9JOf/EQhISHasWOHXC6XWlpatHHjxpPWCXQXR3rgl374wx8qIyNDd955pyQpNDRU8+fP1z/+8Q89+OCD8ng8MpvNWrFihXcqWlddc801ys7O1qRJk9q19+/fX6mpqfrmm2+UmJio66+/Xv369VNBQYHmzZunP/zhD2ptbdX999+vmJiYU64VAGAcDz30kJ544gk988wzMplMuvfee3X++edLklatWqWnnnpKzz33nPr166cBAwZo3rx5uvLKK3Xo0CEVFRUpKSlJJpPJGzqqq6u/dXs5OTl69NFHlZycLI/Ho+nTpysqKkpZWVmaN2+ekpOT1dLSop/+9KfeferRQkJCtGTJEj322GNqamqSyWTS/PnzNXz4cA0dOlQ//vGPNXbsWIWGhuryyy/Xp59+etI6ge4web5tAiiAbvvnP/+p7OxslZaWeg/tz5kzRyNHjtQdd9zh494BAAD4D470AKfBww8/rA8//FCLFy/+1hM1AQAAcPpxpAcAAACAoXEhAwAAAACG1uunt7W1tamxsVGBgYFMEwKAU+DxeNTS0qKBAweqXz++8+ot2M8BwKk72T6u14eexsZGbd++3dfdAADDuPDCC7kHVC/Cfg4Aes6J9nG9PvQEBgZKOlxAUFBQt36Hw+FQVFRUT3bLZ4xUi2Sseqil9zJSPadSS3Nzs7Zv3+59X0XvcKr7OSP9/90V1O0//LFmibq76mT7uF4feo4c6g8KCjqlu/Aa6Q6+RqpFMlY91NJ7GameU62FKVS9S0/s54z0/3dXULf/8MeaJerujhPt45jUDQDwa5s2bVJKSorGjh2rxx9/XJK0efNmJScnKyEhQYsXL/aue+QO8YmJicrKylJra6skqaamRmlpaUpKSlJ6eroaGxt9UgsA4PgIPQAAv/Xll18qNzdXBQUFWr9+vf7973+rvLxcmZmZKigoUFlZmRwOh8rLyyVJGRkZysnJ0caNG+XxeFRYWChJysvLU2pqqmw2m6KiolRQUODLsgAAxyD0AAD81uuvv65x48YpLCxMgYGBWrx4sQYMGKBhw4Zp6NChMpvNSk5Ols1m0+7du9XU1KTo6GhJUkpKimw2m1paWlRRUaHExMR27QCA3qPXn9MDAMDpUl1drcDAQN19993as2ePrr76ao0cOVKhoaHedaxWq2pra7V379527aGhoaqtrdW+ffsUHBwss9ncrr2rHA5Ht+uw2+3dfm5fRt3+wx9rlqi7JxF6AAB+y+1266OPPtKqVat01llnKT09Xf379293IqzH45HJZFJbW9tx24/8e7TuXCwiKiqqWyfv2u12xcTEdPl5fR11+w9/rFmi7q5yuVzf+uURoQcA4LfOPfdcxcXFKSQkRJL0i1/8QjabTQEBAd51nE6nrFarwsLC5HQ6ve11dXWyWq0KCQlRfX293G63AgICvOsDAHoPzukBAPita665Ru+8846++eYbud1u/f3vf1dSUpJ27typ6upqud1ulZaWKj4+XuHh4bJYLN5pFyUlJYqPj1dgYKBiY2NVVlYmSSouLlZ8fLwvywIAHIMjPQAAvzVq1CjdeeedSk1NVUtLi6688kpNnjxZ3//+9zVjxgy5XC6NHj1aSUlJkqT8/HxlZ2eroaFBkZGRmjp1qiQpNzdXc+bM0YoVKzRkyBAtWrTIl2UBAI5B6AEA+LUbbrhBN9xwQ7u2uLg4rV+/vsO6ERERKioq6tAeHh6uVatWnbY+AgBODdPbAAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AANobnH36O/ryk3BenrbALom4qJIn22b1z9gTL58bZ+u9zSu3gYYQFBggJJnlfhk2xuenuiT7QI4bOBZ/Xn9A+hRRvxcwZEeAAAAAIbW6dCzcOFCzZkzR5K0efNmJScnKyEhQYsXL/auU1lZqZSUFCUmJiorK0utra2SpJqaGqWlpSkpKUnp6elqbGzs4TIAAAAA4Pg6FXree+89rVu3TpLU1NSkzMxMFRQUqKysTA6HQ+Xl5ZKkjIwM5eTkaOPGjfJ4PCosLJQk5eXlKTU1VTabTVFRUSooKDhN5QAAAABAeycNPfv379fixYt19913S5K2bt2qYcOGaejQoTKbzUpOTpbNZtPu3bvV1NSk6OhoSVJKSopsNptaWlpUUVGhxMTEdu0AAAAAcCac9EIGOTk5mjlzpvbs2SNJ2rt3r0JDQ72PW61W1dbWdmgPDQ1VbW2t9u3bp+DgYJnN5nbtXeVwOLr8nKPZ7fZTen5vYqRaJGPV46taunK1tdOhL/wN+0IfO8tItQAAcCZ8a+h55ZVXNGTIEMXFxWnt2rWSpLa2NplMJu86Ho9HJpPphO1H/j3ascudERUVJYvF0uXnSYc/IPj6Q2FPMVItkrHqMVItXdXb6zbS3+ZUanG5XKf8BRIAAH3Rt4aesrIyOZ1OTZw4UQcOHNDBgwe1e/duBQQEeNdxOp2yWq0KCwuT0+n0ttfV1clqtSokJET19fVyu90KCAjwrg8AAAAAZ8K3ntOzcuVKlZaWqqSkRPfdd5+uvfZa/eEPf9DOnTtVXV0tt9ut0tJSxcfHKzw8XBaLxTvtoqSkRPHx8QoMDFRsbKzKysokScXFxYqPjz/9lQEAAACAunFzUovFogULFmjGjBlyuVwaPXq0kpKSJEn5+fnKzs5WQ0ODIiMjNXXqVElSbm6u5syZoxUrVmjIkCFatGhRz1YBAAAAACfQ6dCTkpKilJQUSVJcXJzWr1/fYZ2IiAgVFRV1aA8PD9eqVatOoZsAAAAA0D2dvjkpAAAAAPRFhB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBoZl93AAAAX7rlllv09ddfy2w+vEucO3euGhsbNX/+fLlcLo0dO1YzZ86UJFVWViorK0uNjY2KjY1VXl6ezGazampqlJGRoa+++krDhw9Xfn6+Bg4c6MuyAABH6dSRniVLlmjcuHEaP368Vq5cKUl65JFHlJCQoIkTJ2rixIl6/fXXJR3eIaSkpCgxMVFZWVlqbW2VJNXU1CgtLU1JSUlKT09XY2PjaSoJAIDO8Xg8qqqqUklJife/H/7wh8rMzFRBQYHKysrkcDhUXl4uScrIyFBOTo42btwoj8ejwsJCSVJeXp5SU1Nls9kUFRWlgoICX5YFADjGSUPPhx9+qPfff1/r16/Xq6++qlWrVunzzz+Xw+HQ6tWrvTuJMWPGSGKHAADoOz7//HNJ0u23365f/vKXWr16tbZu3aphw4Zp6NChMpvNSk5Ols1m0+7du9XU1KTo6GhJUkpKimw2m1paWlRRUaHExMR27QCA3uOk09t+8pOf6MUXX5TZbFZtba3cbrf69++vmpoaZWZmqra2VmPGjNG9996rPXv2dNghLF26VDfeeKMqKiq0fPlyb/uUKVOUkZFxWosDAODbfPPNN4qLi9NvfvMbtbS0aOrUqbrzzjsVGhrqXcdqtaq2tlZ79+5t1x4aGqra2lrt27dPwcHB3ulxR9q7yuFwdKuGmJiYbj2vp9jtdr/cti/5Y93+WLPku7qN+L7SqXN6AgMDtXTpUv3xj39UUlKSWltbdcUVVyg3N1eDBg3S9OnTVVRUpJEjR562HUJ3dwZHGOnFYqRaJGPVw5tT79UX+thZRqrF1y699FJdeuml3uUbbrhBS5cubfea8ng8MplMamtrk8lk6tB+5N+jHbvcGVFRUbJYLN2owrd89f5jt9t9/t7nC/5Ytz/WLPlv3VL33ldcLte35oVOX8jgvvvu01133aW7775b7733nveojXT4JNDi4mKNGDHitO0QTmVnYKT/aYxUi2SseoxUS1f19rqN9Lc5lVpOtkPwRx999JFaWloUFxcn6fB+Kzw8XE6n07uO0+mU1WpVWFhYu/a6ujpZrVaFhISovr5ebrdbAQEB3vUBAL3HSc/p+eyzz1RZWSlJGjBggBISElRWVqaNGzd61/F4PDKbzZ3aIUhihwAA6BXq6+v15JNPyuVyqaGhQevWrdODDz6onTt3qrq6Wm63W6WlpYqPj1d4eLgsFov3SFtJSYni4+MVGBio2NhYlZWVSZKKi4sVHx/vy7IAAMc4aejZtWuXsrOz1dzcrObmZr355pv68Y9/rCeeeEIHDhxQS0uL1qxZozFjxrBDAAD0Kddcc41Gjx6t6667Ttdff72uv/56XXrppVqwYIFmzJihcePG6fvf/76SkpIkSfn5+Zo/f76SkpJ08OBBTZ06VZKUm5urwsJCjRs3Th999JEeeOABH1YFADjWSae3jR49Wlu3btV1112ngIAAJSQk6N5779XgwYM1efJktba2KiEhQRMmTJB0eIeQnZ2thoYGRUZGttshzJkzRytWrNCQIUO0aNGi01sZAACd8MADD3QIKXFxcVq/fn2HdSMiIlRUVNShPTw8XKtWrTpdXQQAnKJOndMzY8YMzZgxo11bWlqa0tLSOqzLDgEAAABAb9Kpm5MCAAAAQF9F6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIZG6AEAAABgaIQeAAAAAIbWqdCzZMkSjRs3TuPHj9fKlSslSZs3b1ZycrISEhK0ePFi77qVlZVKSUlRYmKisrKy1NraKkmqqalRWlqakpKSlJ6ersbGxtNQDgAAAAC0d9LQ8+GHH+r999/X+vXr9eqrr2rVqlXatm2bMjMzVVBQoLKyMjkcDpWXl0uSMjIylJOTo40bN8rj8aiwsFCSlJeXp9TUVNlsNkVFRamgoOD0VgYAAAAA6kTo+clPfqIXX3xRZrNZX331ldxut7755hsNGzZMQ4cOldlsVnJysmw2m3bv3q2mpiZFR0dLklJSUmSz2dTS0qKKigolJia2awcAAACA061T09sCAwO1dOlSjR8/XnFxcdq7d69CQ0O9j1utVtXW1nZoDw0NVW1trfbt26fg4GCZzeZ27QAAAABwupk7u+J9992nu+66S3fffbeqqqpkMpm8j3k8HplMJrW1tR23/ci/Rzt2+WQcDkeX1j+W3W4/pef3JkaqRTJWPb6qJSYmxifbPaIv/A37Qh87y0i1AABwJpw09Hz22Wdqbm7WRRddpAEDBighIUE2m00BAQHedZxOp6xWq8LCwuR0Or3tdXV1slqtCgkJUX19vdxutwICArzrd0VUVJQsFkuXnnOE3W73+YfCnmKkWiRj1WOkWrqqt9dtpL/NqdTicrlO+QskAAD6opNOb9u1a5eys7PV3Nys5uZmvfnmm5o0aZJ27typ6upqud1ulZaWKj4+XuHh4bJYLN5vIUtKShQfH6/AwEDFxsaqrKxMklRcXKz4+PjTWxkAAAAAqBNHekaPHq2tW7fquuuuU0BAgBISEjR+/HiFhIRoxowZcrlcGj16tJKSkiRJ+fn5ys7OVkNDgyIjIzV16lRJUm5urubMmaMVK1ZoyJAhWrRo0emtDAAAAADUyXN6ZsyYoRkzZrRri4uL0/r16zusGxERoaKiog7t4eHhWrVqVTe7CQAAAADd06mrtwEAAABAX0XoAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQAAAGBohB4AAAAAhkboAQBA0sKFCzVnzhxJ0ubNm5WcnKyEhAQtXrzYu05lZaVSUlKUmJiorKwstba2SpJqamqUlpampKQkpaenq7Gx0Sc1AACOj9ADAPB77733ntatWydJampqUmZmpgoKClRWViaHw6Hy8nJJUkZGhnJycrRx40Z5PB4VFhZKkvLy8pSamiqbzaaoqCgVFBT4rBYAQEeEHgCAX9u/f78WL16su+++W5K0detWDRs2TEOHDpXZbFZycrJsNpt2796tpqYmRUdHS5JSUlJks9nU0tKiiooKJSYmtmsHAPQeZl93AAAAX8rJydHMmTO1Z88eSdLevXsVGhrqfdxqtaq2trZDe2hoqGpra7Vv3z4FBwfLbDa3a+8qh8PRrf7HxMR063k9xW63++W2fckf6/bHmiXf1W3E9xVCDwDAb73yyisaMmSI4uLitHbtWklSW1ubTCaTdx2PxyOTyXTC9iP/Hu3Y5c6IioqSxWLpZiW+46sPR3a73ecfzHzBH+v2x5ol/61b6t77isvl+tYvjwg9AAC/VVZWJqfTqYkTJ+rAgQM6ePCgdu/erYCAAO86TqdTVqtVYWFhcjqd3va6ujpZrVaFhISovr5ebrdbAQEB3vUBAL0H5/QAAPzWypUrVVpaqpKSEt1333269tpr9Yc//EE7d+5UdXW13G63SktLFR8fr/DwcFksFu+0i5KSEsXHxyswMFCxsbEqKyuTJBUXFys+Pt6XZQEAjsGRHgAAjmKxWLRgwQLNmDFDLpdLo0ePVlJSkiQpPz9f2dnZamhoUGRkpKZOnSpJys3N1Zw5c7RixQoNGTJEixYt8mUJAIBjEHoAANDhq66lpKRIkuLi4rR+/foO60RERKioqKhDe3h4uFatWnXa+wgA6B6mtwEAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMj9AAAAAAwNEIPAAAAAEMzd2alZcuW6bXXXpMkjR49WrNnz9Yjjzwiu92uAQMGSJLuvfdejRkzRpWVlcrKylJjY6NiY2OVl5cns9msmpoaZWRk6KuvvtLw4cOVn5+vgQMHnr7K4DPNLW4FBQZ0at2YmBifbRsAAAD+4aShZ/PmzXrnnXe0bt06mUwm3XnnnXr99dflcDi0evVqWa3WdutnZGTo8ccfV3R0tDIzM1VYWKjU1FTl5eUpNTVV48eP1/Lly1VQUKCMjIzTVhh8JygwQMmzSnyy7Q1PT/TJdgEAANB7nXR6W2hoqObMmaOgoCAFBgZqxIgRqqmpUU1NjTIzM5WcnKylS5eqra1Nu3fvVlNTk6KjoyVJKSkpstlsamlpUUVFhRITE9u1AwAAAMDpdtIjPSNHjvT+XFVVpddee00vvfSSPvzwQ+Xm5mrQoEGaPn26ioqKNHLkSIWGhnrXDw0NVW1trfbt26fg4GCZzeZ27V3hcDi6tP6x7Hb7KT2/N+nttfT0lLWu8uX4+Grb/jzmndUX+thZRqoFAIAzoVPn9EjSjh07NH36dM2ePVvf//73tXz5cu9jt9xyi4qLizVixAiZTCZvu8fjkclk8v57tGOXTyYqKkoWi6VLzznCbrf7/ENhTzFSLaeLr8bHn/82vb1uI/1tTqUWl8t1yl8gAQDQF3Xq6m12u1233nqrZs2apV/96lf69NNPtXHjRu/jHo9HZrNZYWFhcjqd3va6ujpZrVaFhISovr5ebrdbkuR0OjucCwQAAAAAp8NJQ8+ePXt0zz33KD8/X+PHj5d0OOQ88cQTOnDggFpaWrRmzRqNGTNG4eHhslgs3qkXJSUlio+PV2BgoGJjY1VWViZJKi4uVnx8/GksCwAAAAAOO+n0tueff14ul0sLFizwtk2aNEnTpk3T5MmT1draqoSEBE2YMEGSlJ+fr+zsbDU0NCgyMlJTp06VJOXm5mrOnDlasWKFhgwZokWLFp2mkgAAAADg/5w09GRnZys7O/u4j6WlpXVoi4iIUFFRUYf28PBwrVq1qhtdBAAAAIDu69Q5PQAAAADQVxF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcAAACAoRF6AAAAABgaoQcA4NeWLFmicePGafz48Vq5cqUkafPmzUpOTlZCQoIWL17sXbeyslIpKSlKTExUVlaWWltbJUk1NTVKS0tTUlKS0tPT1djY6JNaAADHR+gBAPitDz/8UO+//77Wr1+vV199VatWrdK2bduUmZmpgoIClZWVyeFwqLy8XJKUkZGhnJwcbdy4UR6PR4WFhZKkvLw8paamymazKSoqSgUFBb4sCwBwDEIPAMBv/eQnP9GLL74os9msr776Sm63W998842GDRumoUOHymw2Kzk5WTabTbt371ZTU5Oio6MlSSkpKbLZbGppaVFFRYUSExPbtQMAeg+zrzsAAIAvBQYGaunSpfrjH/+opKQk7d27V6Ghod7HrVaramtrO7SHhoaqtrZW+/btU3BwsMxmc7v2rnI4HN3qf0xMTLee11PsdrtfbtuX/LFuf6xZ8l3dRnxfIfQAAPzefffdp7vuukt33323qqqqZDKZvI95PB6ZTCa1tbUdt/3Iv0c7drkzoqKiZLFYul+Ej/jqw5Hdbvf5BzNf8Me6/bFmyX/rlrr3vuJyub71yyOmtwEA/NZnn32myspKSdKAAQOUkJCgDz74QE6n07uO0+mU1WpVWFhYu/a6ujpZrVaFhISovr5ebre73foAgN6D0AMA8Fu7du1Sdna2mpub1dzcrDfffFOTJk3Szp07VV1dLbfbrdLSUsXHxys8PFwWi8U77aKkpETx8fEKDAxUbGysysrKJEnFxcWKj4/3ZVkAgGMwvQ0A4LdGjx6trVu36rrrrlNAQIASEhI0fvx4hYSEaMaMGXK5XBo9erSSkpIkSfn5+crOzlZDQ4MiIyM1depUSVJubq7mzJmjFStWaMiQIVq0aJEvywIAHKNToWfZsmV67bXXJB3eQcyePVubN2/W/Pnz5XK5NHbsWM2cOVPS4XsYZGVlqbGxUbGxscrLy5PZbFZNTY0yMjL01Vdfafjw4crPz9fAgQNPX2UAAHTCjBkzNGPGjHZtcXFxWr9+fYd1IyIiVFRU1KE9PDxcq1atOm19BACcmpNOb9u8ebPeeecdrVu3TsXFxfrkk09UWlrKPQwAAAAA9AknDT2hoaGaM2eOgoKCFBgYqBEjRqiqqop7GAAAAADoE046vW3kyJHen6uqqvTaa69pypQpZ/weBt29f8ERRrq+e2+vxdeXV/THe0b485h3Vl/oY2cZqRYAAM6ETl/IYMeOHZo+fbpmz56tgIAAVVVVeR87E/cwOJX7FxjpOudGquV04Z4RZ15vr9tIf5tTqeVk9zAAAMCoOnXJarvdrltvvVWzZs3Sr371qw73KuAeBgAAAAB6q5OGnj179uiee+5Rfn6+xo8fL0kaNWoU9zAAAAAA0CecdHrb888/L5fLpQULFnjbJk2apAULFnAPAwAAAAC93klDT3Z2trKzs4/7GPcwAAAAANDbdeqcHgAAAADoqwg9AAAAAAzNL0JPxEWRPtt2c4vbZ9sGAAAA0IX79PRlA8/qr+RZJT7Z9oanJ/pkuwAAAAAO84sjPQAAAAD8F6EHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYGqEHAAAAgKERegAAAAAYWqdCT0NDgyZMmKBdu3ZJkh555BElJCRo4sSJmjhxol5//XVJUmVlpVJSUpSYmKisrCy1trZKkmpqapSWlqakpCSlp6ersbHxNJUDAAAAAO2dNPRs2bJFkydPVlVVlbfN4XBo9erVKikpUUlJicaMGSNJysjIUE5OjjZu3CiPx6PCwkJJUl5enlJTU2Wz2RQVFaWCgoLTUw0AAAAAHOOkoaewsFC5ubmyWq2SpEOHDqmmpkaZmZlKTk7W0qVL1dbWpt27d6upqUnR0dGSpJSUFNlsNrW0tKiiokKJiYnt2gEAAADgTDCfbIV58+a1W66rq9MVV1yh3NxcDRo0SNOnT1dRUZFGjhyp0NBQ73qhoaGqra3Vvn37FBwcLLPZ3K69qxwOR5efc0RMTEy3n9sT7HZ7r/59Pc1o490Xtu3PY95ZfaGPnWWkWgAAOBNOGnqONXToUC1fvty7fMstt6i4uFgjRoyQyWTytns8HplMJu+/Rzt2uTOioqJksVi6/LzeoCc/kNrtdp9/wO3tfDU+/vy36e11G+lvcyq1uFyuU/oCCQCAvqrLV2/79NNPtXHjRu+yx+OR2WxWWFiYnE6nt72urk5Wq1UhISGqr6+X2+2WJDmdTu9UOQAAAAA43bocejwej5544gkdOHBALS0tWrNmjcaMGaPw8HBZLBbvtIuSkhLFx8crMDBQsbGxKisrkyQVFxcrPj6+Z6sAAAAAgBPo8vS2iIgITZs2TZMnT1Zra6sSEhI0YcIESVJ+fr6ys7PV0NCgyMhITZ06VZKUm5urOXPmaMWKFRoyZIgWLVrUs1UAAAAAwAl0OvRs2rTJ+3NaWprS0tI6rBMREaGioqIO7eHh4Vq1alU3uwgAwOmzbNkyvfbaa5Kk0aNHa/bs2dq8ebPmz58vl8ulsWPHaubMmZIO348uKytLjY2Nio2NVV5ensxms2pqapSRkaGvvvpKw4cPV35+vgYOHOjLsgAAR+ny9DYAAIxi8+bNeuedd7Ru3ToVFxfrk08+UWlpqTIzM1VQUKCysjI5HA6Vl5dL4n50ANBXEXoAAH4rNDRUc+bMUVBQkAIDAzVixAhVVVVp2LBhGjp0qMxms5KTk2Wz2bgfHQD0YV0+pwcAAKMYOXKk9+eqqiq99tprmjJlSrv7zlmtVtXW1mrv3r298n50vr4cuz/eG83X/LFuf6xZ4v5/PYnQAwDd0NziVlBgwBnfbsRFkWd8m/5gx44dmj59umbPnq2AgABVVVV5Hztyv7m2tjbuR3cc3BvtzPLHuv2xZsl/65a6975ysnvREXoAoBuCAgOUPKvkjG93w9MTz/g2jc5ut+u+++5TZmamxo8frw8//LDdfeeO3F+uM/ejCwgI4H50ANALcU4PAMBv7dmzR/fcc4/y8/M1fvx4SdKoUaO0c+dOVVdXy+12q7S0VPHx8dyPDgD6MI70AAD81vPPPy+Xy6UFCxZ42yZNmqQFCxZoxowZcrlcGj16tJKSkiRxPzoA6KsIPQAAv5Wdna3s7OzjPrZ+/foObdyPDgD6Jqa3AQAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQyP0AAAAADA0Qg8AAAAAQ+tU6GloaNCECRO0a9cuSdLmzZuVnJyshIQELV682LteZWWlUlJSlJiYqKysLLW2tkqSampqlJaWpqSkJKWnp6uxsfE0lAIAAAAAHZ009GzZskWTJ09WVVWVJKmpqUmZmZkqKChQWVmZHA6HysvLJUkZGRnKycnRxo0b5fF4VFhYKEnKy8tTamqqbDaboqKiVFBQcPoqAgAAAICjnDT0FBYWKjc3V1arVZK0detWDRs2TEOHDpXZbFZycrJsNpt2796tpqYmRUdHS5JSUlJks9nU0tKiiooKJSYmtmsHAAAAgDPBfLIV5s2b12557969Cg0N9S5brVbV1tZ2aA8NDVVtba327dun4OBgmc3mdu1d5XA4uvycI2JiYrr93J5gt9t79e/raUYb776wbX8e887q6T76csz7wngDANCbnDT0HKutrU0mk8m77PF4ZDKZTth+5N+jHbvcGVFRUbJYLF1+Xm/Qkx+O7Ha7zz/g9na+Gh9//tv09rqN9rfpbi0ul+uUvkACAKCv6vLV28LCwuR0Or3LTqdTVqu1Q3tdXZ2sVqtCQkJUX18vt9vdbn0AAAAAOBO6HHpGjRqlnTt3qrq6Wm63W6WlpYqPj1d4eLgsFot32kVJSYni4+MVGBio2NhYlZWVSZKKi4sVHx/fs1UAAAAAwAl0eXqbxWLRggULNGPGDLlcLo0ePVpJSUmSpPz8fGVnZ6uhoUGRkZGaOnWqJCk3N1dz5szRihUrNGTIEC1atKhnqwAAAACAE+h06Nm0aZP357i4OK1fv77DOhERESoqKurQHh4erlWrVnWziwAAAADQfV2e3gYAAAAAfQmhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAAAAGBqhBwAAAIChEXoAAH6voaFBEyZM0K5duyRJmzdvVnJyshISErR48WLvepWVlUpJSVFiYqKysrLU2toqSaqpqVFaWpqSkpKUnp6uxsZGn9QBADg+Qg8AwK9t2bJFkydPVlVVlSSpqalJmZmZKigoUFlZmRwOh8rLyyVJGRkZysnJ0caNG+XxeFRYWChJysvLU2pqqmw2m6KiolRQUOCrcgAAx0HoAQD4tcLCQuXm5spqtUqStm7dqmHDhmno0KEym81KTk6WzWbT7t271dTUpOjoaElSSkqKbDabWlpaVFFRocTExHbtAIDew+zrDgAA4Evz5s1rt7x3716FhoZ6l61Wq2prazu0h4aGqra2Vvv27VNwcLDMZnO79q5yOBzd6n9MTEy3ntdT7Ha7X27bl/yxbn+sWfJd3UZ8XyH0AABwlLa2NplMJu+yx+ORyWQ6YfuRf4927HJnREVFyWKxdL/jPuKrD0d2u93nH8x8wR/r9seaJf+tW+re+4rL5frWL4+Y3gYAwFHCwsLkdDq9y06nU1artUN7XV2drFarQkJCVP//t3fn0VGVZxzHv5lkMmCWQshCSKXQYKRGDRSOBmmTUntiXOtRXEprailCS2sVSEXEsGlNyCIFQTBoeypQetRiwZiDEGSx6vEUaA1VcEtiETGZZEDIOlmmf3BmDihL9pt58/v8xVzu5D7P3Pve933m3vvOyZO0traesb6IiPQdKnpEREROk5SURHl5OZ9++imtra0UFRWRkpJCXFwcDofDd9vF5s2bSUlJwW63M378eIqLiwH4xz/+QUpKipUpiIjIV+j2NhERkdM4HA5ycnK4//77aWpqIjU1lfT0dADy8/N59NFHqa2tJTExkYyMDAAWLlzIww8/zOrVq4mNjeXJJ5+0MgUREfkKFT0iIiLA66+/7vv3hAkT2LJly9fWGT16NC+99NLXlsfFxbFu3boejU9ERDpPt7eJiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRuvQ7Pffccw8ul4ugoFN/ZsmSJdTV1ZGdnU1TUxPXX389s2bNAuDgwYPMnz+furo6xo8fz+LFi33vExERERER6Smdrjo8Hg8VFRXs3LnTV7w0NjaSnp7OunXriI2NZcaMGezevZvU1FR+//vf8/jjjzNmzBgeeeQRXnjhBaZMmdJtiYiIiIiIiJxNp29vKysrA2Dq1KnccsstrF+/ntLSUr71rW9x8cUXExQUxM0338zWrVs5cuQIjY2NjBkzBoDbbruNrVu3dksCIiIiIiIi59PpKz0nTpxgwoQJZGVl0dzcTEZGBtOmTSMqKsq3TnR0NJWVlVRVVZ2xPCoqisrKyg5t77///W9nQ2XcuHGdfm932LdvX5/+e93NtM/bH7bdnz/z9uruGK38zP3h8xYREelLOl30jB07lrFjx/peT548mRUrVpwxEPB4PAQEBNDW1kZAQMDXlnfE5ZdfjsPh6Gy4lurOwdG+ffssH+D2dVZ9Pv153/T1vE3bN53NpampqUtfIImIiPirTt/etnfvXt5++23fa4/HQ1xcHE6n07fM6XQSHR3N0KFDz1heXV1NdHR0ZzctIiIiIiLSbp0uek6ePElubi5NTU3U1tby8ssvM3v2bMrLy/n0009pbW2lqKiIlJQU4uLicDgcvlsyNm/eTEpKSrclISIiIiIici6dvr1t0qRJvPvuu9x66620tbUxZcoUxo4dS05ODvfffz9NTU2kpqaSnp4OQH5+Po8++ii1tbUkJiaSkZHRbUmIiIiIiIicS5d+KOfBBx/kwQcfPGPZhAkT2LJly9fWHT16NC+99FJXNiciIiIiItJhnb69TURERERExB+o6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaOp6BEREREREaP1atHzyiuvcMMNN5CWlsaGDRt6c9MiIiI9Tv2ciEjfFNRbG6qsrGTZsmVs2rSJ4OBg7r77bq6++mpGjRrVWyGIiIj0GPVzIiJ9V68VPW+99RbJyckMGjQIgOuuu46tW7fy29/+9rzv83g8ALjd7i5tf1BIYJfe31lNTU1+8Te7m0mft79sv79+5u3VE3Fa8Zl3JQ/vedR7XpXuZWU/11/bv9Xbt0p/zLs/5gwaV3TEhfq4AE8v9X7PPPMM9fX1zJo1C4AXX3yR0tJSHnvssfO+7+TJk3z44Ye9EaKISL+QkJBAWFiY1WEYR/2ciIj1ztXH9dqVnra2NgICAnyvPR7PGa/PJSQkhISEBOx2e7vWFxGRs/N4PDQ3NxMSEmJ1KEZSPyciYp0L9XG9VvQMHTqUvXv3+l47nU6io6Mv+D6bzaZvJEVEusmAAQOsDsFY6udERKx1vj6u12Zvu+aaa3j77bdxuVw0NDSwbds2UlJSemvzIiIiPUr9nIhI39VrV3piYmKYNWsWGRkZNDc3M3nyZK688sre2ryIiEiPUj8nItJ39dpEBiIiIiIiIlbo1R8nFRERERER6W0qekRERERExGgqekRERERExGgqekRERERExGgqekRERERExGj9pugxZZK6pqYmq0OQCzDlWDMlDzCz3Zi0f6TrdDz0L62trVaHIOJ3jC96jh49SkNDA3V1dVaH0mVvvfUWf/3rX2lqaqKtrc3qcLqVCR12VVUVbW1tBAQEWB1Kl5jUZsC8dmPa/pGu6a/HQ3l5OU6nk88//9zqUHpVaWkpDQ0NBAYG9qvCp6ysjKqqKj777DOrQ+k1ZWVlOJ1OKisrrQ7FUt05Puy1Hye1wo4dOygsLGTYsGGEhYVx7bXXkpqaanVYnbJr1y4KCgrIy8vD4XBYHU6Xvffeexw7dozIyEji4+Ox2+20tbVhs/lnHb5r1y6KioqYO3cuUVFRwKmG6m8FkEltBsxrN6btH+ma/no87N69m+XLlzNq1ChOnDjBfffdx7hx46wOq8e1tbWxfPlyWlpaKCwsxOFw0NraSmBgoNWh9ajdu3eTn59PXFwcEydOZMqUKdhsNr/rXzti9+7dLFu2jEsuuQS73c4DDzxAdHS00Tl79eT40Niip6qqiieffJI//OEPhIWFceDAAXJycmhoaCA9Pd3q8DrkwIEDLF68mOeeew6Xy8WyZcsICQkhKSmJq6++2urwOmzHjh0UFBSQmJiIzWajsbGRnJwcBg4c6JeFz44dO1i1ahU5OTlERUXR2tpKQEAANpvNr/Ixqc2Aee3GtP0jXdNfj4fDhw+Tm5tLbm4uUVFRvPjii+zbt49x48b51fm2MwICAoiOjubNN9/kF7/4BYWFhYSGhlodVo9yuVysXLmShQsXMn78eFwuF263m/r6eoYMGWJ1eD2isrKS/Px8FixYQGxsLAUFBXg8Hlwul7E5e/X0+NDYoicoKIj4+HjGjBkDQHx8PAMGDGDVqlWEhITw/e9/39oAO+Do0aNcddVVHDx4kPXr13PddddRXV3NY489xuzZs/nhD39odYjt5vF4eO2115g/fz4TJ07k888/5+mnn2b69OkUFhYycOBAv7pCcuTIEZ566imysrL47LPPyM3NJTw8nNDQUObNm+dX+ZjUZsCsdgPm7R/pmv56PNTX1xMTE0NiYiIAkZGR7Ny5E8DoggdOFT1JSUlce+21vPPOO8ycOZOZM2cSHBzMd7/7XavD6xHBwcFERET4Cp7Zs2czZMgQnE4nP/vZz0hLS7M6xG5nt9tJSEjgkksuoaGhgXfeeYcnnniCDz/8kPvuu4/bb7/d6hB7RG+MD409Q0RERFBTU8OiRYt8y9LS0vj5z3/O9u3bqaur85vnSNLS0ggMDCQ7O5uFCxdy7733kpmZyYwZM9i2bRu1tbV+k4vH46GxsRGn0wnAsGHDmDdvHiNHjiQrK4vm5ma/KBC87HY78fHxlJSU8Pe//53MzExuu+02bDYbc+bM8at8TGozYFa7AfP2j3RNfz0eRo4cSWRkJB9//DEAgwYNoqWlxff/x44dsyq0XnHRRRexf/9+5s+fj91uZ9q0adTU1ABmTm4QGhrKiRMnWLp0KatXr+amm24iMzOTO++8kz//+c988cUXVofY7SIiIqirq2PevHnccMMN3HvvveTl5ZGVlcXKlSspKyuzOsQe0RvjQyOLHm/DX7p0KUeOHGHFihXAqW+BrrjiCr788kvsdrtfDEa9uTzxxBMkJyefcXL3fgvgcDj8Ihc4tQ9uueUW1qxZw7/+9S8ABg4cyNSpU/F4PFRUVFgbYAdFR0eTkZHBK6+8QlJSEqNHj+aaa67hN7/5DXa7nfLycqtD7BAT2szpTGk3Jp3TpOv66/HQ2tpKcHAwWVlZjBw5Ejh19cP7vN7LL79Mbm4ujY2NVobZI7yTsAwfPpyLLrqI8vJyXC4XEyZMYPXq1dTV1Rn3bI/3vP3www/jcrl4//33+fGPf0xsbCypqanExsYSHBxscZTdy9u216xZw5IlS0hPT2f69Ok4HA4mTpxIcnIyAwYMsDjKntEb40Njip7Dhw9z8OBBmpubfcuGDh3Kr371Kw4cOMCCBQsA+Oijj6iurqa+vt6qUC/obLkA5OXlcfnll/sOhrKyMo4dO9anc/kqj8fDj370I+655x5WrlzJ3r17sdlsjBgxArfbTXV1tdUhdojH4yEpKYm8vDyuvPJK4FTDjYqKoqWlhS+//NLiCM/t0KFD/POf/6SiogK32w2c+mbFH9sMnD0f8N92U1FRccZMTQBxcXF+u3+ka0zq4zribHmHhIT42kRtbS0jRoxg+/bt/OUvf2HatGlGDApPz7u1tdV3615CQgJvvPEG06ZN44EHHmDt2rWMGTPGmCtcp+ftLdpHjhzJ9773PY4ePUpBQQEAe/bsoaKiwoirW+ca80VFRXHkyBGWLl0KQHFxMR988IFxxa1Xb4wPAzwGXP/etm0by5YtY+jQoURERJCYmMjkyZMJDw+npaUFp9PJ3LlziYyMpKKiguzsbC699FKrwz6rs+Vyxx13EBYWRktLCzU1NTz00EN4PB5qamooKChg9OjRVod9Tu+//z6RkZFER0efsfz48eO8+uqrPP/88/zyl7+kra2NjRs38vTTTxMXF2dRtBd2rnzg1DdxRUVFhIaG0tjYyJo1a3jmmWeIjY21INLzKykpYfny5QwfPhyHw0FaWprv4WePx8MXX3zhN20Gzp2Pdwrxqqoqv2o3JSUlrFixgsGDB2O321m7dq1vAOBv5zTpOpP6uI44X3/onbVs06ZNLFiwgKSkJBYvXsyoUaOsDrvLzpd3Q0MDzz33HMnJyYwfPx7AmAkcvpr3ZZddxh133EF4eDh1dXUcOHCA/Px8oqKiqKqqIjs7m4SEBKvD7pLz7Ws4NZNZVlYWQ4YM8U1w4O85e1kxPvT7oqe+vp6HHnqImTNnctlll1FcXMz+/ftxOBxMnz6db3zjG7513W43bre7z852cr5cZsyYQXh4OIDvnsfQ0FAGDx5scdRn533YLDMzk6NHj/LHP/7RN5Xz6Xbt2sXrr7+OzWbjJz/5SZ/tqNuTj9vt5rXXXmPDhg3ExMTw61//uk8OrJ1OJ7Nnz2bRokXEx8ezatUqDh48yMqVK7+2bl9vM9D+fPyh3cDX87n99tuZOXMml156KYMHDyYkJMS3rj/sH+kak/q4jmhvf/i///2POXPmkJ2dbUTB05797Xa7fbd1+ctEORfSkePc+zymtzDwV+3NubW1lerqahwOB4MGDbI26G5g5fjQ778aCAgIwOVy+X6gLD09nUmTJtHU1MSWLVsA2LdvHy6Xi+Dg4D7dGZwvl82bNwOwf/9+Ghsbufjii/v0wM17ErbZbHz00UfMnTvX93Da6XX2D37wA5YsWcKiRYv6bMED58/HKzg4mJtvvpn169eTn5/fJwseODXrU3Nzs+9S+p133snx48epra31rfPuu+9SU1PT59sMtC+f0tJS6uvr+3y7gVP51NfXExoaSk1NDYcPH2bjxo08/vjjPPvsswD8+9//9otzmnSdSX1cR7SnP/zPf/5DUFAQf/rTn4woeKB9+/u9997D5XL51jdBR47z0NBQvy94oH0579+/n5MnTxITE2NEwQPWjg/9vugZOHAgkydPZs+ePRw6dAibzUZycrLvHn6Xy8XGjRu/dq9kX9SeXLy/LO8vhg0bxt/+9jeioqKYM2cOTqfTd8CXlJTwxhtv+NUMQ2fLx6ukpIQ9e/YQFBSE3W63MMrzCwsL4+677/b94JfL5aKmpsa3Xw4dOsTatWt9D872de3Jp7Cw0G/u/Q4LCyMzM5OYmBg++eQTFi5cyLPPPstdd93FJ598wscff8yGDRv84pwmXWdSH9cR7cl73bp12O12IwbAXu3J28T23x+PcxPHfB1hxfjQ74seOFUNhoeH8+qrr3Lo0CECAwO59dZbOX78OM3NzeTm5hITE2N1mO1iUi4AN954I9/85jdZunQpMTExZxQK3itW/vRN1YXyGT58uMURXlhQUBDXX389I0aMwGaz0dLSQmBgICEhIWzatIkXXniBxYsXn/Vyc19kYj4TJkwA4KqrruLGG28EYNKkSbjdbhwOB/n5+X51HpCuMa1faK8L5Z2Xl+c37bojtL/7T979MWcvK8aHRhQ9ERER/PSnP6WtrY3nn3+e4uJiiouLOXbsGIGBgX71gJ9JucCp6YG99x7n5eURFxfH9OnTcblc3HTTTYwYMcLaADvIlHwcDodvBpgBAwZwxRVXsH37dtavX89dd93ld7/6bFo+Xs3NzXzwwQeUlpayc+dOqqqqfNPzSv9hWr/QXspbeZued3/M2cuK8ZTfT2RwOpfLxZtvvklRURHh4eFMnTqV73znO1aH1Skm5QJnzi6zYMECZsyY0adnabsQk/KpqKggPT2db3/72zz11FPEx8dbHVKXmJRPU1MTmzZtYsuWLYSGhjJnzpw++6yY9DzT+oX2Ut7K2/S8+2POXr05njKq6PFyu90EBAT06ecq2sukXEyZVtPLlHwaGhp45JFH+N3vfuf7wT9/Zlo+LS0tuN1u2trajHlIXbrGpH6hI5S38jZdf8wZem88ZWTRIyIdc/oUqCYwLR8RERHpGhU9IiIiIiJiNP+/N0dEREREROQ8VPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjRVPSIiIiIiIjR/g+Vdh4tBzRgrgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x1008 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "main_data.hist(figsize=(14,14), xrot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70512f80-e177-423b-92a5-85c69f3cbf2d",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">2. Data Processing </h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afaffc-4de9-404a-8700-0765e14170b7",
   "metadata": {},
   "source": [
    "## 2.1 Check Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e17ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CELL_TYPE_SAMPLE_SIZE = 5\n",
    "\n",
    "for cell_type_name in main_data['cellTypeName'].unique():\n",
    "    df_sample = main_data[main_data['cellTypeName'] == cell_type_name].sample(CELL_TYPE_SAMPLE_SIZE)\n",
    "    plt.figure(figsize=(CELL_TYPE_SAMPLE_SIZE ** 2, CELL_TYPE_SAMPLE_SIZE))\n",
    "    for image_index, image_name in enumerate(df_sample['ImageName']):\n",
    "        plt.subplot(1, CELL_TYPE_SAMPLE_SIZE + 1, image_index+1)\n",
    "        plt.grid(None)\n",
    "        img = image.load_img('./patch_images/' + image_name, target_size=(27, 27))\n",
    "        plt.imshow(img)\n",
    "        plt.title(cell_type_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c0ebe-3f52-4abc-ab51-cbe68d86c726",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#3D3D3D;\n",
    "           font-size:110%;\n",
    "           font-family:Verdana;\n",
    "           letter-spacing:0.5px\">\n",
    "\n",
    "<p style=\"padding: 10px;\n",
    "              color:#FFD154;\">\n",
    "No image is missing label\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c9003-153a-4015-8efe-5932aa63e59e",
   "metadata": {},
   "source": [
    "## 2.2 Check duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = os.listdir('./patch_images/')\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea685c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duplicates = []\n",
    "hash_keys = dict()\n",
    "for index, filename in  enumerate(os.listdir('./patch_images/')):  #listdir('.') = current directory\n",
    "\n",
    "    if os.path.isfile('./patch_images/'+filename):\n",
    "        with open('./patch_images/'+filename, 'rb') as f:\n",
    "            filehash = hashlib.md5(f.read()).hexdigest()\n",
    "        if filehash not in hash_keys: \n",
    "            hash_keys[filehash] = index\n",
    "        else:\n",
    "            duplicates.append((index,hash_keys[filehash]))\n",
    "            print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7b6c6-7237-48a4-a5ee-5a2f90a4f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "for file_indexes in duplicates[:30]:\n",
    "    try:\n",
    "    \n",
    "        plt.subplot(121),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[1]]))\n",
    "        plt.title(file_indexes[1]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        plt.subplot(122),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[0]]))\n",
    "        plt.title(str(file_indexes[0]) + ' duplicate'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    except OSError as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e190503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate\n",
    "for index in duplicates:\n",
    "    os.remove('./patch_images/' + file_list[index[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "5ce2cae9-8864-49e6-9903-a26e6eb0c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in duplicates:\n",
    "    main_data = main_data[main_data.ImageName  != file_list[index[0]]]\n",
    "    df_random_cancer_from_extra = df_random_cancer_from_extra[df_random_cancer_from_extra.ImageName  != file_list[index[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "fae53bb9-cbda-4036-acec-6fb9a4564a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       InstanceID  patientID  ImageName cellTypeName  cellType  isCancerous\n",
      "0           22405          1  22405.png   fibroblast       0.0            0\n",
      "1           22406          1  22406.png   fibroblast       0.0            0\n",
      "2           22407          1  22407.png   fibroblast       0.0            0\n",
      "3           22408          1  22408.png   fibroblast       0.0            0\n",
      "4           22409          1  22409.png   fibroblast       0.0            0\n",
      "...           ...        ...        ...          ...       ...          ...\n",
      "11626        7212         71   7212.png          NaN       NaN            1\n",
      "11627        9878         86   9878.png          NaN       NaN            1\n",
      "11628        6517         68   6517.png          NaN       NaN            1\n",
      "11629       14199         66  14199.png          NaN       NaN            1\n",
      "11630        5311         78   5311.png          NaN       NaN            1\n",
      "\n",
      "[11631 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(main_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb7fb9c-3abc-403f-a390-32305d2ad537",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#3D3D3D;\n",
    "           font-size:110%;\n",
    "           font-family:Verdana;\n",
    "           letter-spacing:0.5px\">\n",
    "\n",
    "<p style=\"padding: 10px;\n",
    "              color:#FFD154;\">\n",
    "There are 3 duplicate image so I have remove it from image folder and the dataset\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e470154-c699-4ba9-a02f-b3a2fa2bf392",
   "metadata": {},
   "source": [
    "## 2.3 Imbalancing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f4cea-ffb4-4899-bf39-5d515f446305",
   "metadata": {},
   "source": [
    "This bias in the training dataset can impact various machine learning algorithms, causing some to completely disregard the minority class. This is a concern since projections are often based on the minority class.\n",
    "\n",
    "One method for dealing with class imbalance is to randomly resample the training dataset. The two basic methods for randomly resampling an unbalanced dataset are to eliminate instances from the majority class, which is known as undersampling, and to duplicate examples from the minority class, which is known as oversampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cancer_class_count = main_data.isCancerous.value_counts()\n",
    "amount_for_balance = abs(is_cancer_class_count[0] - is_cancer_class_count[1])\n",
    "df_random_cancer_from_extra = main_data_extra[main_data_extra['isCancerous'] == 1].sample(amount_for_balance)\n",
    "for index in duplicates:\n",
    "    main_data = main_data[main_data.ImageName  != file_list[index[0]]]\n",
    "    df_random_cancer_from_extra = df_random_cancer_from_extra[df_random_cancer_from_extra.ImageName  != file_list[index[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "56ad15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the data for task 2\n",
    "main_data_task2 = main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.concat([main_data, df_random_cancer_from_extra], ignore_index=True)\n",
    "main_data.isCancerous.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "raw_train_task, test_data = train_test_split(main_data[['ImageName', 'isCancerous']], test_size=0.2, random_state=9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39fd63c-5165-4140-9b68-45c9779cf160",
   "metadata": {},
   "source": [
    "## 2.4 Generate data for fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_task, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_task, val_data = train_test_split(raw_train_task, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(raw_train_task.shape[0], val_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_dataframe_iterator(dataframe, \n",
    "                            image_shape = (27, 27), \n",
    "                            batch_size = 64,\n",
    "                            x_col = \"ImageName\",\n",
    "                            y_col = \"cellTypeName\",\n",
    "                            classes = [\"fibroblast\", \"inflammatory\", \"epithelial\", \"others\"]):\n",
    "    dataframe[y_col] = dataframe[y_col].apply(str)\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        rotation_range = 20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ) \n",
    "    iterator = generator.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = \"./patch_images\", \n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        classes = classes, \n",
    "        class_mode = \"categorical\", \n",
    "        target_size = image_shape, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77af1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = get_dataframe_iterator(raw_train_task, y_col='isCancerous', classes=['0','1'])\n",
    "val_iterator = get_dataframe_iterator(val_data, y_col='isCancerous', classes=['0','1'])\n",
    "test_iterator = get_dataframe_iterator(test_data, y_col='isCancerous', classes=['0','1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b3757-22c4-488b-adf2-f8ff647086de",
   "metadata": {},
   "source": [
    "## 2.5 Define function for fitting model and measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d655018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, iterator, val_iterator, \n",
    "              epochs = 100, \n",
    "              export_dir = './export',\n",
    "              name = 'default'):\n",
    "    history = model.fit_generator(\n",
    "        iterator,\n",
    "        validation_data = val_iterator,\n",
    "        epochs = epochs,\n",
    "        verbose = 1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f238539-03fc-4308-b6bf-85b1649ec5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy', precision_m, recall_m, f1_m]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26673582-a850-455e-9952-b8884b311932",
   "metadata": {},
   "source": [
    "## 2.6 Processing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_images = []\n",
    "\n",
    "for path in main_data['ImageName']:\n",
    "  image_path = os.path.join(\"./patch_images\", path)\n",
    "  image = cv2.imread(image_path , cv2.IMREAD_GRAYSCALE)\n",
    "  list_of_images.append(image)\n",
    "\n",
    "list_of_images = np.asarray(list_of_images)\n",
    "np.array(list_of_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = np.reshape(list_of_images,  (-1 , 27 * 27))\n",
    "list_of_images = pd.DataFrame(list_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4853ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_cancer , validate_x_cancer, train_y_cancer , validate_y_cancer = train_test_split(list_of_images, main_data['isCancerous'], test_size=0.2 , random_state = 42, shuffle = True)\n",
    "\n",
    "print(\"Train X shape: \" , train_x_cancer.shape)\n",
    "print(\"Train Y shape: \" , train_y_cancer.shape)\n",
    "print(\"Validate X shape: \" , validate_x_cancer.shape)\n",
    "print(\"Validate Y shape: \" , validate_y_cancer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29434787-2bba-442a-ae2a-6c6815c58f9e",
   "metadata": {},
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#3D3D3D;\n",
    "           font-size:110%;\n",
    "           font-family:Verdana;\n",
    "           letter-spacing:0.5px\">\n",
    "\n",
    "<p style=\"padding: 10px;\n",
    "              color:#FFD154;\">\n",
    "Put images in to an array and split in train_x_cancer , validate_x_cancer, train_y_cancer , validate_y_cancer\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54878a-2a4a-4e0e-a757-f252395f4440",
   "metadata": {},
   "source": [
    "<h1 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">3. Model Traning</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8e72",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8348d1b9-b463-4a00-9db1-313b232cddff",
   "metadata": {},
   "source": [
    "### *Definition\n",
    "- It is a supervised learninng for the binary classification problem.\n",
    "- It is decision tree-based machine learning algorithm and optimized by the Gradient Boosting framewor.\n",
    "- It builds trees in parallel. \n",
    "- It won lots of award in Kaggle\n",
    "\n",
    "![logistic-regression-definition](https://vtitech.vn/wp-content/uploads/2020/09/xgboost.jpeg)\n",
    "\n",
    "### Purposes:\n",
    "   In task 1, the problem is binary classification (maligant or benign cell). Therefore, it is reasonable for us to apply the XGBoost algorithm to build our model and make the prediction, since this is consider as one of the best algorithm decision tree-based, we expect to product a higher accuracy and precision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6b814",
   "metadata": {},
   "source": [
    "### 1. Default model (without any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae76c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
    "\n",
    "# We will use objective = \"binary:logistic\" since this problem is binary classification\n",
    "xgbr = xgb.XGBClassifier(objective='binary:logistic')\n",
    "xgbr.fit(train_x_cancer, train_y_cancer)\n",
    "\n",
    "\n",
    "y_pred_validate = xgbr.predict(validate_x_cancer)\n",
    "prediction_validate = [round(value) for value in y_pred_validate]\n",
    "\n",
    "y_pred_train = xgbr.predict(train_x_cancer)\n",
    "prediction_train = [round(value) for value in y_pred_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Train report\")\n",
    "print(classification_report(train_y_cancer, y_pred_train))\n",
    "print(\"Validate report\")\n",
    "print(classification_report(validate_y_cancer, prediction_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b83202-7e3b-4deb-8a86-c04ede7e93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "print(\"Train F1 Score:\" + str(f1_score (train_y_cancer, prediction_train)))\n",
    "print(\"Train Accuracy Score:\" + str(accuracy_score (train_y_cancer, prediction_train)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Test F1 Score:\" + str(f1_score(validate_y_cancer, prediction_validate)))\n",
    "print(\"Test Accuracy Score:\" + str(accuracy_score (validate_y_cancer, prediction_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44da496-614d-4c9d-b18b-110fc235c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def plot_conf_matrix (conf_matrix, dtype):\n",
    "    class_names = [0,1]\n",
    "    fontsize=14\n",
    "    df_conf_matrix = pd.DataFrame(\n",
    "            conf_matrix, index=class_names, columns=class_names, \n",
    "        )\n",
    "    fig = plt.figure()\n",
    "    heatmap = sns.heatmap(df_conf_matrix, annot=True, fmt=\"d\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix for {0}'.format(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b8f16-e747-4199-9275-a16e117c531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(validate_y_cancer, y_pred_validate), \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1185211-b041-4cb0-9f80-300276bfa91e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(validate_y_cancer,y_pred_validate),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a25ef39-e33c-4515-8813-a2e7c7f2cebb",
   "metadata": {},
   "source": [
    "### 🔬 Observation:\n",
    "\n",
    "1. According to the report, the weighted avg for precision and recall for train data is 1 and 1\n",
    "2. According to the report, the weighted avg for precision and recall for validate data is 0.81 and 0.81\n",
    "3. Since the difference between train and validate is pretty large( more than 20%), thus, we can conclude this model are overfiting. Therefore, we need to apply hyper tuning to solve this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5583d6",
   "metadata": {},
   "source": [
    "### 2. Using GridSearchCV to find best params and calculate RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f56922",
   "metadata": {},
   "source": [
    "####  **Hyperparameter tuning chosen**\n",
    "1. gamma:  to figure out the pseudo-regularisation.\n",
    "2. learning_rate: to figure the step size at each iteration.\n",
    "3. max_depths: to figure out max level number of the tree. This parameter can cause overfit but also increase the performance.\n",
    "4. n_jobs: to set the number of job to 10 to use all processors.\n",
    "5. n_estimators: to limit the trees in ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# We will use objective = \"binary:logistic\" since this problem is binary classification\n",
    "\n",
    "params = { 'gamma': [0,0.2,1],\n",
    "              'learning_rate': [0.01, 0.06, 0.1],\n",
    "              'max_depth': [5,6,7],\n",
    "              'n_estimators': [50],\n",
    "              }\n",
    "gs_xgbr = xgb.XGBClassifier(objective= 'binary:logistic',nthread=4,seed=42)\n",
    "grid_search_cv = GridSearchCV(estimator=gs_xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring = 'roc_auc',\n",
    "                    n_jobs = 10,\n",
    "                    cv = 5,\n",
    "                    verbose=True)\n",
    "grid_search_cv.fit(train_x_cancer, train_y_cancer)\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "best_n_estimators_value = grid_search_cv.best_params_['n_estimators']\n",
    "best_max_depth_value = grid_search_cv.best_params_['max_depth']\n",
    "best_learning_rate_value = grid_search_cv.best_params_['learning_rate']\n",
    "best_gamma = grid_search_cv.best_params_['gamma']\n",
    "best_score = grid_search_cv.best_score_\n",
    "print(\"Best Score: \", (grid_search_cv.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "gs_y_pred_validate = grid_search_cv.predict(validate_x_cancer)\n",
    "gs_prediction_validate = [round(value) for value in gs_y_pred_validate]\n",
    "\n",
    "gs_y_pred_train = grid_search_cv.predict(train_x_cancer)\n",
    "gs_prediction_train = [round(value) for value in gs_y_pred_train]\n",
    "\n",
    "print(\"Train report\")\n",
    "print(classification_report(train_y_cancer, gs_y_pred_train))\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer, gs_prediction_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483ef70-342a-41c4-9711-4272915e016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "\n",
    "# accuracy = accuracy_score(validate_y_cancer, prediction_validate)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "print(\"Train F1 Score:\" + str(f1_score (train_y_cancer, gs_prediction_train)))\n",
    "print(\"Train Accuracy Score:\" + str(accuracy_score (train_y_cancer, gs_prediction_train)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Test F1 Score:\" + str(f1_score(validate_y_cancer, gs_prediction_validate)))\n",
    "print(\"Test Accuracy Score:\" + str(accuracy_score (validate_y_cancer, gs_prediction_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9a760f-493f-4804-97b5-a14bfebb9a15",
   "metadata": {},
   "source": [
    "### 🔬 Observation:\n",
    "\n",
    "1. According to the report, the weighted avg for precision and recall for train data is about 0.97 and 0.98\n",
    "2. According to the report, the weighted avg for precision and recall for validate data is about 0.81 and 0.81\n",
    "3. According to the report, the validate f1 score is about 0.98 whereas the train f1 score is about 0.81.\n",
    "4. The overfit between train and test is about 20% (which is extremly large).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3490b37-6da1-4105-a506-9083485dcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(validate_y_cancer, gs_y_pred_validate), \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a80ffe-8fd7-43a5-84ff-e50ea52b185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(validate_y_cancer,gs_y_pred_validate),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54259f87",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "For this model, when diagnose 1112 not-cancerous cells, the machine predict corect 912 cells, which is 81%. On the other hand, when predict for cancerous cells, the machine predict correct 978 over 1215 cell, which 81%. As our a problem is diagnose whether the cell is cancerous or not, thus, it is more ***important*** to consider the ***false negative*** than ***false postive***. In other words, if the normal cell is diagnose as positive, we need to pay extra fee for medical and place for that patient whereas the positive cell is diagnose as negative, that patient may lost their life. Therefore, compare between the money and people life, obviously, we should pay more attention on the people life which is affected by false negative. Thus, this model is acceptable since the percentage of recall is 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ead81-a9fe-426f-8e0f-9ad4a7ee9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(roc_auc_train, roc_auc_test):\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr_tr, tpr_tr, 'g', label = 'Training AUC = %0.2f' % roc_auc_train)\n",
    "    plt.plot(fpr_ts, tpr_ts, 'b', label = 'Testing AUC = %0.2f' % roc_auc_test)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d32f7-25ca-4079-8223-b303d2aee28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data ROC\n",
    "fpr_tr, tpr_tr, threshold = roc_curve(train_y_cancer, gs_y_pred_train)\n",
    "roc_auc_train = auc(fpr_tr, tpr_tr)\n",
    "\n",
    "#test data ROC\n",
    "fpr_ts, tpr_ts, threshold = roc_curve(validate_y_cancer, gs_y_pred_validate)\n",
    "roc_auc_test = auc(fpr_ts, tpr_ts)\n",
    "\n",
    "#Plot ROC curve\n",
    "plot_roc_curve(roc_auc_train, roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c99922-d0ed-4cbb-8d0d-09f51a88c91c",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "According to the graph, our model is extremely overfitting. The closet point is when testing AUC equals to 0.81 and training AUC equals to 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fc388-b375-4e59-a9d3-a52da76edc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "evaluation_xgboost_t1 = [None]\n",
    "evaluation_xgboost_t1.append(accuracy_score(validate_y_cancer,gs_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(precision_score(validate_y_cancer, gs_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(recall_score(validate_y_cancer, gs_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(f1_score(validate_y_cancer, gs_y_pred_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20c228c-9a30-43aa-b3eb-336fb34161d0",
   "metadata": {},
   "source": [
    " ### Conclusion: \n",
    " After evaluting the model, our group figure out that it provides a good accuaracy and precision for identifying the cancerous and non-cancerous cell type.However, the model has the remarkable overfit eventhough we used the grid search to figure out the best parameters. Therefore, our group continue to explore more approaches in order to fix this problem. One of the most well-known approach at present is neutral network which is also approriate for supervised problem in task 1. Since there are many algorithms inspired by neural network, our group will pick serveral algorithms to train, evaluate and compare to figure out the best model to handle this problem. First, we will use the inceptionV3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42bda2",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31edc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54611d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "!pip install keras_applications\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(include_top=False, input_shape=(75, 75, 3), weights='imagenet')\n",
    "\n",
    "# Resize Input images to 75x75\n",
    "newInput = Input(batch_shape=(None, 27, 27, 3))\n",
    "resizedImg = Lambda(lambda image: tf.compat.v1.image.resize_images(image, (75, 75)))(newInput)\n",
    "newOutputs = model(resizedImg)\n",
    "model = Model(newInput, newOutputs)\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add Dense layer to classify on CIFAR10\n",
    "output = model.output\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dense(units=2, activation='softmax')(output)\n",
    "model_inceptionv3 = Model(model.input, output)\n",
    "\n",
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0045 , amsgrad = True)\n",
    "model_inceptionv3.compile(optimizer=Adam(lr=1e-4),loss='categorical_crossentropy', metrics=METRICS)\n",
    "\n",
    "history_inception_v3 = fit_model(model_inceptionv3, train_iterator, val_iterator, \n",
    "                                export_dir='.',\n",
    "                                name=\"Inception_Task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c1f2a",
   "metadata": {},
   "source": [
    "# GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269e503-75f9-4f1f-896e-4501fed4c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_googlenet(model, iterator, val_iterator, \n",
    "              epochs = 50, \n",
    "              export_dir = './export',\n",
    "              name = 'default'):\n",
    "    es = EarlyStopping(monitor='dense_5_accuracy', \n",
    "                       mode='max', \n",
    "                       verbose=1, \n",
    "                       patience=10, \n",
    "                       restore_best_weights=True)\n",
    "    mc = ModelCheckpoint('{}/model_{}.h5'.format(export_dir, name), \n",
    "                         monitor='dense_5_accuracy', \n",
    "                         mode='max', \n",
    "                         save_best_only=True)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        iterator,\n",
    "        validation_data = val_iterator,\n",
    "        epochs = epochs,\n",
    "        verbose = 1,\n",
    "        callbacks=[mc,es]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
    "  # Input: \n",
    "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "\n",
    "  # 1st path:\n",
    "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "\n",
    "  # 2nd path\n",
    "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "  # 3rd path\n",
    "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "  # 4th path\n",
    "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
    "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
    "\n",
    "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "  return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogLeNet():\n",
    "  # input layer \n",
    "  input_layer = Input(shape = (27, 27, 3))\n",
    "\n",
    "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
    "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
    "\n",
    "  X = ZeroPadding2D(padding=(10, 10))(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 1)(X)\n",
    "\n",
    "  # convolutional layer: filters = 64, strides = 1\n",
    "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
    "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 1st Inception block\n",
    "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
    "\n",
    "  # 2nd Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 3rd Inception block\n",
    "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
    "\n",
    "  # Extra network 1:\n",
    "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
    "  X1 = Flatten()(X1)\n",
    "  X1 = Dense(1024, activation = 'relu')(X1)\n",
    "  X1 = Dropout(0.7)(X1)\n",
    "  X1 = Dense(2, activation = 'softmax')(X1) # <----- changed 1000 to 2\n",
    "\n",
    "  \n",
    "  # 4th Inception block\n",
    "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 5th Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 6th Inception block\n",
    "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # Extra network 2:\n",
    "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "  X2 = Flatten()(X2)\n",
    "  X2 = Dense(1024, activation = 'relu')(X2)\n",
    "  X2 = Dropout(0.7)(X2)\n",
    "  X2 = Dense(2, activation = 'softmax')(X2) # <----- changed 1000 to 2\n",
    "  \n",
    "  \n",
    "  # 7th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
    "                      f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # 8th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # 9th Inception block\n",
    "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # Global Average pooling layer \n",
    "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
    "\n",
    "  # Dropoutlayer \n",
    "  X = Dropout(0.4)(X)\n",
    "\n",
    "  # output layer \n",
    "  X = Dense(2, activation = 'softmax')(X) # <------ changed from 1000 to 2 \n",
    "  \n",
    "  # model\n",
    "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_googlenet_t1 = GoogLeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model_googlenet_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_googlenet_t1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91fdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00045, amsgrad = True)\n",
    "model_googlenet_t1.compile(optimizer=opt, loss='binary_crossentropy',metrics=METRICS)\n",
    "\n",
    "history_googlenet_t1 = fit_model_googlenet(model_googlenet_t1, train_iterator, val_iterator,\n",
    "                                export_dir='.',\n",
    "                                name=\"GoogLeNet_Task1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f6155-2911-4db6-bcc0-ebce8a87cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_googlenet_t1.save('./googlenet.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99379d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = model_googlenet_t1.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = [\n",
    "    evaluation_googlenet_t1[1], # dense_4_loss\n",
    "    evaluation_googlenet_t1[4], # dense_4_accuracy\n",
    "    evaluation_googlenet_t1[5], # dense_4_precision\n",
    "    evaluation_googlenet_t1[6], # dense_4_recall\n",
    "    evaluation_googlenet_t1[7]  # dense_4_f1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23359c1",
   "metadata": {},
   "source": [
    "# Resnet50\n",
    "## Defining an identity block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8768b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n",
    "def identity_block(X, f, filters, block, activation='relu'):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "    \n",
    "    Arguments:\n",
    "    X: input tensor\n",
    "    f: shape for middle CONV kernel size param\n",
    "    filters: list of number of filters in the CONV layers of the main path\n",
    "    block: name of this block\n",
    "    \n",
    "    Returns:\n",
    "    X: output, returns a tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    conv_name = 'conv' + block\n",
    "    bn_name = 'batchNorm' + block\n",
    "    \n",
    "    # get filters from parameter\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # copy the original shape to add it back to the main path\n",
    "    X_copy = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name + 'a', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name + 'b', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name + 'c', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'c')(X)\n",
    "\n",
    "    # add shortcut back to main path, and use relu activation\n",
    "    X = Add()([X, X_copy])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb650ac2",
   "metadata": {},
   "source": [
    "## Defining a convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ed88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, block, s = 2, activation='relu'):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X: input tensor\n",
    "    f: shape for middle CONV kernel size param\n",
    "    filters: list of number of filters in the CONV layers of the main path\n",
    "    block: name of this block\n",
    "    s: stride param to be used for shortcut component\n",
    "    \n",
    "    Returns:\n",
    "    X: output, returns a tensor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    conv_name = 'conv' + block\n",
    "    bn_name = 'batchNorm' + block\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_copy = X\n",
    "\n",
    "    # First component\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name + 'a', kernel_initializer  = GlorotUniform(seed= 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Second component\n",
    "    X = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name + 'b', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Third component\n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name + 'c', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'c')(X)\n",
    "\n",
    "    # Shortcut\n",
    "    X_copy = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name + 'd', kernel_initializer = GlorotUniform(seed = 0))(X_copy)\n",
    "    X_copy = BatchNormalization(axis = 3, name = bn_name + 'd')(X_copy)\n",
    "\n",
    "    # add shortcut back to main path, and use relu activation\n",
    "    X = Add()([X, X_copy])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf27882",
   "metadata": {},
   "source": [
    "## Implementing a ResNet50 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (27, 27, 3), classes = 2):\n",
    "    \"\"\"\n",
    "    Implementation using the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    MAXPOOl -> TOPLAYER\n",
    "\n",
    "    reducing the typical 5 stage to 3 stage to reduce time and memory expense\n",
    "\n",
    "    Arguments:\n",
    "    input_shape: shape of image, currently is 27x27\n",
    "    classes: integer, number of classes to identify\n",
    "    \n",
    "    returns a Model() instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set x_input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # add padding for tensor\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    #since resnet only works for images that is 30x30 pixels or higher, we need to add padding pixels for the algorithm to work\n",
    "    \n",
    "    # first stage\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = initializers.RandomNormal(stddev=0.01))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # second\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], block='2a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2c')\n",
    "\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    \n",
    "    # third\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], block='3a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3d')\n",
    "    \n",
    "    # avg pooling\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = GlorotUniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30573cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50_t1 = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16040cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0045 , amsgrad = True)\n",
    "model_resnet50_t1.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "history_resnet50_t1 = fit_model(model_resnet50_t1, train_iterator, val_iterator, \n",
    "                                export_dir=\"\",\n",
    "                                name=\"resnet50_t1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_resnet50_t1 = model_resnet50_t1.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0af1d",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1306304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(27, 27, 3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.7))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.9))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(10))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98\n",
    "\n",
    "\n",
    "def AlexNet():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', input_shape=(27, 27, 3)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(1,1)),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        \n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.7),\n",
    "\n",
    "        keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cac0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0035)\n",
    "\n",
    "alex_model = AlexNet()\n",
    "alex_model.compile(optimizer=\"SGD\", loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "alex_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80197643",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_AlexNet = fit_model(alex_model, train_iterator, val_iterator,name=\"Task1_AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0eb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alex1 = alex_model.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa198f7",
   "metadata": {},
   "source": [
    "# *Task2: Classify  images  according  to  cell-type,  such  as:  fibroblast,  inflammatory, epithelial or others* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ded6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = main_data_task2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee169c46",
   "metadata": {},
   "source": [
    "<a id =\"IV\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">Ⅰ. Cleaning dataset  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfb9f6",
   "metadata": {},
   "source": [
    "#### Before cleaning the data, let display the dataset to observe it in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d555f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbc66d",
   "metadata": {},
   "source": [
    "<a id =\"IV.A1\"></a>\n",
    "\n",
    "### *1. Check Data type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ee211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all info row by row\n",
    "main_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18d525",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "We need to check data type for overall understanding for our dataset and identifying which column we should keep or change data type for later encoding and better model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f5b0",
   "metadata": {},
   "source": [
    "<a id =\"IV.A2\"></a>\n",
    "\n",
    "### *2. Checking missing values*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535ad0a",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Missing value can lead to error for machine, thus, we need to check if there is any missing value and fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset has any missing value, \n",
    "main_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c605a",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the return value is false, we can conclude that the dataset has no missing values. However, we should double check for every columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f45c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total missing values for each columns \n",
    "main_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cf7a5",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "There is 100% no missing values in any columns in the dataset, thus, we dont not need to fill any missing values for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4d506",
   "metadata": {},
   "source": [
    "<a id =\"IV.A3\"></a>\n",
    "\n",
    "### *3. Check typography*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_name_values = main_data['cellTypeName'].nunique(dropna=False)\n",
    "print(celltype_name_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_data['cellTypeName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9b944",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Typo value can lead to time runing and storage problem for machine (fibroblast, fibreblast are 2 different values but have same meaning), thus, we check typo preventing same meaningful values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c8a06",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the cellTypeName column have 4 different values such as fibroblast, inflammatory, epithelial or others. => no typo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8813c8b",
   "metadata": {},
   "source": [
    "<a id =\"IV.A4\"></a>\n",
    "\n",
    "### *4. Convert string column to uppercase*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73572b",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since there are only 4 values fibroblast, inflammatory, epithelial in cellTypeName columns. Therefore, we do not need to convert to lowercase or uppercase for this dataset. However, in the larger dataset with multiple values, we should convert to all uppercase or lowercase to avoid duplication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb3f63",
   "metadata": {},
   "source": [
    "<a id =\"IV.A5\"></a>\n",
    "\n",
    "### 5. Eliminate extra white spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d910c3",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since the Sepsis column have 4 different values such as fibroblast, inflammatory, epithelial or others => no extra white spaces    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c994bd3",
   "metadata": {},
   "source": [
    "<a id =\"IV.A6\"></a>\n",
    "\n",
    "### *6. Check duplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Datafrane -> no dupplication in the main_data dataframe\n",
    "duplicate_values = main_data[main_data.duplicated()]\n",
    "print(duplicate_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc5f7",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Duplicate data can lead to time runing and storage problem for machine, thus, we need to check if there is any duplicated data and drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88066fec",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "There is 100% no duplicated values in the dataset, thus, we dont not need to drop any rows for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d66ff",
   "metadata": {},
   "source": [
    "<a id =\"IV.A7a\"></a>\n",
    "\n",
    "### 7. Check impossible values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5655b",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "Some time the dataset has some impossible values such as age is negative, thus, we need to check impossible value to find and drop or fix it to improve the accuracy of the machine learing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfdd5e",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "In this dataset, all of the data are reasonable => no impossible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a211bb",
   "metadata": {},
   "source": [
    "<a id =\"IV.B8\"></a>\n",
    "\n",
    "### 8. Check outlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7.5]\n",
    "# plot the boxplot to see the outlier of each numerical column\n",
    "sns.boxplot(data=main_data,orient=\"v\")\n",
    "plt.title(\"Bot-Plots Distribution\", y = 1,fontsize = 20, pad = 40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1cd74",
   "metadata": {},
   "source": [
    "### 🔬 Observation:\n",
    "According to the bot-plots, there are completely no outliner in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385a602",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "After finish cleaning the data, we should display the data to double check the data and figure out the count, mean, min , 25%, 50%, 75%, max to prepare for EDA step in later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9fb32",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">II. Exploratory Data Analysis (EDA)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf39ec",
   "metadata": {},
   "source": [
    "<a id =\"V.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.My hypothesises </h3>\n",
    "\n",
    "1. The value for each type in the cell type name will be different.\n",
    "\n",
    "2. The value of `others` class will be the least compare to other classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "ax = sns.countplot(y=\"cellTypeName\", data=main_data)\n",
    "ax.set_title(\"Bar chart to display the total number of each type in cell type name\", fontsize=15)\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d95a7f",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "In this plot, the vertical axis is cellTypeName and the horizontal axis is count (total values). In overall, the class epithelial has the most value (4079) whereas the other class have the least value (1386). In additional, the different between each class are large, thus, we should consider to solve this problem by using imbalance in the feature engineering step. \n",
    "\n",
    "After observation, we can conclude that our hypotheses are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a094c3",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">III. Feature Enginnering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1622526",
   "metadata": {},
   "source": [
    "<a id =\"VI.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Drop Unrealated columns to the target</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe28d3f",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "Since all columns in the dataset are neccessary => we do not need to drop any columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ad113",
   "metadata": {},
   "source": [
    "<a id =\"VI.2\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2.Class Imbalances</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_data['cellTypeName'].value_counts())\n",
    "print(main_data['cellTypeName'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dc023",
   "metadata": {},
   "source": [
    "### 📚 Reason: \n",
    "The reason, we need to rebalance these classes value is the accuracy of the sepsis prediction might affected by the amount of values in one class. In other words , if one class has more values compare to the others , it is likely that we will receive the better prediction for this class instead of others, thus, the prediction for other clas might be worst. Thus,in this particular situation, since the difference between these classes are large, we can rebalance these classes using <strong>upsample method</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4059c3a",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "After upsampling these classes, the value for all classes are the same, thus, we can move to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7430e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_images = []\n",
    "\n",
    "for path in main_data['ImageName']:\n",
    "  image_path = os.path.join(\"./patch_images\", path)\n",
    "  image = cv2.imread(image_path , cv2.IMREAD_GRAYSCALE)\n",
    "  list_of_images.append(image)\n",
    "\n",
    "list_of_images = np.asarray(list_of_images)\n",
    "np.array(list_of_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = np.reshape(list_of_images,  (-1 , 27 * 27))\n",
    "list_of_images = pd.DataFrame(list_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d2a69",
   "metadata": {},
   "source": [
    "<a id =\"VII\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">IV. Model Building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c999e89",
   "metadata": {},
   "source": [
    "<a id =\"VII.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Split dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdb6d5-a993-4996-ab7a-81fcad7dfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = main_data['cellTypeName'].value_counts()\n",
    "main_data_resampled = main_data[main_data['cellTypeName'] == 'epithelial']\n",
    "for cellTypeName in class_count.keys():\n",
    "  if (cellTypeName == 'epithelial'): continue\n",
    "  main_data_class = main_data[main_data['cellTypeName'] == cellTypeName].sample(class_count['epithelial'], replace=True)\n",
    "  main_data_resampled = pd.concat([main_data_resampled, main_data_class], axis=0)\n",
    "main_data_resampled['cellTypeName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed73915-3e25-4358-b536-e9212f6f3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(main_data_resampled, test_size=0.2, random_state=9999)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a50f2-b333-4ead-bd14-fe6d2014db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = get_dataframe_iterator(train_df)\n",
    "val_iterator = get_dataframe_iterator(val_df)\n",
    "test_iterator = get_dataframe_iterator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704de4c-3842-46ad-a627-6a9047ec8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x_cancer_task2 , validate_x_cancer_task2, train_y_cancer_task2 , validate_y_cancer_task2 = train_test_split(\n",
    "    list_of_images, \n",
    "    main_data['cellType'], \n",
    "    train_size = 0.8, \n",
    "    random_state = 9999, \n",
    "    shuffle = True)\n",
    "\n",
    "print(\"Training X shape: \" , train_x_cancer_task2.shape)\n",
    "print(\"Training Y shape: \" , train_y_cancer_task2.shape)\n",
    "print(\"Testing X shape: \" , validate_x_cancer_task2.shape)\n",
    "print(\"Testing Y shape: \" , validate_y_cancer_task2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663692d4-42ea-4510-b1e2-c2be430d8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ffd26",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "After spliting the data, we can start training the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41770af",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2. XG Boost</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b7de4",
   "metadata": {},
   "source": [
    "### 1. Default model (without any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09207bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Binary:logistic is used for logistic classfication problem which is our problem in this task\n",
    "xgbr_task2 = xgb.XGBClassifier(objective='binary:logistic')\n",
    "xgbr_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "\n",
    "y_pred_validate_task2 = xgbr_task2.predict(validate_x_cancer_task2)\n",
    "prediction_validate_task2 = [round(value) for value in y_pred_validate_task2]\n",
    "y_pred_train_task2 = xgbr_task2.predict(train_x_cancer_task2)\n",
    "prediction_train_task2 = [round(value) for value in y_pred_train_task2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train report\")\n",
    "print(classification_report(train_y_cancer_task2, y_pred_train_task2))\n",
    "print(\"Validate report\")\n",
    "print(classification_report(validate_y_cancer_task2, prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d3c70-e059-4ba5-840d-4f6755ac6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "print(\"Train F1 Score:\" + str(f1_score (train_y_cancer_task2, prediction_train_task2)))\n",
    "print(\"Train Accuracy Score:\" + str(accuracy_score (train_y_cancer_task2, prediction_train_task2)))\n",
    "print(\"--------------------------------------------------------\")\n",
    "print(\"Test F1 Score:\" + str(f1_score(validate_y_cancer_task2, prediction_validate_task2)))\n",
    "print(\"Test Accuracy Score:\" + str(accuracy_score (validate_y_cancer_task2, prediction_validate_task2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8d100e-4ff0-499c-8efb-8817b780591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(validate_y_cancer_task2, y_pred_validate_task2), \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a284b5ac-6cc5-46ba-a399-74c805298fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(confusion_matrix(validate_y_cancer_task2,y_pred_validate_task2),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3dc0f",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "The alogrithm produce a high accuracy and low RMSE. However, we should increase the efficency of this model by figure out the best parameters for this alogirthm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58243cc",
   "metadata": {},
   "source": [
    "### 2. Using GridSearchCV to find best params and calculate RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfc7d8",
   "metadata": {},
   "source": [
    "####  **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = { 'gamma': [0,0.2,1],\n",
    "              'learning_rate': [0.01, 0.06, 0.1],\n",
    "              'max_depth': [5,6,7],\n",
    "              'n_estimators': [50]}\n",
    "gs_xgbr_task2 = xgb.XGBClassifier(objective= 'binary:logistic',nthread=4,seed=42)\n",
    "grid_search_cv_task2 = GridSearchCV(estimator=gs_xgbr_task2, \n",
    "                   param_grid=params,\n",
    "                   scoring = 'roc_auc',\n",
    "                    n_jobs = 10,\n",
    "                    cv = 3,\n",
    "                    verbose=True)\n",
    "grid_search_cv_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "print(\"Best parameters:\", grid_search_cv_task2.best_params_)\n",
    "print(\"Lowest RMSE: \", (-grid_search_cv_task2.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "gs_y_pred_validate_task2 = grid_search_cv_task2.predict(validate_x_cancer_task2)\n",
    "gs_prediction_validate_task2 = [round(value) for value in gs_y_pred_validate_task2]\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer_task2, gs_prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96183c",
   "metadata": {},
   "source": [
    "### 3. Using Randomized Search CV to find best params and calculate lowest RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1475a8",
   "metadata": {},
   "source": [
    "#### **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = { 'gamma': [0,0.2,1],\n",
    "              'learning_rate': [0.01, 0.06, 0.1],\n",
    "              'max_depth': [5,6,7],\n",
    "              'n_estimators': [50]}\n",
    "rs_xgbr_task2 = xgb.XGBClassifier(objective= 'binary:logistic',nthread=4,seed=42)\n",
    "random_search_task2 = RandomizedSearchCV(estimator=rs_xgbr_task2,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         cv = 3,\n",
    "                         verbose=1)\n",
    "random_search_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "print(\"Best parameters:\", random_search_task2.best_params_)\n",
    "print(\"Lowest RMSE: \", (-random_search_task2.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "rd_y_pred_validate_task2 = random_search_task2.predict(validate_x_cancer_task2)\n",
    "rd_prediction_validate_task2 = [round(value) for value in rd_y_pred_validate_task2]\n",
    "rd_y_pred_train_task2 = random_search_task2_cv.predict(train_x_cancer_task2)\n",
    "rd_prediction_train_task2 = [round(value) for value in rd_y_pred_train_task2]\n",
    "\n",
    "print(\"Train report\")\n",
    "print(classification_report(train_y_cancer_task2, rd_prediction_train_task2))\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer_task2, rd_prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad462d",
   "metadata": {},
   "source": [
    "### 🔬 Observation:\n",
    "\n",
    "1. According to the report, the weighted avg for precision and recall for train data is about 0.97 and 0.98\n",
    "2. According to the report, the weighted avg for precision and recall for validate data is about 0.81 and 0.81\n",
    "3. According to the report, the validate f1 score is about 0.98 whereas the train f1 score is about 0.81.\n",
    "4. The overfit between train and test is about 20% (which is extremly large)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_conf_matrix(confusion_matrix(validate_y_cancer_task2, rd_y_pred_validate_task2), \"Test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw a summary table for prediction sepsis and not sepsis\n",
    "pd.DataFrame(confusion_matrix(validate_y_cancer_task2,rd_y_pred_validate_task2),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aee2174-eb18-4f1b-9f7f-3fa7936caaa0",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "For this model, when diagnose 1112 not-cancerous cells, the machine predict corect 912 cells, which is 81%. On the other hand, when predict for cancerous cells, the machine predict correct 978 over 1215 cell, which 81%. As our a problem is diagnose whether the cell is cancerous or not, thus, it is more ***important*** to consider the ***false negative*** than ***false postive***. In other words, if the normal cell is diagnose as positive, we need to pay extra fee for medical and place for that patient whereas the positive cell is diagnose as negative, that patient may lost their life. Therefore, compare between the money and people life, obviously, we should pay more attention on the people life which is affected by false negative. Thus, this model is acceptable since the percentage of recall is 81%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842ca60-bd7c-4d07-9ae3-532aa8de3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data ROC\n",
    "fpr_tr, tpr_tr, threshold = roc_curve(train_y_cancer_task2, rd_y_pred_train_task2)\n",
    "roc_auc_train_task2 = auc(fpr_tr, tpr_tr)\n",
    "\n",
    "#test data ROC\n",
    "fpr_ts, tpr_ts, threshold = roc_curve(validate_y_cancer_task2, rd_y_pred_validate_task2)\n",
    "roc_auc_test_task2 = auc(fpr_ts, tpr_ts)\n",
    "\n",
    "#Plot ROC curve\n",
    "plot_roc_curve(roc_auc_train_task2, roc_auc_test_task2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c379dca-1366-43fa-9adb-7fc36c01d9ff",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n",
    "According to the graph, our model is extremely overfitting. The closet point is when testing AUC equals to 0.81 and training AUC equals to 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce1788",
   "metadata": {},
   "source": [
    "### 🔬 Observation: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evaluation_xgboost_t1 = [None]\n",
    "evaluation_xgboost_t1.append(accuracy_score(validate_y_cancer_task2,rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(precision_score(validate_y_cancer_task2, rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(recall_score(validate_y_cancer_task2, rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(f1_score(validate_y_cancer_task2, rd_y_pred_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a82977",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">3. Resnet</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ResNet50_t2(input_shape = (27, 27, 3), classes = 2):\n",
    "    \"\"\"\n",
    "    Implementation using the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*3 -> CONVBLOCK -> IDBLOCK*3\n",
    "    AVGPOOL -> TOPLAYER\n",
    "\n",
    "    reducing the typical 5 stage to 3 stage to reduce time and memory expense\n",
    "\n",
    "    Arguments:\n",
    "    input_shape: shape of image, currently is 27x27\n",
    "    classes: integer, number of classes to identify\n",
    "    \n",
    "    returns a Model() instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set x_input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # add padding for tensor\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    #since resnet only works for images that is 30x30 pixels or higher, we need to add padding pixels for the algorithm to work\n",
    "    \n",
    "    # first stage\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = initializers.RandomNormal(stddev=0.01))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # second\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], block='2a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2c')\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2d')\n",
    "\n",
    "    # third\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], block='3a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3d')\n",
    "    \n",
    "    # avg pooling\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = GlorotUniform(seed=0) , kernel_regularizer=l2(0.01))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5214e",
   "metadata": {
    "id": "bRyL4qIcto4t"
   },
   "outputs": [],
   "source": [
    "model_resnet50_t2 = ResNet50_t2(classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecc78b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjPwhpG7u-49",
    "outputId": "388b2bb0-c7e9-41c6-e292-7bef030b8a27"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00052) \n",
    "model_resnet50_t2.compile(optimizer=opt, loss='categorical_crossentropy', \n",
    "                          metrics=METRICS)\n",
    "\n",
    "history_resnet50_t2 = fit_model(model_resnet50_t2, train_iterator, val_iterator,\n",
    "                                export_dir=\"\",\n",
    "                                name='ResNet50_Task2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74c0fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-RYfEgZu7_a",
    "outputId": "5204fc06-3957-4081-d0ff-ef1c1c933d14"
   },
   "outputs": [],
   "source": [
    "evaluation_resnet50_t2 = model_resnet50_t2.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cc294",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">4. VGG16</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720e989-c8e5-4ae0-aba3-55e1b283c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce2388-70f3-499e-9872-46a5905aca0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VGG16_Task2():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\", input_shape = (27, 27, 3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(528, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = \"relu\"))    \n",
    "    model.add(Dense(64, activation = \"relu\")) \n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b05d1-5758-4b80-9e96-51e41b30a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = VGG16_Task2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728ac42-934a-4408-aae2-4e28181576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56247a-fb66-43d4-b309-052768356dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model_vgg16.compile(optimizer=opt, loss='categorical_crossentropy', \n",
    "                       metrics=METRICS)\n",
    "\n",
    "history_vgg16_t2 = fit_model(model_vgg16, train_iterator, val_iterator,\n",
    "                             export_dir='model/',\n",
    "                             name=\"VGG19_Task2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108253bb-9946-4ae7-b212-f0c1858c7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_vgg16_t2 = model_vgg16.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758d7f0",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">5. Alex Net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def AlexNet2(input_shape = (27, 27, 3), \n",
    "                 classes = 4, \n",
    "                 optimizer ='SGD'):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(classes, activation='softmax' , kernel_regularizer=l2(0.001))\n",
    "        ])\n",
    "    model.compile(optimizer=optimizer, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model2 = AlexNet2()\n",
    "alex_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_AlexNet = fit_model(alex_model2, train_iterator, val_iterator,name=\"Task2_AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d617ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alex2 = alex_model2.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc26d9c",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">5. Alex Net (Supervised)</h3>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05769ab26bc4c6f953a6ba0a347b071c6ea6ed51577d89c547c43644aca31720"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
