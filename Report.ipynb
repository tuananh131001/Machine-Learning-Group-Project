{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765f9435",
   "metadata": {},
   "source": [
    "![Cancer](https://media2.giphy.com/media/sCqnpiUFN228E/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978f40a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad110d1d",
   "metadata": {},
   "source": [
    "Among the most important areas in the world is human health. Exploring the methods for preventing and detecting health problems has sparked a lot of interest. Cancer is the most common illness that has a significant impact on human health. A malignant tumor is a cancerous tumor that develops as a result of the disease. Colon cancer, together with breast cancer and lung cancer, is the third most deadly disease in the United States, killing 49,190 people in 2016 [1]. This is a cancer that begins in the large intestine colon, which is the last component of the digestive system.\n",
    "\n",
    "The machine learning technique should be used in this assignment to aid in the detection of malignant cells and the differentiation of cell types in colon cancer. Deep learning algorithms such as AlexNet, Resnet50, and VGG19 will all be developed and evaluated in this notebook, with XGBoost being the sole non-deep learning option to tackle the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb03b9",
   "metadata": {},
   "source": [
    "# Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc69724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d33aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c7fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f49e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px \n",
    "from tensorflow.keras.preprocessing import image\n",
    "import hashlib, os\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad\n",
    "from keras.regularizers import l2\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from zipfile import ZipFile\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adagrad\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.util import tf_inspect\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Lambda, Input\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "\n",
    "# Tensorflow\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D, AveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Add\n",
    "from keras import regularizers\n",
    "from keras import Input\n",
    "from tensorflow.keras import initializers\n",
    "from keras.initializers import GlorotUniform\n",
    "\n",
    "from keras import Model\n",
    "from keras import backend as K\n",
    "\n",
    "# https://medium.com/mlearning-ai/implementation-of-googlenet-on-keras-d9873aeed83c\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3043d",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv(\"data_labels_mainData.csv\")\n",
    "main_data_extra = pd.read_csv(\"data_labels_extraData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988081ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZipFile(\"Image_classification_data.zip\").extractall(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632656e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344fecba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_data['cellType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186064f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = main_data.groupby('patientID').any()\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=cancer_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 60])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b314f",
   "metadata": {},
   "source": [
    "51 out of total of 77 persons who have cancer, the rest 26 out of 77 is the number of people who don't have cancer cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6702eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pie=px.pie(data_frame=main_data,\n",
    "           names='cellTypeName',\n",
    "           color_discrete_sequence=px.colors.qualitative.Pastel,\n",
    "           width=550,\n",
    "           height=550)\n",
    "pie.update_layout(title_text='Distribution of cell types', title_x=0.5)\n",
    "pie.update_traces(textinfo='value+label+percent')\n",
    "pie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db41865a",
   "metadata": {},
   "source": [
    "From the graph, we can conclude the epithelial is cancerous cell type as all the patients who have cancer all possess epithelia cell type. As the number of cells of the epithelial type have the biggest number in the record (41.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c70346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=main_data, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 6000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06185e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax1 = plt.subplots(figsize = (8 , 8))\n",
    "graph = sns.countplot(ax=ax1,x='isCancerous', data=df_label_extra, palette='tab10')\n",
    "graph.set_title(\"Positive vs Negative cancerous patients extra df\", fontsize=20)\n",
    "graph.set_xticklabels(graph.get_xticklabels(),rotation=0)\n",
    "ax1.set_ylim([0, 8000])\n",
    "for p in graph.patches:\n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x()+p.get_width()/2., height + 1, height, ha=\"center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ee1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df_label.hist(figsize=(14,14), xrot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e17ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CELL_TYPE_SAMPLE_SIZE = 5\n",
    "\n",
    "for cell_type_name in main_data['cellTypeName'].unique():\n",
    "    df_sample = main_data[main_data['cellTypeName'] == cell_type_name].sample(CELL_TYPE_SAMPLE_SIZE)\n",
    "    plt.figure(figsize=(CELL_TYPE_SAMPLE_SIZE ** 2, CELL_TYPE_SAMPLE_SIZE))\n",
    "    for image_index, image_name in enumerate(df_sample['ImageName']):\n",
    "        plt.subplot(1, CELL_TYPE_SAMPLE_SIZE + 1, image_index+1)\n",
    "        plt.grid(None)\n",
    "        img = image.load_img('./patch_images/' + image_name, target_size=(27, 27))\n",
    "        plt.imshow(img)\n",
    "        plt.title(cell_type_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f8ffd",
   "metadata": {},
   "source": [
    "## *Task1: Classify  images  according  to  whether  given  cell  image  represents  a cancerous cells or not (isCancerous)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff58db1c",
   "metadata": {},
   "source": [
    "# Data Processing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
    "\n",
    "def get_dataframe_iterator(dataframe, \n",
    "                            image_shape = (27, 27), \n",
    "                            batch_size = 64,\n",
    "                            x_col = \"ImageName\",\n",
    "                            y_col = \"cellTypeName\",\n",
    "                            classes = [\"fibroblast\", \"inflammatory\", \"epithelial\", \"others\"]):\n",
    "    dataframe[y_col] = dataframe[y_col].apply(str)\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        rotation_range = 20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ) \n",
    "    iterator = generator.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = \"./patch_images\", \n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        classes = classes, \n",
    "        class_mode = \"categorical\", \n",
    "        target_size = image_shape, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e646a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_list = os.listdir('./patch_images/')\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea685c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "duplicates = []\n",
    "hash_keys = dict()\n",
    "for index, filename in  enumerate(os.listdir('./patch_images/')):  #listdir('.') = current directory\n",
    "\n",
    "    if os.path.isfile('./patch_images/'+filename):\n",
    "        with open('./patch_images/'+filename, 'rb') as f:\n",
    "            filehash = hashlib.md5(f.read()).hexdigest()\n",
    "        if filehash not in hash_keys: \n",
    "            hash_keys[filehash] = index\n",
    "        else:\n",
    "            duplicates.append((index,hash_keys[filehash]))\n",
    "            print(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d8d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread\n",
    "for file_indexes in duplicates[:30]:\n",
    "    try:\n",
    "    \n",
    "        plt.subplot(121),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[1]]))\n",
    "        plt.title(file_indexes[1]), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "        plt.subplot(122),plt.imshow(imread('./patch_images/'+ file_list[file_indexes[0]]))\n",
    "        plt.title(str(file_indexes[0]) + ' duplicate'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "    \n",
    "    except OSError as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e190503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate\n",
    "for index in duplicates:\n",
    "    os.remove('./patch_images/' + file_list[index[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bb811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cancer_class_count = main_data.isCancerous.value_counts()\n",
    "amount_for_balance = abs(is_cancer_class_count[0] - is_cancer_class_count[1])\n",
    "df_random_cancer_from_extra = main_data_extra[main_data_extra['isCancerous'] == 1].sample(amount_for_balance)\n",
    "for index in duplicates:\n",
    "    main_data = main_data[main_data.ImageName  != file_list[index[0]]]\n",
    "    df_random_cancer_from_extra = df_random_cancer_from_extra[df_random_cancer_from_extra.ImageName  != file_list[index[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_task2 = main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.concat([main_data, df_random_cancer_from_extra], ignore_index=True)\n",
    "main_data.isCancerous.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213baa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "raw_train_task, test_data = train_test_split(main_data[['ImageName', 'isCancerous']], test_size=0.2, random_state=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_task, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce77b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_task, val_data = train_test_split(raw_train_task, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(raw_train_task.shape[0], val_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e7662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# document: https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def get_dataframe_iterator(dataframe, \n",
    "                            image_shape = (27, 27), \n",
    "                            batch_size = 64,\n",
    "                            x_col = \"ImageName\",\n",
    "                            y_col = \"cellTypeName\",\n",
    "                            classes = [\"fibroblast\", \"inflammatory\", \"epithelial\", \"others\"]):\n",
    "    dataframe[y_col] = dataframe[y_col].apply(str)\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale = 1./255, \n",
    "        rotation_range = 20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True\n",
    "    ) \n",
    "    iterator = generator.flow_from_dataframe(\n",
    "        dataframe = dataframe,\n",
    "        directory = \"./patch_images\", \n",
    "        x_col = x_col,\n",
    "        y_col = y_col,\n",
    "        classes = classes, \n",
    "        class_mode = \"categorical\", \n",
    "        target_size = image_shape, \n",
    "        batch_size = batch_size,\n",
    "    )\n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77af1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = get_dataframe_iterator(raw_train_task, y_col='isCancerous', classes=['0','1'])\n",
    "val_iterator = get_dataframe_iterator(val_data, y_col='isCancerous', classes=['0','1'])\n",
    "test_iterator = get_dataframe_iterator(test_data, y_col='isCancerous', classes=['0','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d655018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, iterator, val_iterator, \n",
    "              epochs = 100, \n",
    "              export_dir = './export',\n",
    "              name = 'default'):\n",
    "    history = model.fit_generator(\n",
    "        iterator,\n",
    "        validation_data = val_iterator,\n",
    "        epochs = epochs,\n",
    "        verbose = 1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0079c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f238539-03fc-4308-b6bf-85b1649ec5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = ['accuracy', precision_m, recall_m, f1_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe1edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_images = []\n",
    "\n",
    "for path in main_data['ImageName']:\n",
    "  image_path = os.path.join(\"./patch_images\", path)\n",
    "  image = cv2.imread(image_path , cv2.IMREAD_GRAYSCALE)\n",
    "  list_of_images.append(image)\n",
    "\n",
    "list_of_images = np.asarray(list_of_images)\n",
    "np.array(list_of_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = np.reshape(list_of_images,  (-1 , 27 * 27))\n",
    "list_of_images = pd.DataFrame(list_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4853ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_cancer , validate_x_cancer, train_y_cancer , validate_y_cancer = train_test_split(list_of_images, main_data['isCancerous'], test_size=0.2 , random_state = 42, shuffle = True)\n",
    "\n",
    "print(\"Train X shape: \" , train_x_cancer.shape)\n",
    "print(\"Train Y shape: \" , train_y_cancer.shape)\n",
    "print(\"Validate X shape: \" , validate_x_cancer.shape)\n",
    "print(\"Validate Y shape: \" , validate_y_cancer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b8e72",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d6b814",
   "metadata": {},
   "source": [
    "### 1. Default model (without any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae76c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Binary:logistic is used for logistic classfication problem which is our problem in this task\n",
    "xgbr = xgb.XGBClassifier(objective='binary:logistic')\n",
    "xgbr.fit(train_x_cancer, train_y_cancer)\n",
    "\n",
    "y_pred_validate = xgbr.predict(validate_x_cancer)\n",
    "prediction_validate = [round(value) for value in y_pred_validate]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(validate_y_cancer, prediction_validate)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "mse = mean_squared_error(validate_y_cancer, y_pred_validate)\n",
    "print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "# accuracy = accuracy_score(validate_y_cancer, ypred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a2738",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = xgbr.predict(train_x_cancer)\n",
    "prediction_train = [round(value) for value in y_pred_train]\n",
    "print(\"Validate report\")\n",
    "print(classification_report(validate_y_cancer, prediction_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae13d0d",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "The alogrithm produce a high accuracy and low RMSE. However, we should increase the efficency of this model by figure out the best parameters for this alogirthm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5583d6",
   "metadata": {},
   "source": [
    "### 2. Using GridSearchCV to find best params and calculate RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f56922",
   "metadata": {},
   "source": [
    "####  **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e117bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "gs_xgbr = xgb.XGBClassifier(seed = 20)\n",
    "grid_search_cv = GridSearchCV(estimator=gs_xgbr, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "grid_search_cv.fit(train_x_cancer, train_y_cancer)\n",
    "print(\"Best parameters:\", grid_search_cv.best_params_)\n",
    "print(\"Lowest RMSE: \", (-grid_search_cv.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1d819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "gs_y_pred_validate = grid_search_cv.predict(validate_x_cancer)\n",
    "gs_prediction_validate = [round(value) for value in gs_y_pred_validate]\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer, gs_prediction_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e4bb6",
   "metadata": {},
   "source": [
    "### 3. Using Randomized Search CV to find best params and calculate lowest RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94715c0e",
   "metadata": {},
   "source": [
    "#### **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3755536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "rs_xgbr = xgb.XGBClassifier(seed = 20)\n",
    "random_search = RandomizedSearchCV(estimator=rs_xgbr,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         verbose=1)\n",
    "random_search.fit(train_x_cancer, train_y_cancer)\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Lowest RMSE: \", (-random_search.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b5875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "rd_y_pred_validate = random_search.predict(validate_x_cancer)\n",
    "rd_prediction_validate = [round(value) for value in rd_y_pred_validate]\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer, rd_prediction_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b3722",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "- After using 2 different approaches : grid search and random search, it is straightforward that the random search produce the higher accuracy ***(83% > 82%)*** and lower RMSE ***(0.421% > 0.423%)*** than the grid search . Therefore, we design to use random search instead of gridsearch to build our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a1bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "fig, ( ax1) = plt.subplots(1, 1, figsize=(20, 8))\n",
    "plot_confusion_matrix(random_search, validate_x_cancer, validate_y_cancer, ax=ax1)\n",
    "\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw a summary table for prediction sepsis and not sepsis\n",
    "pd.DataFrame(confusion_matrix(validate_y_cancer,rd_y_pred_validate),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54259f87",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "For this model, when diagnose 1108 not-cancerous cells, the machine predict corect 929 cells, which is 84%. On the other hand, when predict for cancerous cells, the machine predict correct 999 over 1219 cell, which 82%. As our a problem is diagnose whether the cell is cancerous or not, thus, it is more ***important*** to consider the ***false negative*** than ***false postive***. In other words, if the normal cell is diagnose as positive, we need to pay extra fee for medical and place for that patient whereas the positive cell is diagnose as negative, that patient may lost their life. Therefore, compare between the money and people life, obviously, we should pay more attention on the people life which is affected by false negative. Thus, this model is acceptable since the percentage of recall is 84%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b621f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "evaluation_xgboost_t1 = [None]\n",
    "evaluation_xgboost_t1.append(accuracy_score(validate_y_cancer,rd_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(precision_score(validate_y_cancer, rd_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(recall_score(validate_y_cancer, rd_y_pred_validate))\n",
    "evaluation_xgboost_t1.append(f1_score(validate_y_cancer, rd_y_pred_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42bda2",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31edc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54611d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "!pip install keras_applications\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(include_top=False, input_shape=(75, 75, 3), weights='imagenet')\n",
    "\n",
    "# Resize Input images to 75x75\n",
    "newInput = Input(batch_shape=(None, 27, 27, 3))\n",
    "resizedImg = Lambda(lambda image: tf.compat.v1.image.resize_images(image, (75, 75)))(newInput)\n",
    "newOutputs = model(resizedImg)\n",
    "model = Model(newInput, newOutputs)\n",
    "\n",
    "# Freeze all the layers\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add Dense layer to classify on CIFAR10\n",
    "output = model.output\n",
    "output = GlobalAveragePooling2D()(output)\n",
    "output = Dense(units=2, activation='softmax')(output)\n",
    "model_inceptionv3 = Model(model.input, output)\n",
    "\n",
    "model_inceptionv3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0045 , amsgrad = True)\n",
    "model_inceptionv3.compile(optimizer=Adam(lr=1e-4),loss='categorical_crossentropy', metrics=METRICS)\n",
    "\n",
    "history_inception_v3 = fit_model(model_inceptionv3, train_iterator, val_iterator, \n",
    "                                export_dir='.',\n",
    "                                name=\"Inception_Task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738c1f2a",
   "metadata": {},
   "source": [
    "# GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c269e503-75f9-4f1f-896e-4501fed4c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_googlenet(model, iterator, val_iterator, \n",
    "              epochs = 50, \n",
    "              export_dir = './export',\n",
    "              name = 'default'):\n",
    "    es = EarlyStopping(monitor='dense_5_accuracy', \n",
    "                       mode='max', \n",
    "                       verbose=1, \n",
    "                       patience=10, \n",
    "                       restore_best_weights=True)\n",
    "    mc = ModelCheckpoint('{}/model_{}.h5'.format(export_dir, name), \n",
    "                         monitor='dense_5_accuracy', \n",
    "                         mode='max', \n",
    "                         save_best_only=True)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        iterator,\n",
    "        validation_data = val_iterator,\n",
    "        epochs = epochs,\n",
    "        verbose = 1,\n",
    "        callbacks=[mc,es]\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b70d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inception_block(input_layer, f1, f2_conv1, f2_conv3, f3_conv1, f3_conv5, f4): \n",
    "  # Input: \n",
    "  # - f1: number of filters of the 1x1 convolutional layer in the first path\n",
    "  # - f2_conv1, f2_conv3 are number of filters corresponding to the 1x1 and 3x3 convolutional layers in the second path\n",
    "  # - f3_conv1, f3_conv5 are the number of filters corresponding to the 1x1 and 5x5  convolutional layer in the third path\n",
    "  # - f4: number of filters of the 1x1 convolutional layer in the fourth path\n",
    "\n",
    "  # 1st path:\n",
    "  path1 = Conv2D(filters=f1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "\n",
    "  # 2nd path\n",
    "  path2 = Conv2D(filters = f2_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path2 = Conv2D(filters = f2_conv3, kernel_size = (3,3), padding = 'same', activation = 'relu')(path2)\n",
    "\n",
    "  # 3rd path\n",
    "  path3 = Conv2D(filters = f3_conv1, kernel_size = (1,1), padding = 'same', activation = 'relu')(input_layer)\n",
    "  path3 = Conv2D(filters = f3_conv5, kernel_size = (5,5), padding = 'same', activation = 'relu')(path3)\n",
    "\n",
    "  # 4th path\n",
    "  path4 = MaxPooling2D((3,3), strides= (1,1), padding = 'same')(input_layer)\n",
    "  path4 = Conv2D(filters = f4, kernel_size = (1,1), padding = 'same', activation = 'relu')(path4)\n",
    "\n",
    "  output_layer = concatenate([path1, path2, path3, path4], axis = -1)\n",
    "\n",
    "  return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a636b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GoogLeNet():\n",
    "  # input layer \n",
    "  input_layer = Input(shape = (27, 27, 3))\n",
    "\n",
    "  # convolutional layer: filters = 64, kernel_size = (7,7), strides = 2\n",
    "  X = Conv2D(filters = 64, kernel_size = (7,7), strides = 2, padding = 'valid', activation = 'relu')(input_layer)\n",
    "\n",
    "  X = ZeroPadding2D(padding=(10, 10))(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 1)(X)\n",
    "\n",
    "  # convolutional layer: filters = 64, strides = 1\n",
    "  X = Conv2D(filters = 64, kernel_size = (1,1), strides = 1, padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # convolutional layer: filters = 192, kernel_size = (3,3)\n",
    "  X = Conv2D(filters = 192, kernel_size = (3,3), padding = 'same', activation = 'relu')(X)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 1st Inception block\n",
    "  X = Inception_block(X, f1 = 64, f2_conv1 = 96, f2_conv3 = 128, f3_conv1 = 16, f3_conv5 = 32, f4 = 32)\n",
    "\n",
    "  # 2nd Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 192, f3_conv1 = 32, f3_conv5 = 96, f4 = 64)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size= (3,3), strides = 2)(X)\n",
    "\n",
    "  # 3rd Inception block\n",
    "  X = Inception_block(X, f1 = 192, f2_conv1 = 96, f2_conv3 = 208, f3_conv1 = 16, f3_conv5 = 48, f4 = 64)\n",
    "\n",
    "  # Extra network 1:\n",
    "  X1 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X1 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X1)\n",
    "  X1 = Flatten()(X1)\n",
    "  X1 = Dense(1024, activation = 'relu')(X1)\n",
    "  X1 = Dropout(0.7)(X1)\n",
    "  X1 = Dense(2, activation = 'softmax')(X1) # <----- changed 1000 to 2\n",
    "\n",
    "  \n",
    "  # 4th Inception block\n",
    "  X = Inception_block(X, f1 = 160, f2_conv1 = 112, f2_conv3 = 224, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 5th Inception block\n",
    "  X = Inception_block(X, f1 = 128, f2_conv1 = 128, f2_conv3 = 256, f3_conv1 = 24, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # 6th Inception block\n",
    "  X = Inception_block(X, f1 = 112, f2_conv1 = 144, f2_conv3 = 288, f3_conv1 = 32, f3_conv5 = 64, f4 = 64)\n",
    "\n",
    "  # Extra network 2:\n",
    "  X2 = AveragePooling2D(pool_size = (5,5), strides = 3)(X)\n",
    "  X2 = Conv2D(filters = 128, kernel_size = (1,1), padding = 'same', activation = 'relu')(X2)\n",
    "  X2 = Flatten()(X2)\n",
    "  X2 = Dense(1024, activation = 'relu')(X2)\n",
    "  X2 = Dropout(0.7)(X2)\n",
    "  X2 = Dense(2, activation = 'softmax')(X2) # <----- changed 1000 to 2\n",
    "  \n",
    "  \n",
    "  # 7th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, \n",
    "                      f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # max-pooling layer: pool_size = (3,3), strides = 2\n",
    "  X = MaxPooling2D(pool_size = (3,3), strides = 2)(X)\n",
    "\n",
    "  # 8th Inception block\n",
    "  X = Inception_block(X, f1 = 256, f2_conv1 = 160, f2_conv3 = 320, f3_conv1 = 32, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # 9th Inception block\n",
    "  X = Inception_block(X, f1 = 384, f2_conv1 = 192, f2_conv3 = 384, f3_conv1 = 48, f3_conv5 = 128, f4 = 128)\n",
    "\n",
    "  # Global Average pooling layer \n",
    "  X = GlobalAveragePooling2D(name = 'GAPL')(X)\n",
    "\n",
    "  # Dropoutlayer \n",
    "  X = Dropout(0.4)(X)\n",
    "\n",
    "  # output layer \n",
    "  X = Dense(2, activation = 'softmax')(X) # <------ changed from 1000 to 2 \n",
    "  \n",
    "  # model\n",
    "  model = Model(input_layer, [X, X1, X2], name = 'GoogLeNet')\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_googlenet_t1 = GoogLeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "model_googlenet_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_googlenet_t1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91fdfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.00045, amsgrad = True)\n",
    "model_googlenet_t1.compile(optimizer=opt, loss='binary_crossentropy',metrics=METRICS)\n",
    "\n",
    "history_googlenet_t1 = fit_model_googlenet(model_googlenet_t1, train_iterator, val_iterator,\n",
    "                                export_dir='.',\n",
    "                                name=\"GoogLeNet_Task1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f6155-2911-4db6-bcc0-ebce8a87cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_googlenet_t1.save('./googlenet.h5');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99379d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = model_googlenet_t1.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f6a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_googlenet_t1 = [\n",
    "    evaluation_googlenet_t1[1], # dense_4_loss\n",
    "    evaluation_googlenet_t1[4], # dense_4_accuracy\n",
    "    evaluation_googlenet_t1[5], # dense_4_precision\n",
    "    evaluation_googlenet_t1[6], # dense_4_recall\n",
    "    evaluation_googlenet_t1[7]  # dense_4_f1\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23359c1",
   "metadata": {},
   "source": [
    "# Resnet50\n",
    "## Defining an identity block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8768b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/analytics-vidhya/understanding-and-implementation-of-residual-networks-resnets-b80f9a507b9c\n",
    "def identity_block(X, f, filters, block, activation='relu'):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block\n",
    "    \n",
    "    Arguments:\n",
    "    X: input tensor\n",
    "    f: shape for middle CONV kernel size param\n",
    "    filters: list of number of filters in the CONV layers of the main path\n",
    "    block: name of this block\n",
    "    \n",
    "    Returns:\n",
    "    X: output, returns a tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    conv_name = 'conv' + block\n",
    "    bn_name = 'batchNorm' + block\n",
    "    \n",
    "    # get filters from parameter\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # copy the original shape to add it back to the main path\n",
    "    X_copy = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name + 'a', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    \n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name + 'b', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name + 'c', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'c')(X)\n",
    "\n",
    "    # add shortcut back to main path, and use relu activation\n",
    "    X = Add()([X, X_copy])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb650ac2",
   "metadata": {},
   "source": [
    "## Defining a convolutional block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ed88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, block, s = 2, activation='relu'):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block\n",
    "    \n",
    "    Arguments:\n",
    "    X: input tensor\n",
    "    f: shape for middle CONV kernel size param\n",
    "    filters: list of number of filters in the CONV layers of the main path\n",
    "    block: name of this block\n",
    "    s: stride param to be used for shortcut component\n",
    "    \n",
    "    Returns:\n",
    "    X: output, returns a tensor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    conv_name = 'conv' + block\n",
    "    bn_name = 'batchNorm' + block\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_copy = X\n",
    "\n",
    "    # First component\n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name + 'a', kernel_initializer  = GlorotUniform(seed= 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'a')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Second component\n",
    "    X = Conv2D(F2, (f,f), strides = (1,1), padding = 'same', name = conv_name + 'b', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'b')(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    # Third component\n",
    "    X = Conv2D(F3, (1,1), strides = (1,1), padding = 'valid', name = conv_name + 'c', kernel_initializer = GlorotUniform(seed = 0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name + 'c')(X)\n",
    "\n",
    "    # Shortcut\n",
    "    X_copy = Conv2D(F3, (1,1), strides = (s,s), padding = 'valid', name = conv_name + 'd', kernel_initializer = GlorotUniform(seed = 0))(X_copy)\n",
    "    X_copy = BatchNormalization(axis = 3, name = bn_name + 'd')(X_copy)\n",
    "\n",
    "    # add shortcut back to main path, and use relu activation\n",
    "    X = Add()([X, X_copy])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf27882",
   "metadata": {},
   "source": [
    "## Implementing a ResNet50 architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece5b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (27, 27, 3), classes = 2):\n",
    "    \"\"\"\n",
    "    Implementation using the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    MAXPOOl -> TOPLAYER\n",
    "\n",
    "    reducing the typical 5 stage to 3 stage to reduce time and memory expense\n",
    "\n",
    "    Arguments:\n",
    "    input_shape: shape of image, currently is 27x27\n",
    "    classes: integer, number of classes to identify\n",
    "    \n",
    "    returns a Model() instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set x_input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # add padding for tensor\n",
    "    X = ZeroPadding2D((0, 0))(X_input)\n",
    "\n",
    "    #since resnet only works for images that is 30x30 pixels or higher, we need to add padding pixels for the algorithm to work\n",
    "    \n",
    "    # first stage\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = initializers.RandomNormal(stddev=0.01))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # second\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], block='2a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2c')\n",
    "\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    \n",
    "    # third\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], block='3a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3d')\n",
    "    \n",
    "    # avg pooling\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = GlorotUniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30573cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50_t1 = ResNet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16040cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001 , amsgrad = True)\n",
    "model_resnet50_t1.compile(optimizer=opt, loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "history_resnet50_t1 = fit_model(model_resnet50_t1, train_iterator, val_iterator, \n",
    "                                export_dir=\"\",\n",
    "                                name=\"resnet50_t1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e8045",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_resnet50_t1 = model_resnet50_t1.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be0af1d",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1306304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "\n",
    "\n",
    "np.random.seed(1000)\n",
    "\n",
    "#Instantiation\n",
    "AlexNet = Sequential()\n",
    "\n",
    "#1st Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=96, input_shape=(27, 27, 3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#2nd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "#3rd Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#4th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "\n",
    "#5th Convolutional Layer\n",
    "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "AlexNet.add(MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same'))\n",
    "\n",
    "#Passing it to a Fully Connected layer\n",
    "AlexNet.add(Flatten())\n",
    "# 1st Fully Connected Layer\n",
    "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "AlexNet.add(Dropout(0.5))\n",
    "\n",
    "#2nd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.7))\n",
    "\n",
    "#3rd Fully Connected Layer\n",
    "AlexNet.add(Dense(4096))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('relu'))\n",
    "#Add Dropout\n",
    "AlexNet.add(Dropout(0.9))\n",
    "\n",
    "#Output Layer\n",
    "AlexNet.add(Dense(10))\n",
    "AlexNet.add(BatchNormalization())\n",
    "AlexNet.add(Activation('softmax'))\n",
    "\n",
    "#Model Summary\n",
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/implementing-alexnet-cnn-architecture-using-tensorflow-2-0-and-keras-2113e090ad98\n",
    "\n",
    "\n",
    "def AlexNet():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', input_shape=(27, 27, 3)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        \n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(1,1)),\n",
    "        \n",
    "        keras.layers.Flatten(),\n",
    "        \n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        \n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.7),\n",
    "\n",
    "        keras.layers.Dense(2, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cac0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0035)\n",
    "\n",
    "alex_model = AlexNet()\n",
    "alex_model.compile(optimizer=\"SGD\", loss='binary_crossentropy', metrics=METRICS)\n",
    "\n",
    "alex_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80197643",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_AlexNet = fit_model(alex_model, train_iterator, val_iterator,name=\"Task1_AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0eb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alex1 = alex_model.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa198f7",
   "metadata": {},
   "source": [
    "# *Task2: Classify  images  according  to  cell-type,  such  as:  fibroblast,  inflammatory, epithelial or others* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ded6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = main_data_task2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee169c46",
   "metadata": {},
   "source": [
    "<a id =\"IV\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">â… . Cleaning dataset  </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfb9f6",
   "metadata": {},
   "source": [
    "#### Before cleaning the data, let display the dataset to observe it in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d555f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acbc66d",
   "metadata": {},
   "source": [
    "<a id =\"IV.A1\"></a>\n",
    "\n",
    "### *1. Check Data type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ee211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all info row by row\n",
    "main_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18d525",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "We need to check data type for overall understanding for our dataset and identifying which column we should keep or change data type for later encoding and better model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f5b0",
   "metadata": {},
   "source": [
    "<a id =\"IV.A2\"></a>\n",
    "\n",
    "### *2. Checking missing values*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b535ad0a",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "Missing value can lead to error for machine, thus, we need to check if there is any missing value and fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the dataset has any missing value, \n",
    "main_data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c605a",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "Since the return value is false, we can conclude that the dataset has no missing values. However, we should double check for every columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f45c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total missing values for each columns \n",
    "main_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6cf7a5",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "There is 100% no missing values in any columns in the dataset, thus, we dont not need to fill any missing values for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4d506",
   "metadata": {},
   "source": [
    "<a id =\"IV.A3\"></a>\n",
    "\n",
    "### *3. Check typography*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype_name_values = main_data['cellTypeName'].nunique(dropna=False)\n",
    "print(celltype_name_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_data['cellTypeName'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9b944",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "Typo value can lead to time runing and storage problem for machine (fibroblast, fibreblast are 2 different values but have same meaning), thus, we check typo preventing same meaningful values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6c8a06",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "Since the cellTypeName column have 4 different values such as fibroblast, inflammatory, epithelial or others. => no typo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8813c8b",
   "metadata": {},
   "source": [
    "<a id =\"IV.A4\"></a>\n",
    "\n",
    "### *4. Convert string column to uppercase*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73572b",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "Since there are only 4 values fibroblast, inflammatory, epithelial in cellTypeName columns. Therefore, we do not need to convert to lowercase or uppercase for this dataset. However, in the larger dataset with multiple values, we should convert to all uppercase or lowercase to avoid duplication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdb3f63",
   "metadata": {},
   "source": [
    "<a id =\"IV.A5\"></a>\n",
    "\n",
    "### 5. Eliminate extra white spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d910c3",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "Since the Sepsis column have 4 different values such as fibroblast, inflammatory, epithelial or others => no extra white spaces    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c994bd3",
   "metadata": {},
   "source": [
    "<a id =\"IV.A6\"></a>\n",
    "\n",
    "### *6. Check duplication*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty Datafrane -> no dupplication in the main_data dataframe\n",
    "duplicate_values = main_data[main_data.duplicated()]\n",
    "print(duplicate_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dfc5f7",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "Duplicate data can lead to time runing and storage problem for machine, thus, we need to check if there is any duplicated data and drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88066fec",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "There is 100% no duplicated values in the dataset, thus, we dont not need to drop any rows for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d66ff",
   "metadata": {},
   "source": [
    "<a id =\"IV.A7a\"></a>\n",
    "\n",
    "### 7. Check impossible values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab5655b",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "Some time the dataset has some impossible values such as age is negative, thus, we need to check impossible value to find and drop or fix it to improve the accuracy of the machine learing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfdd5e",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "In this dataset, all of the data are reasonable => no impossible values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a211bb",
   "metadata": {},
   "source": [
    "<a id =\"IV.B8\"></a>\n",
    "\n",
    "### 8. Check outlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 7.5]\n",
    "# plot the boxplot to see the outlier of each numerical column\n",
    "sns.boxplot(data=main_data,orient=\"v\")\n",
    "plt.title(\"Bot-Plots Distribution\", y = 1,fontsize = 20, pad = 40);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1cd74",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation:\n",
    "According to the bot-plots, there are completely no outliner in this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385a602",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "After finish cleaning the data, we should display the data to double check the data and figure out the count, mean, min , 25%, 50%, 75%, max to prepare for EDA step in later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9fb32",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">II. Exploratory Data Analysis (EDA)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febf39ec",
   "metadata": {},
   "source": [
    "<a id =\"V.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.My hypothesises </h3>\n",
    "\n",
    "1. The value for each type in the cell type name will be different.\n",
    "\n",
    "2. The value of `others` class will be the least compare to other classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0874225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "titanic = sns.load_dataset(\"titanic\")\n",
    "ax = sns.countplot(y=\"cellTypeName\", data=main_data)\n",
    "ax.set_title(\"Bar chart to display the total number of each type in cell type name\", fontsize=15)\n",
    "for bars in ax.containers:\n",
    "    ax.bar_label(bars)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d95a7f",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "In this plot, the vertical axis is cellTypeName and the horizontal axis is count (total values). In overall, the class epithelial has the most value (4079) whereas the other class have the least value (1386). In additional, the different between each class are large, thus, we should consider to solve this problem by using imbalance in the feature engineering step. \n",
    "\n",
    "After observation, we can conclude that our hypotheses are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a094c3",
   "metadata": {},
   "source": [
    "<a id =\"VI\"></a>\n",
    "\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">III. Feature Enginnering</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1622526",
   "metadata": {},
   "source": [
    "<a id =\"VI.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Drop Unrealated columns to the target</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe28d3f",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "Since all columns in the dataset are neccessary => we do not need to drop any columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ad113",
   "metadata": {},
   "source": [
    "<a id =\"VI.2\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2.Class Imbalances</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(main_data['cellTypeName'].value_counts())\n",
    "print(main_data['cellTypeName'].value_counts(normalize=True, dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8dc023",
   "metadata": {},
   "source": [
    "### ðŸ“š Reason: \n",
    "The reason, we need to rebalance these classes value is the accuracy of the sepsis prediction might affected by the amount of values in one class. In other words , if one class has more values compare to the others , it is likely that we will receive the better prediction for this class instead of others, thus, the prediction for other clas might be worst. Thus,in this particular situation, since the difference between these classes are large, we can rebalance these classes using <strong>upsample method</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4059c3a",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "After upsampling these classes, the value for all classes are the same, thus, we can move to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7430e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_images = []\n",
    "\n",
    "for path in main_data['ImageName']:\n",
    "  image_path = os.path.join(\"./patch_images\", path)\n",
    "  image = cv2.imread(image_path , cv2.IMREAD_GRAYSCALE)\n",
    "  list_of_images.append(image)\n",
    "\n",
    "list_of_images = np.asarray(list_of_images)\n",
    "np.array(list_of_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715dd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = np.reshape(list_of_images,  (-1 , 27 * 27))\n",
    "list_of_images = pd.DataFrame(list_of_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d2a69",
   "metadata": {},
   "source": [
    "<a id =\"VII\"></a>\n",
    "<h2 style = \"text-align:center; color:white; font-weight:600; padding:0.5em; background-color: #B02B00; border-radius:25px ; box-shadow: 0 0 20px 0 #ACA7CB; margin-right:3em; margin-bottom:1em\">IV. Model Building</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c999e89",
   "metadata": {},
   "source": [
    "<a id =\"VII.1\"></a>\n",
    "\n",
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">1.Split dataframe </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acdb6d5-a993-4996-ab7a-81fcad7dfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = main_data['cellTypeName'].value_counts()\n",
    "main_data_resampled = main_data[main_data['cellTypeName'] == 'epithelial']\n",
    "for cellTypeName in class_count.keys():\n",
    "  if (cellTypeName == 'epithelial'): continue\n",
    "  main_data_class = main_data[main_data['cellTypeName'] == cellTypeName].sample(class_count['epithelial'], replace=True)\n",
    "  main_data_resampled = pd.concat([main_data_resampled, main_data_class], axis=0)\n",
    "main_data_resampled['cellTypeName'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed73915-3e25-4358-b536-e9212f6f3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(main_data_resampled, test_size=0.2, random_state=9999)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=9999)\n",
    "\n",
    "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_df.shape[0], val_df.shape[0], test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a50f2-b333-4ead-bd14-fe6d2014db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = get_dataframe_iterator(train_df)\n",
    "val_iterator = get_dataframe_iterator(val_df)\n",
    "test_iterator = get_dataframe_iterator(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704de4c-3842-46ad-a627-6a9047ec8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x_cancer_task2 , validate_x_cancer_task2, train_y_cancer_task2 , validate_y_cancer_task2 = train_test_split(\n",
    "    list_of_images, \n",
    "    main_data['cellType'], \n",
    "    train_size = 0.8, \n",
    "    random_state = 9999, \n",
    "    shuffle = True)\n",
    "\n",
    "print(\"Training X shape: \" , train_x_cancer_task2.shape)\n",
    "print(\"Training Y shape: \" , train_y_cancer_task2.shape)\n",
    "print(\"Testing X shape: \" , validate_x_cancer_task2.shape)\n",
    "print(\"Testing Y shape: \" , validate_y_cancer_task2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663692d4-42ea-4510-b1e2-c2be430d8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ffd26",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "After spliting the data, we can start training the models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41770af",
   "metadata": {},
   "source": [
    "<h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">2. XG Boost</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24b7de4",
   "metadata": {},
   "source": [
    "### 1. Default model (without any parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09207bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Binary:logistic is used for logistic classfication problem which is our problem in this task\n",
    "xgbr_task2 = xgb.XGBClassifier(objective='binary:logistic')\n",
    "xgbr_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "\n",
    "y_pred_validate_task2 = xgbr_task2.predict(validate_x_cancer_task2)\n",
    "prediction_validate_task2 = [round(value) for value in y_pred_validate_task2]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(validate_y_cancer_task2, prediction_validate_task2)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "mse = mean_squared_error(validate_y_cancer_task2, y_pred_validate_task2)\n",
    "print(\"RMSE: %.2f\" % (mse**(1/2.0)))\n",
    "# accuracy = accuracy_score(validate_y_cancer, ypred)\n",
    "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validate report\")\n",
    "print(classification_report(validate_y_cancer_task2, prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3dc0f",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n",
    "The alogrithm produce a high accuracy and low RMSE. However, we should increase the efficency of this model by figure out the best parameters for this alogirthm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58243cc",
   "metadata": {},
   "source": [
    "### 2. Using GridSearchCV to find best params and calculate RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dfc7d8",
   "metadata": {},
   "source": [
    "####  **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = { 'max_depth': [3,6,10],\n",
    "           'learning_rate': [0.01, 0.05, 0.1],\n",
    "           'n_estimators': [100, 500, 1000],\n",
    "           'colsample_bytree': [0.3, 0.7]}\n",
    "gs_xgbr_task2 = xgb.XGBClassifier(seed = 20)\n",
    "grid_search_cv_task2 = GridSearchCV(estimator=gs_xgbr_task2, \n",
    "                   param_grid=params,\n",
    "                   scoring='neg_mean_squared_error', \n",
    "                   verbose=1)\n",
    "grid_search_cv_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "print(\"Best parameters:\", grid_search_cv_task2.best_params_)\n",
    "print(\"Lowest RMSE: \", (-grid_search_cv_task2.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "gs_y_pred_validate_task2 = grid_search_cv_task2.predict(validate_x_cancer_task2)\n",
    "gs_prediction_validate_task2 = [round(value) for value in gs_y_pred_validate_task2]\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer_task2, gs_prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96183c",
   "metadata": {},
   "source": [
    "### 3. Using Randomized Search CV to find best params and calculate lowest RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1475a8",
   "metadata": {},
   "source": [
    "#### **Hyperparameter tuning chosen**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "rs_xgbr_task2 = xgb.XGBClassifier(seed = 20)\n",
    "random_search_task2 = RandomizedSearchCV(estimator=rs_xgbr_task2,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         verbose=1)\n",
    "random_search_task2.fit(train_x_cancer_task2, train_y_cancer_task2)\n",
    "print(\"Best parameters:\", random_search_task2.best_params_)\n",
    "print(\"Lowest RMSE: \", (-random_search_task2.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict the y train and y validate using our model with x train and x validate\n",
    "rd_y_pred_validate_task2 = random_search_task2.predict(validate_x_cancer_task2)\n",
    "rd_prediction_validate_task2 = [round(value) for value in rd_y_pred_validate_task2]\n",
    "\n",
    "print(\"Validation report\")\n",
    "print(classification_report(validate_y_cancer_task2, rd_prediction_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad462d",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9605bf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ( ax1) = plt.subplots(1, 1, figsize=(20, 8))\n",
    "plot_confusion_matrix(random_search_task2, validate_x_cancer_task2, validate_y_cancer_task2, ax=ax1)\n",
    "\n",
    "\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "ax1.title.set_text('Test Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draw a summary table for prediction sepsis and not sepsis\n",
    "pd.DataFrame(confusion_matrix(validate_y_cancer,rd_y_pred_validate),\\\n",
    "            columns=[\"Predicted Not-Cancerous\", \"Predicted Cancerous\"],\\\n",
    "            index=[\"Not-Cancerous\",\"Cancerous\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce1788",
   "metadata": {},
   "source": [
    "### ðŸ”¬ Observation: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "evaluation_xgboost_t1 = [None]\n",
    "evaluation_xgboost_t1.append(accuracy_score(validate_y_cancer_task2,rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(precision_score(validate_y_cancer_task2, rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(recall_score(validate_y_cancer_task2, rd_y_pred_validate_task2))\n",
    "evaluation_xgboost_t1.append(f1_score(validate_y_cancer_task2, rd_y_pred_validate_task2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a82977",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">3. Resnet</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50_t2(input_shape = (27, 27, 3), classes = 4):\n",
    "    \"\"\"\n",
    "    Implementation using the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*3 -> CONVBLOCK -> IDBLOCK*3\n",
    "    AVGPOOL -> TOPLAYER\n",
    "\n",
    "    reducing the typical 5 stage to 3 stage to reduce time and memory expense\n",
    "\n",
    "    Arguments:\n",
    "    input_shape: shape of image, currently is 27x27\n",
    "    classes: integer, number of classes to identify\n",
    "    \n",
    "    returns a Model() instance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # set x_input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # add padding for tensor\n",
    "    X = ZeroPadding2D((0, 0))(X_input)\n",
    "\n",
    "    #since resnet only works for images that is 30x30 pixels or higher, we need to add padding pixels for the algorithm to work\n",
    "    \n",
    "    # first stage\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = initializers.RandomNormal(stddev=0.01))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # second\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], block='2a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], block='2c')\n",
    "    # X = identity_block(X, 3, [64, 64, 256], block='2d')\n",
    "\n",
    "    # third\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], block='3a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], block='3d')\n",
    "    \n",
    "    # avg pooling\n",
    "    X = AveragePooling2D()(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    # X = Dense(1024, activation='relu')(X)\n",
    "    # X = Dropout(0.2)(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = GlorotUniform(seed=0) , kernel_regularizer=l2(0.01))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5214e",
   "metadata": {
    "id": "bRyL4qIcto4t"
   },
   "outputs": [],
   "source": [
    "model_resnet50_t2 = ResNet50_t2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecc78b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TjPwhpG7u-49",
    "outputId": "388b2bb0-c7e9-41c6-e292-7bef030b8a27"
   },
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.001, amsgrad = True) \n",
    "model_resnet50_t2.compile(optimizer=opt, loss='categorical_crossentropy', \n",
    "                          metrics=METRICS)\n",
    "\n",
    "history_resnet50_t2 = fit_model(model_resnet50_t2, train_iterator, val_iterator,\n",
    "                                export_dir=\"\",\n",
    "                                name='ResNet50_Task2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74c0fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-RYfEgZu7_a",
    "outputId": "5204fc06-3957-4081-d0ff-ef1c1c933d14"
   },
   "outputs": [],
   "source": [
    "evaluation_resnet50_t2 = model_resnet50_t2.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954cc294",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">4. VGG16</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8720e989-c8e5-4ae0-aba3-55e1b283c82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cce2388-70f3-499e-9872-46a5905aca0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VGG16_Task2():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\", input_shape = (27, 27, 3)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(32, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    # model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(528, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = \"relu\"))    \n",
    "    model.add(Dense(64, activation = \"relu\")) \n",
    "    model.add(Dense(4, activation = \"softmax\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301b05d1-5758-4b80-9e96-51e41b30a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = VGG16_Task2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728ac42-934a-4408-aae2-4e28181576df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb56247a-fb66-43d4-b309-052768356dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model_vgg16.compile(optimizer=opt, loss='categorical_crossentropy', \n",
    "                       metrics=METRICS)\n",
    "\n",
    "history_vgg16_t2 = fit_model(model_vgg16, train_iterator, val_iterator,\n",
    "                             export_dir='model/',\n",
    "                             name=\"VGG19_Task2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108253bb-9946-4ae7-b212-f0c1858c7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_vgg16_t2 = model_vgg16.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758d7f0",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">5. Alex Net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "def AlexNet2(input_shape = (27, 27, 3), \n",
    "                 classes = 4, \n",
    "                 optimizer ='SGD'):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(1,1), strides=(1,1), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(4096, activation='relu'),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(classes, activation='softmax' , kernel_regularizer=l2(0.001))\n",
    "        ])\n",
    "    model.compile(optimizer=optimizer, \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=METRICS)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d9f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "alex_model2 = AlexNet2()\n",
    "alex_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task2_AlexNet = fit_model(alex_model2, train_iterator, val_iterator,name=\"Task2_AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d617ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_alex2 = alex_model2.evaluate(test_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc26d9c",
   "metadata": {},
   "source": [
    "# <h3 style = \"color : #F06200; font-style:italic; letter-spacing:0.075em;\">5. Alex Net (Supervised)</h3>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05769ab26bc4c6f953a6ba0a347b071c6ea6ed51577d89c547c43644aca31720"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
